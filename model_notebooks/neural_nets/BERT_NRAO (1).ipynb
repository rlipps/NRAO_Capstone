{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E6QfYryifSGc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VSRPiTgpfZQ0"
      },
      "outputs": [],
      "source": [
        "projects = pd.read_csv('nrao_projects_use.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Yps6raskfgNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "394ddb11-75ea-45c2-9ec1-e12dc19a9727"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     project_code                                      project_title  \\\n",
              "0  2021.1.01616.L  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
              "1  2022.1.01077.L  A SPectroscopic survey of biased halos In the ...   \n",
              "2  2016.1.00324.L  ASPECS: The ALMA SPECtral line Survey in the U...   \n",
              "3  2022.1.00875.L                The ALMA Disk-Exoplanet C/Onnection   \n",
              "4  2017.1.01355.L  ALMA-IMF: ALMA transforms our view of the orig...   \n",
              "5  2016.1.00484.L  Small-Scale Substructures in Protoplanetary Disks   \n",
              "6  2021.1.01123.L                                            exoALMA   \n",
              "7  2019.1.01634.L  REBELS: An ALMA Large Program to Discover the ...   \n",
              "8  2019.1.00261.L           Early Planet Formation in Embedded Disks   \n",
              "9  2023.1.00127.L  Probing the molecular gas -- the missing puzzl...   \n",
              "\n",
              "                                    project_abstract fs_type  \\\n",
              "0  We propose the first ever statistical survey o...    line   \n",
              "1  We propose to obtain deep ALMA 1.2mm mosaic ob...    line   \n",
              "2  ASPECS represents an unparalleled three-dimens...    line   \n",
              "3  Protoplanetary disks set the initial compositi...    line   \n",
              "4  Studying massive protoclusters is an absolute ...    line   \n",
              "5  We propose a Large Program designed to charact...    line   \n",
              "6  Detecting planets embedded in their natal prot...    line   \n",
              "7  REBELS will construct the first large statisti...    line   \n",
              "8  We propose an ALMA Large Program to investigat...    line   \n",
              "9  The interactions between gas and galaxies are ...    line   \n",
              "\n",
              "             science_category  \\\n",
              "0            Galaxy evolution   \n",
              "1            Galaxy evolution   \n",
              "2            Galaxy evolution   \n",
              "3  Disks and planet formation   \n",
              "4      ISM and star formation   \n",
              "5  Disks and planet formation   \n",
              "6  Disks and planet formation   \n",
              "7            Galaxy evolution   \n",
              "8  Disks and planet formation   \n",
              "9                   Cosmology   \n",
              "\n",
              "                                     science_keyword band  target  \\\n",
              "0    Surveys of galaxies, Galaxy groups and clusters    6       1   \n",
              "1  Sub-mm Galaxies (SMG), High-z Active Galactic ...    6       1   \n",
              "2                         Lyman Break Galaxies (LBG)    3       1   \n",
              "3           Disks around low-mass stars, Exo-planets    7       1   \n",
              "4  High-mass star formation, Low-mass star formation    6       1   \n",
              "5                        Disks around low-mass stars    6       1   \n",
              "6           Disks around low-mass stars, Exo-planets    7       1   \n",
              "7  Lyman Break Galaxies (LBG), Galaxy structure &...    6       1   \n",
              "8                        Disks around low-mass stars    6       1   \n",
              "9  Cosmic Microwave Background (CMB)/Sunyaev-Zel'...    6       1   \n",
              "\n",
              "                                            raw_text  \\\n",
              "0  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
              "1  A SPectroscopic survey of biased halos In the ...   \n",
              "2  ASPECS: The ALMA SPECtral line Survey in the U...   \n",
              "3  The ALMA Disk-Exoplanet C/Onnection. Protoplan...   \n",
              "4  ALMA-IMF: ALMA transforms our view of the orig...   \n",
              "5  Small-Scale Substructures in Protoplanetary Di...   \n",
              "6  exoALMA. Detecting planets embedded in their n...   \n",
              "7  REBELS: An ALMA Large Program to Discover the ...   \n",
              "8  Early Planet Formation in Embedded Disks. We p...   \n",
              "9  Probing the molecular gas -- the missing puzzl...   \n",
              "\n",
              "                                   standardized_text  \\\n",
              "0  jelly survey of nearby jellyfish and ram press...   \n",
              "1  a spectroscopic survey of biased halos in the ...   \n",
              "2  aspecs the spectral line survey in the udf an ...   \n",
              "3  the disk exoplanet c onnection protoplanetary ...   \n",
              "4  imf transforms our view of the origin of stell...   \n",
              "5  small scale substructures in protoplanetary di...   \n",
              "6  exo detecting planets embedded in their natal ...   \n",
              "7  rebels an large program to discover the most l...   \n",
              "8  early planet formation in embedded disks we pr...   \n",
              "9  probing the molecular gas the missing puzzle p...   \n",
              "\n",
              "                                          no_sw_text  \\\n",
              "0  jelly survey nearby jellyfish ram pressure str...   \n",
              "1  spectroscopic survey biased halos reionization...   \n",
              "2  aspecs spectral line survey udf large program ...   \n",
              "3  disk exoplanet c onnection protoplanetary disk...   \n",
              "4  imf transforms view origin stellar masses stud...   \n",
              "5  small scale substructures protoplanetary disks...   \n",
              "6  exo detecting planets embedded natal protoplan...   \n",
              "7  rebels large program discover luminous cii oii...   \n",
              "8  early planet formation embedded disks propose ...   \n",
              "9  probing molecular gas missing puzzle piece bar...   \n",
              "\n",
              "                                  lemmatized_sw_text  \\\n",
              "0  jelly survey of nearby jellyfish and ram press...   \n",
              "1  a spectroscopic survey of biased halo in the r...   \n",
              "2  aspecs the spectral line survey in the udf an ...   \n",
              "3  the disk exoplanet c onnection protoplanetary ...   \n",
              "4  imf transform our view of the origin of stella...   \n",
              "5  small scale substructure in protoplanetary dis...   \n",
              "6  exo detect planet embed in their natal protopl...   \n",
              "7  rebel an large program to discover the most lu...   \n",
              "8  early planet formation in embedded disk we pro...   \n",
              "9  probe the molecular gas the miss puzzle piece ...   \n",
              "\n",
              "                               lemmatized_no_sw_text  \n",
              "0  jelly survey nearby jellyfish ram pressure str...  \n",
              "1  spectroscopic survey bias halos reionization e...  \n",
              "2  aspecs spectral line survey udf large program ...  \n",
              "3  disk exoplanet c onnection protoplanetary disk...  \n",
              "4  imf transforms view origin stellar mass study ...  \n",
              "5  small scale substructure protoplanetary disk p...  \n",
              "6  exo detect planet embed natal protoplanetary d...  \n",
              "7  rebel large program discover luminous cii oiii...  \n",
              "8  early planet formation embed disk propose larg...  \n",
              "9  probe molecular gas miss puzzle piece baryon c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e32ec0-25f1-43ed-9690-14660179aa82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project_code</th>\n",
              "      <th>project_title</th>\n",
              "      <th>project_abstract</th>\n",
              "      <th>fs_type</th>\n",
              "      <th>science_category</th>\n",
              "      <th>science_keyword</th>\n",
              "      <th>band</th>\n",
              "      <th>target</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>standardized_text</th>\n",
              "      <th>no_sw_text</th>\n",
              "      <th>lemmatized_sw_text</th>\n",
              "      <th>lemmatized_no_sw_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021.1.01616.L</td>\n",
              "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
              "      <td>We propose the first ever statistical survey o...</td>\n",
              "      <td>line</td>\n",
              "      <td>Galaxy evolution</td>\n",
              "      <td>Surveys of galaxies, Galaxy groups and clusters</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
              "      <td>jelly survey of nearby jellyfish and ram press...</td>\n",
              "      <td>jelly survey nearby jellyfish ram pressure str...</td>\n",
              "      <td>jelly survey of nearby jellyfish and ram press...</td>\n",
              "      <td>jelly survey nearby jellyfish ram pressure str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022.1.01077.L</td>\n",
              "      <td>A SPectroscopic survey of biased halos In the ...</td>\n",
              "      <td>We propose to obtain deep ALMA 1.2mm mosaic ob...</td>\n",
              "      <td>line</td>\n",
              "      <td>Galaxy evolution</td>\n",
              "      <td>Sub-mm Galaxies (SMG), High-z Active Galactic ...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>A SPectroscopic survey of biased halos In the ...</td>\n",
              "      <td>a spectroscopic survey of biased halos in the ...</td>\n",
              "      <td>spectroscopic survey biased halos reionization...</td>\n",
              "      <td>a spectroscopic survey of biased halo in the r...</td>\n",
              "      <td>spectroscopic survey bias halos reionization e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016.1.00324.L</td>\n",
              "      <td>ASPECS: The ALMA SPECtral line Survey in the U...</td>\n",
              "      <td>ASPECS represents an unparalleled three-dimens...</td>\n",
              "      <td>line</td>\n",
              "      <td>Galaxy evolution</td>\n",
              "      <td>Lyman Break Galaxies (LBG)</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>ASPECS: The ALMA SPECtral line Survey in the U...</td>\n",
              "      <td>aspecs the spectral line survey in the udf an ...</td>\n",
              "      <td>aspecs spectral line survey udf large program ...</td>\n",
              "      <td>aspecs the spectral line survey in the udf an ...</td>\n",
              "      <td>aspecs spectral line survey udf large program ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022.1.00875.L</td>\n",
              "      <td>The ALMA Disk-Exoplanet C/Onnection</td>\n",
              "      <td>Protoplanetary disks set the initial compositi...</td>\n",
              "      <td>line</td>\n",
              "      <td>Disks and planet formation</td>\n",
              "      <td>Disks around low-mass stars, Exo-planets</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>The ALMA Disk-Exoplanet C/Onnection. Protoplan...</td>\n",
              "      <td>the disk exoplanet c onnection protoplanetary ...</td>\n",
              "      <td>disk exoplanet c onnection protoplanetary disk...</td>\n",
              "      <td>the disk exoplanet c onnection protoplanetary ...</td>\n",
              "      <td>disk exoplanet c onnection protoplanetary disk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017.1.01355.L</td>\n",
              "      <td>ALMA-IMF: ALMA transforms our view of the orig...</td>\n",
              "      <td>Studying massive protoclusters is an absolute ...</td>\n",
              "      <td>line</td>\n",
              "      <td>ISM and star formation</td>\n",
              "      <td>High-mass star formation, Low-mass star formation</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>ALMA-IMF: ALMA transforms our view of the orig...</td>\n",
              "      <td>imf transforms our view of the origin of stell...</td>\n",
              "      <td>imf transforms view origin stellar masses stud...</td>\n",
              "      <td>imf transform our view of the origin of stella...</td>\n",
              "      <td>imf transforms view origin stellar mass study ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016.1.00484.L</td>\n",
              "      <td>Small-Scale Substructures in Protoplanetary Disks</td>\n",
              "      <td>We propose a Large Program designed to charact...</td>\n",
              "      <td>line</td>\n",
              "      <td>Disks and planet formation</td>\n",
              "      <td>Disks around low-mass stars</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>Small-Scale Substructures in Protoplanetary Di...</td>\n",
              "      <td>small scale substructures in protoplanetary di...</td>\n",
              "      <td>small scale substructures protoplanetary disks...</td>\n",
              "      <td>small scale substructure in protoplanetary dis...</td>\n",
              "      <td>small scale substructure protoplanetary disk p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021.1.01123.L</td>\n",
              "      <td>exoALMA</td>\n",
              "      <td>Detecting planets embedded in their natal prot...</td>\n",
              "      <td>line</td>\n",
              "      <td>Disks and planet formation</td>\n",
              "      <td>Disks around low-mass stars, Exo-planets</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>exoALMA. Detecting planets embedded in their n...</td>\n",
              "      <td>exo detecting planets embedded in their natal ...</td>\n",
              "      <td>exo detecting planets embedded natal protoplan...</td>\n",
              "      <td>exo detect planet embed in their natal protopl...</td>\n",
              "      <td>exo detect planet embed natal protoplanetary d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2019.1.01634.L</td>\n",
              "      <td>REBELS: An ALMA Large Program to Discover the ...</td>\n",
              "      <td>REBELS will construct the first large statisti...</td>\n",
              "      <td>line</td>\n",
              "      <td>Galaxy evolution</td>\n",
              "      <td>Lyman Break Galaxies (LBG), Galaxy structure &amp;...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>REBELS: An ALMA Large Program to Discover the ...</td>\n",
              "      <td>rebels an large program to discover the most l...</td>\n",
              "      <td>rebels large program discover luminous cii oii...</td>\n",
              "      <td>rebel an large program to discover the most lu...</td>\n",
              "      <td>rebel large program discover luminous cii oiii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2019.1.00261.L</td>\n",
              "      <td>Early Planet Formation in Embedded Disks</td>\n",
              "      <td>We propose an ALMA Large Program to investigat...</td>\n",
              "      <td>line</td>\n",
              "      <td>Disks and planet formation</td>\n",
              "      <td>Disks around low-mass stars</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>Early Planet Formation in Embedded Disks. We p...</td>\n",
              "      <td>early planet formation in embedded disks we pr...</td>\n",
              "      <td>early planet formation embedded disks propose ...</td>\n",
              "      <td>early planet formation in embedded disk we pro...</td>\n",
              "      <td>early planet formation embed disk propose larg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2023.1.00127.L</td>\n",
              "      <td>Probing the molecular gas -- the missing puzzl...</td>\n",
              "      <td>The interactions between gas and galaxies are ...</td>\n",
              "      <td>line</td>\n",
              "      <td>Cosmology</td>\n",
              "      <td>Cosmic Microwave Background (CMB)/Sunyaev-Zel'...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>Probing the molecular gas -- the missing puzzl...</td>\n",
              "      <td>probing the molecular gas the missing puzzle p...</td>\n",
              "      <td>probing molecular gas missing puzzle piece bar...</td>\n",
              "      <td>probe the molecular gas the miss puzzle piece ...</td>\n",
              "      <td>probe molecular gas miss puzzle piece baryon c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e32ec0-25f1-43ed-9690-14660179aa82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88e32ec0-25f1-43ed-9690-14660179aa82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88e32ec0-25f1-43ed-9690-14660179aa82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e380fd9-e7e1-4acb-8cc2-b91a05074563\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e380fd9-e7e1-4acb-8cc2-b91a05074563')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e380fd9-e7e1-4acb-8cc2-b91a05074563 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "projects",
              "summary": "{\n  \"name\": \"projects\",\n  \"rows\": 4528,\n  \"fields\": [\n    {\n      \"column\": \"project_code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4528,\n        \"samples\": [\n          \"2021.1.01628.S\",\n          \"2011.0.00656.S\",\n          \"2013.1.00397.S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"project_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4183,\n        \"samples\": [\n          \"Ice in the embers: Testing the existence of cold molecular gas in a lensed compact quiescent galaxy at z=2.15\",\n          \"Through the magnifying glass: a unique view of the low-metallicity ISM at high redshift\",\n          \"Resolving the sub-arcsec structure surrounding the AGB star R Leo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"project_abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4445,\n        \"samples\": [\n          \"The main goal of this proposal is to shed light on the host galaxies of the most extreme AGN in the Universe. To this end, we selected two WISE/SDSS hyper-luminous (WISSH) QSOs at z~4.5, where winds and feedbacks are well developed. The main products of the proposed observations are: 1) assess whether the QSO host galaxies are in interaction with other nearby galaxies; 2) measure their dynamical mass; 3) given the known SFR, assess the position of the QSOs with respect to the galaxy main-sequence; 4) given the known SMBH masses, study their position in the SMBH mass - galaxy mass diagram; 5) search for any fast winds in the wings of the [CII] emission; 6) measure, or put a limit on the atomic/ionised wind mass loading factor Mdot_OF/SFR, and compare it to that of more normal AGN and star-forming galaxies. The two WISSH QSOs are selected to have: Lbol>~10^48 ergs/s, a robust SFR determination from Herschel, dec<+15 and a redshift fitting well in the ALMA band 7.\",\n          \"The radio quasar 3C 186 has been recently identified as an excellent candidate for a 'kicked' super-massive black hole, a scenario theoretically predicted to occur under certain conditions when two super-massive black holes coalesce after the merger of their host galaxies. The radio-loud QSO in 3C 186 is separated 1.3\\\" from the host galaxy isophotal center, and the broad emission lines appear blueshifted by 2100 km/s relative to the narrow lines. The currently favored explanation for these observations is that the broad line system tracks the kicked black hole (QSO), while the narrow-line system was left behind in the host galaxy. We propose to test this interpretation by mapping the system in CO(4-3) and CO(6-5) at high (0.1-0.16'') resolution, with the goal of tracing the exact location and redshift of the bulk of the cold gas reservoir, as well as determining the excitation state and extent of gas around the offset QSO. These observations are critical to understanding the history and dynamics of these rare extreme GW-recoil events, which result from anisotropic GW radiation during the BH-BH merger\",\n          \"Statistically-significant galaxy samples of the distant universe and reionization epoch have started to be revealed in the current JWST era. The knowledge on their molecular content is crucial to understand the star formation history of the universe. However, this is still unknown in the extremely metal-poor high-z environments. Here we propose to detect and map the molecular gas with the CO(1-0) in a selected subsample of metal-poor and low-mass local galaxies from the COS Legacy Archive Spectroscopic SurveY (CLASSY). CLASSY represents the first high-resolution spectral far-UV catalog of local star-forming galaxies, including high-z analogs, and also collecting multi-wavelength data, from the IR to the UV. CLASSY-CO will allow us to directly explore the connection between the molecular gas reservoir of these systems and the incident far-UV radiation as well as its connection with their interstellar medium properties. Our aim is to shed light on the role of CO as molecular gas diagnostic in high-z environments. Our study will allow to build an extremely powerful toolkit that will be pivotal for understanding the cold gas conditions of the earliest galaxies.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fs_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"continuum\",\n          \"line\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"science_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Solar system\",\n          \"Disks and planet formation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"science_keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 284,\n        \"samples\": [\n          \"Asymptotic Giant Branch (AGB) stars\",\n          \"Spiral galaxies, Outflows, jets, feedback\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"band\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"9\",\n          \"6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4461,\n        \"samples\": [\n          \"Dissecting the cold dust in the most massive AGN hosts. Using Spitzer, Herschel, SCUBA and LABOCA, we have obtained 12-band 3.6 to 850um photometry of 71 radio galaxies covering 1\",\n          \"Deep Dive into the ISM at z=6 with ALMA + JWST: From the Individual Lensed Star to 1-20pc Star-Forming Clumps. Recent HST and JWST/NIRCam studies have identified strongly lensed star clusters and even individual stars out to z=6, offering us new hope of directly observing such compact systems and their local environments at cosmological distances. Here we propose ALMA [CII]158um observations of the most highly magnified (mu~300) low-mass dwarf galaxy (2e9 Msun) hosting the strongly lensed star, Earendel (Welch+22, Nature), whose redshift has been confirmed at z=5.93 in the latest JWST/NIRSpec observations. In the 16\\\" long lensed arc, the recent NIRCam observations also map out diffuse ISM gas as well as several compact clumps that are the most distant known bound massive star clusters, with radii between 1 and 20pc, the size of local star clusters. This program aims to complete the initial FIR characterization from the full (~16\\\") lensed arc to the individual small clumps by obtaining their total fluxes and distributions of the [CII] emission line and the dust continuum via the combination of the compact and extended configurations. This is an essential step to design future further high-resolution follow-up to study e.g., even the rotation of the individual star clusters at z=6.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"standardized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4436,\n        \"samples\": [\n          \"building bridges large to small scale envelope structure around bhr in order to understand the formation of disks around protostars it is crucial to trace the kinematics of the rotating and infalling gas from the core and envelope scales pc down to the disk scales s au to date there are no complete studies linking the dynamics from scales pc down to au for a single system sma and ir studies have uncovered a nearby pc protostellar source forming within an isolated core bhr it has a marginally resolved disk in dust continuum with possible keplerian rotation and bipolar outflows indicative of active protostellar mass assembly this is an ideal archetypal source that is isolated near edge on enabling a unique opportunity to disentangle the kinematics of envelope infall disk rotation and outflows unlike many other sources we propose observations using the inner envelope and disk tracer c o and outer envelope tracer n h to map the inflow and angular momentum from the outer envelope down to the disk is the ideal facility able to image this archetypal system with simultanous high spatial spectral resolutions and high sensitivities to large angular scales\",\n          \"proving the agn feedback in the extremely ir bright dust obscured galaxies we aim to reveal the relation between the sf activity and the molecular gas outflow regarding the agn positive negative feedback in the extremely ir bright dust obscured galaxies dogs through the observations of co j co j as well as continuum observations the extremely ir bright dogs are a key population to understand the growing phase of the co evolution between galaxies and supermassive black holes investigating how the molecular gas outflow affects the sf activity in the ir bright dogs is crucial to tackle the mystery of the co evolution behind the dust combining the latest sdss data with wise data we discovered extremely ir bright dogs over the largest survey footprint so far among them we discovered four peculiar objects that show a clear outflow associated with ionized gasses oiii outflow in their optical spectra although whether or not the neutral molecular gasses are also associated with outflow for them we will investigate the spatial distribution and of dense and diffuse molecular gas as well as velocity distribution in addition we will investigate their sfr map derived from far ir luminosity based on continuum data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_sw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4433,\n        \"samples\": [\n          \"star formation one massive cluster z fuelled cooling flow spt cl j spt z among massive known galaxy clusters z bcg accompanied kpc long star forming filament identified hst rest frame uv images recent sz x ray radio studies revealed multiple mass gas components indicative recent cluster merger bcg located within cool x ray core strong radio jets along axis star forming filament observed spatial correlation filament cool core indicates starburst may triggered runaway cooling analogous cooling flow clusters low z one high z cluster found similar properties would tremendous find confirming runaway cooling following cluster merger could fuel star formation gyr ago alternatives include triggering wet merger bcg uplifted cold gas radio jets distinguish alternatives aim exploit unrivaled capabilities probe co emission spt constrain amount velocity structure molecular gas associated bcg\",\n          \"using ci map real structure low metallicity starburst low metallicity environments frequently exhibit starburst behavior forming stars massive clusters physical conditions molecular ism must dictate distinct mode star formation unfortunately typical tracer molecular ism co emission confined densest parts molecular clouds instead much molecular gas colocated atomic carbon propose using ci characterize molecular gas using superior resolution spatial spectral surface brightness sensitivity map bulk molecular clouds nearby low metallicity starburst ngc low metallicity environment expect larger fraction molecular gas traced ci instead co data measure properties molecular clouds low metallicity starburst establish connection molecular ism rich population young clusters imaged hubble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_sw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4434,\n        \"samples\": [\n          \"be the star formation in one of the most massive cluster at z fuel by a cooling flow spt cl j spt z be among the most massive know galaxy cluster at z and it bcg be accompany by a kpc long star form filament identify in hst rest frame uv image recent sz x ray and radio study have reveal multiple mass and gas component indicative of a recent cluster merger and that the bcg be locate within a cool x ray core with strong radio jet along the same axis a the star form filament the observed spatial correlation between the filament and cool core indicate that the starburst may be trigger by runaway cool analogous to cool flow cluster at low z a only one other high z cluster have be find with similar property this would be a tremendous find confirming that runaway cool follow the cluster merger could fuel star formation gyr ago alternative include trigger from a wet merger with the bcg or uplifted cold gas from the radio jet to distinguish between these alternative we aim to exploit s unrivaled capability to probe co emission from spt and to constrain the amount and velocity structure of the molecular gas associate with the bcg\",\n          \"use ci to map the real structure of a low metallicity starburst low metallicity environment frequently exhibit starburst behavior form most of their star in massive cluster the physical condition in the molecular ism must dictate this distinct mode of star formation unfortunately our typical tracer of the molecular ism co emission be confine to the dense part of molecular cloud instead much of the molecular gas be colocated with atomic carbon we propose use ci to characterize molecular gas use s superior resolution both spatial and spectral and surface brightness sensitivity to map the bulk of the molecular cloud in the nearby low metallicity starburst ngc in this low metallicity environment we expect a large fraction of the molecular gas to be trace by the ci instead of the co with these data we will measure the property of molecular cloud in a low metallicity starburst and establish the connection between the molecular ism and the rich population of young cluster image by hubble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_no_sw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4431,\n        \"samples\": [\n          \"heavily resolve molecular gas layer protoype edge galaxy ngc propose directly measure thickness molecular gas layer edge galaxy ngc measurement require high linear resolution high sensitivity k km channel width wide spatial coverage possible sensible integration time hour array thickness molecular gas layer important numerous study star formation e derive volume density molecular gas galaxy structure e comparison expectation hydrostatic equilibrium measurement would also important constraint study star formation efficiency per free fall time sample phangs large program previous measurement barely resolve vertical distribution molecular gas limited central region therefore propose overcome limitation observe whole stellar disk kpc radius finer resolution pc well sensitivity solar mass per square parsec\",\n          \"use ci map real structure low metallicity starburst low metallicity environment frequently exhibit starburst behavior form star massive cluster physical condition molecular ism must dictate distinct mode star formation unfortunately typical tracer molecular ism co emission confine dense part molecular cloud instead much molecular gas colocated atomic carbon propose use ci characterize molecular gas use superior resolution spatial spectral surface brightness sensitivity map bulk molecular cloud nearby low metallicity starburst ngc low metallicity environment expect large fraction molecular gas trace ci instead co data measure property molecular cloud low metallicity starburst establish connection molecular ism rich population young cluster image hubble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "projects.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB3_CZQIfmBf"
      },
      "outputs": [],
      "source": [
        "measurements = pd.read_csv('nrao_measurements_use.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRf3ViAbhPap"
      },
      "outputs": [],
      "source": [
        "measurements.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoWOHLirhRLs"
      },
      "outputs": [],
      "source": [
        "measurements.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FK_MUU7ilU6"
      },
      "source": [
        "## TARGET FROM NOAH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrY0IDXYhnak"
      },
      "outputs": [],
      "source": [
        "#TARGET FROM NOAH\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import plotly.express as px\n",
        "\n",
        "measurements = pd.read_csv('/content/nrao_measurements_use.csv')\n",
        "\n",
        "measurements = measurements[measurements.diff_freq < 5]\n",
        "lines = measurements.query('fs_type == \"line\"')\n",
        "lines = lines[['project_code', 'diff_freq', 'med_freq']]\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QJq1b66jmjq"
      },
      "outputs": [],
      "source": [
        "len(sorted(lines['diff_freq'].round(2).unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5BT_pAzikMh"
      },
      "outputs": [],
      "source": [
        "diffs = sorted(lines['diff_freq'].round(2).unique())\n",
        "meds = sorted(lines['med_freq'].round(2).unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Pffy-jfioxK"
      },
      "outputs": [],
      "source": [
        "def group_values_by_range(lst, group_size):\n",
        "    lst.sort()  # Sort the list first\n",
        "    ranges = []\n",
        "    start = lst[0]  # Start with the minimum value\n",
        "\n",
        "    while start < lst[-1]:\n",
        "        end = start + group_size\n",
        "        values_in_range = [val for val in lst if start <= val < end]\n",
        "        ranges.append([start, end])\n",
        "\n",
        "        # Move to the next value that's greater than the current end\n",
        "        start = next((val for val in lst if val >= end), lst[-1] + 1)\n",
        "\n",
        "    return ranges\n",
        "\n",
        "def build_range(med_vals, diff_vals=0.2, remove_imp= True):\n",
        "    '''\n",
        "    Returns ranges with the range set by med_vals and diff_vals\n",
        "    '''\n",
        "    diff_range = group_values_by_range(diffs, diff_vals)\n",
        "    med_range = group_values_by_range(meds, med_vals)\n",
        "\n",
        "    ranges = []\n",
        "    for item1 in diff_range:\n",
        "        for item2 in med_range :\n",
        "            ranges.append([item1, item2])\n",
        "\n",
        "    return ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbyAH_rziqVz"
      },
      "outputs": [],
      "source": [
        "def target_discretization(df, ranges):\n",
        "    '''\n",
        "    This function creates a new dataframe with project code and a new target variable vector,\n",
        "    which will represent the target probabilities of a given project code\n",
        "    to use for a machine learning model. It will discretize a large range of values (in this case, frequencies)\n",
        "    into categories set in the ranges parameter.\n",
        "\n",
        "    param df, pandas.dataframe: dataframe of measurements\n",
        "\n",
        "    param ranges, 2- D array: Nested list of ranges to sort values into for each project. The length\n",
        "    of the first dimension of this list will determine the length of the truth vector returned.\n",
        "    [[[0.05, 0.25], [36.08, 41.08]],]\n",
        "    '''\n",
        "    df_new = pd.DataFrame(columns=['project_code', 'target']) # new df to return\n",
        "    for pc in df.project_code.unique(): # loop through all line projects\n",
        "        truth_vals = [0 for _ in range(len(ranges))] # create initial truth value list\n",
        "        df_small = df[df['project_code'] == pc] # subset to correct observations\n",
        "        for i in range(len(df_small)): # loop through all oobservations\n",
        "            diff_f = df_small.iloc[i]['diff_freq']\n",
        "            med_f = df_small.iloc[i]['med_freq']\n",
        "            for a in range(len(ranges)): # Loop through ranges and match observation to range\n",
        "                if diff_f >= ranges[a][0][0] and diff_f < ranges[a][0][1] and \\\n",
        "                med_f >= ranges[a][1][0] and med_f < ranges[a][1][1]:\n",
        "                    truth_vals[a] = truth_vals[a] + 1 # add 1 for each observation in given range\n",
        "        pos = sum(truth_vals) # now we change to probabilities\n",
        "        for a in range(len(truth_vals)):\n",
        "            if truth_vals[a] != 0:\n",
        "                truth_vals[a] = truth_vals[a]/pos\n",
        "        df_new.loc[len(df_new)] = [pc, truth_vals] # append to return dataframe\n",
        "\n",
        "    return df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIbpRerIjUSF"
      },
      "outputs": [],
      "source": [
        "target = target_discretization(lines, build_range(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNXK1r8cjYsI"
      },
      "outputs": [],
      "source": [
        "target.iloc[0]['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp4TOEoeitRh"
      },
      "outputs": [],
      "source": [
        "target['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30qNwdlwiwQ-"
      },
      "outputs": [],
      "source": [
        "lines[lines['project_code'] == '2016.1.00854.S']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PM0Lldnixni"
      },
      "outputs": [],
      "source": [
        "target.iloc[123]['target'].index(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUiF6FopymDF"
      },
      "source": [
        "### TARGET: a vector representing the discretized frequency setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si2hG2a-o7E8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "measurements = pd.read_csv('/content/nrao_measurements_use.csv')\n",
        "\n",
        "# Preprocessing steps to filter the measurements and prepare the target variable\n",
        "measurements = measurements[measurements.diff_freq < 5]\n",
        "lines = measurements.query('fs_type == \"line\"')\n",
        "\n",
        "# Function to build range and target discretization is already defined\n",
        "\n",
        "# Assuming build_range and target_discretization functions are defined as provided\n",
        "ranges = build_range(5)  # Example range building with med_val = 5\n",
        "target_df = target_discretization(lines, ranges)\n",
        "\n",
        "# Combine project title and abstract into a single text column for the input\n",
        "# Assuming the project title and abstract are in 'measurements' DataFrame\n",
        "measurements['text'] = measurements['project_title'] + \" \" + measurements['project_abstract']\n",
        "\n",
        "# Merging the target vector into the measurements DataFrame\n",
        "# This involves ensuring each project code in 'measurements' matches its corresponding target vector in 'target_df'\n",
        "final_df = measurements.merge(target_df, on='project_code', how='inner')\n",
        "\n",
        "# The final_df DataFrame now contains the text data and the corresponding target variable vector for each project code\n",
        "final_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rygB4oxAo7c9"
      },
      "outputs": [],
      "source": [
        "print(final_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BKgi6a-pm48"
      },
      "source": [
        "This code block performs tokenization of the dataset text data, which will be the input for the BERT.\n",
        "\n",
        "Adjust number of tokens accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-PxxUObqHUH"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoXJQ0sqpTuV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Replace NaN values in the 'text' column with an empty string\n",
        "final_df['text'] = final_df['text'].fillna('')\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# ma\n",
        "# For every sentence...\n",
        "for sent in final_df.text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence\n",
        "    #   (2) Prepend the `[CLS]` token to the start\n",
        "    #   (3) Append the `[SEP]` token to the end\n",
        "    #   (4) Map tokens to their IDs\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 250,           # Pad & truncate all sentences\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding)\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(final_df['target_y'].tolist())\n",
        "\n",
        "print('Original: ', final_df.text[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G7i9p2EsVai"
      },
      "source": [
        "CLS and SEP are used in BERT models as markers to mark the beginning and the end of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASizdxFxsVDO"
      },
      "outputs": [],
      "source": [
        "# Splitting Data by 25%\n",
        "# Masks in BERT models indicate which tokens to pay attention to\n",
        "\n",
        "# train_inputs, validation_inputs: Tokenized and encoded text data split into training and validation sets.\n",
        "# train_labels, validation_labels: Corresponding labels for training and validation sets, representing the target frequency setups.\n",
        "# train_masks, validation_masks: Attention masks for training and validation sets to indicate which tokens the model should focus on.\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2018, test_size=0.25)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.25)\n",
        "\n",
        "print(\"Training Set:\", len(train_inputs))\n",
        "print(\"Validation Set:\", len(validation_inputs))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "id": "vqt-bQnmRp0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpWV22m_x551"
      },
      "source": [
        "Import DataLoaders to manage data during the training and evaluation phases, handling tasks like shuffling the data for training and creating iterable mini-batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgzkwf3SyCXX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for the training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for the validation set\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "print(\"Dataloaders created for training and validation sets.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfIy2CzZyb2d"
      },
      "source": [
        "### NOW WE LOAD THE PRE-TRAINED BERT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSxGGIMwzeu6"
      },
      "outputs": [],
      "source": [
        "num_classes = train_labels.shape[1]\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjusted_learning_rate = 5e-5\n",
        "num_training_steps = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * 0.1"
      ],
      "metadata": {
        "id": "iC0JbOhEsRKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_o4y710yGwS"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#     num_labels = 854, # The number of output labels--2 for binary classification.\n",
        "#                                         # You can increase this for multi-class tasks.\n",
        "#     output_attentions = False, # Whether the model returns attentions weights.\n",
        "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=num_classes,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "G1LE4lKX0TP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "iTEitD8n0XOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX06ct-iyZ2Q"
      },
      "source": [
        "### RUN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1)\n",
        "    labels_flat = np.argmax(labels, axis=1)\n",
        "    return np.mean(pred_flat == labels_flat)"
      ],
      "metadata": {
        "id": "ijDjAS0fsZft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# Now, before you start your training loop, define a starting time:\n",
        "t0 = time.time()\n"
      ],
      "metadata": {
        "id": "3Kh-P-WVsbGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def train_model(model, train_dataloader, epochs=4):\n",
        "    model.train()  # Put the model in training mode\n",
        "    for epoch_i in range(epochs):\n",
        "        print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "        print('Training...')\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0  # Initialize total accuracy for the epoch\n",
        "\n",
        "        for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            total_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        avg_train_accuracy = total_accuracy / len(train_dataloader)  # Calculate the average accuracy over all batches\n",
        "\n",
        "        print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "        print(f\"  Average training accuracy: {avg_train_accuracy:.2f}\")\n",
        "        # Optionally, you can add code here to track and print other metrics"
      ],
      "metadata": {
        "id": "ZV5flDk-scQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, validation_dataloader):\n",
        "    print(\"\\nRunning Validation...\")\n",
        "    model.eval()  # Put the model in evaluation mode\n",
        "    eval_accuracy = 0\n",
        "    nb_eval_steps = 0\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "    print(f\"  Accuracy: {eval_accuracy/nb_eval_steps:.2f}\")\n",
        "    # Optionally, add code here to calculate and print other metrics such as F1 score, if desired\n"
      ],
      "metadata": {
        "id": "L_WLDmIgsdkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, train_dataloader, epochs=4)"
      ],
      "metadata": {
        "id": "IdQB-laqse56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "validate_model(model, validation_dataloader, epochs=4)"
      ],
      "metadata": {
        "id": "RZLUmWe0sf0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}