{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cff5715-42a3-4d22-b465-24723d64143d",
   "metadata": {},
   "source": [
    "# Capstone Binary Classification Attempt\n",
    "Completed by following this [medium article](https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e)\n",
    "\n",
    "Noah McIntire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce6883-ced1-487f-95dd-76d112469515",
   "metadata": {},
   "source": [
    "## Imports and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd558e4-2d6e-417f-b11e-cad7eb49668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/noahmcintire/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/noahmcintire/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/noahmcintire/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/noahmcintire/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np #for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')#for model-building\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer#for word embedding\n",
    "# Word2Vec (may deal with this later)\n",
    "#! pip install gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8abc00ec-03fe-4706-b063-ecfad9ec7f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_code</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_abstract</th>\n",
       "      <th>fs_type</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.1.01205.L</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>The huge variety of planetary systems discover...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.1.00316.L</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>The emergence of complex organic molecules in ...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017.1.00161.L</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>A great variety in gas composition is observed...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.1.01616.L</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>We propose the first ever statistical survey o...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021.1.00869.L</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>A radio survey of red giant SiO sources in the...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     project_code                                      project_title  \\\n",
       "0  2018.1.01205.L  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "1  2022.1.00316.L  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2  2017.1.00161.L  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "3  2021.1.01616.L  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "4  2021.1.00869.L  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                    project_abstract fs_type  target  \\\n",
       "0  The huge variety of planetary systems discover...    line       1   \n",
       "1  The emergence of complex organic molecules in ...    line       1   \n",
       "2  A great variety in gas composition is observed...    line       1   \n",
       "3  We propose the first ever statistical survey o...    line       1   \n",
       "4  A radio survey of red giant SiO sources in the...    line       1   \n",
       "\n",
       "                                                text  \n",
       "0  Fifty AU STudy of the chemistry in the disk/en...  \n",
       "1  COMPASS: Complex Organic Molecules in Protosta...  \n",
       "2  ALCHEMI: the ALMA Comprehensive High-resolutio...  \n",
       "3  ALMA JELLY - Survey of Nearby Jellyfish and Ra...  \n",
       "4  Bulge symmetry or not? The hidden dynamics of ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nrao_projects.csv')\n",
    "df['target'] = pd.get_dummies(df['fs_type'], dtype=int)['line']\n",
    "df['text'] = df.project_title + \" \" + df.project_abstract\n",
    "df['text'] = df['text'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0c2511-6ecc-46bb-9daf-3e39dea5db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    3628\n",
      "0     900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x=df['target'].value_counts()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a3780a-53f7-4e70-a54f-9dd9d524b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a91256-d4a7-43cb-a77f-ed3605684ea2",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dff8bba-e85a-4f46-b6fd-ffdee55226d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    " \n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "252864c1-7521-48f8-8e1b-dcac8e297ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_code</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_abstract</th>\n",
       "      <th>fs_type</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.1.01205.L</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>The huge variety of planetary systems discover...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>fifty au study chemistry disk envelope system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.1.00316.L</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>The emergence of complex organic molecules in ...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>compass complex organic molecule protostars al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017.1.00161.L</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>A great variety in gas composition is observed...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>alchemi alma comprehensive high resolution ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.1.01616.L</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>We propose the first ever statistical survey o...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>alma jelly survey nearby jellyfish ram pressur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021.1.00869.L</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>A radio survey of red giant SiO sources in the...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>bulge symmetry hidden dynamic far side radio s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     project_code                                      project_title  \\\n",
       "0  2018.1.01205.L  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "1  2022.1.00316.L  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2  2017.1.00161.L  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "3  2021.1.01616.L  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "4  2021.1.00869.L  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                    project_abstract fs_type  target  \\\n",
       "0  The huge variety of planetary systems discover...    line       1   \n",
       "1  The emergence of complex organic molecules in ...    line       1   \n",
       "2  A great variety in gas composition is observed...    line       1   \n",
       "3  We propose the first ever statistical survey o...    line       1   \n",
       "4  A radio survey of red giant SiO sources in the...    line       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "1  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "3  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "4  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  fifty au study chemistry disk envelope system ...  \n",
       "1  compass complex organic molecule protostars al...  \n",
       "2  alchemi alma comprehensive high resolution ext...  \n",
       "3  alma jelly survey nearby jellyfish ram pressur...  \n",
       "4  bulge symmetry hidden dynamic far side radio s...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df_train['clean_text'] = df_train['text'].apply(lambda x: finalpreprocess(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a01d65-df18-4d3f-b306-7e49ba585eff",
   "metadata": {},
   "source": [
    "## Extracting Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68d58f66-59c0-4f91-a8e9-7c34a124b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[\"clean_text\"],df_train[\"target\"],test_size=0.2,shuffle=True)#Word2Vec\n",
    "# Word2Vec runs on tokenized sentences\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79f58e48-22fb-40fe-b126-90a92161dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "df['clean_text_tok']=[nltk.word_tokenize(i) for i in df['clean_text']]\n",
    "\n",
    "model = Word2Vec(df['clean_text_tok'],min_count=1) \n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors)) ## CHANGE model.wv._____\n",
    "\n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_test_vectors_w2v = modelw.transform(X_test_tok) # CHANGE var name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65d68e3a-227a-48c5-b07f-f89ff3db6f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68       180\n",
      "           1       0.91      0.96      0.93       726\n",
      "\n",
      "    accuracy                           0.89       906\n",
      "   macro avg       0.84      0.78      0.80       906\n",
      "weighted avg       0.88      0.89      0.88       906\n",
      "\n",
      "Confusion Matrix: [[108  72]\n",
      " [ 31 695]]\n",
      "AUC: 0.9005280073461892\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20372e20-ec70-4117-9592-6b31e178e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.46      0.55       180\n",
      "           1       0.88      0.95      0.91       726\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.79      0.70      0.73       906\n",
      "weighted avg       0.84      0.85      0.84       906\n",
      "\n",
      "Confusion Matrix: [[ 82  98]\n",
      " [ 36 690]]\n",
      "AUC: 0.8615013774104683\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression (W2v)\n",
    "lr_w2v=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v.fit(X_train_vectors_w2v, y_train) #model\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob = lr_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "066fd491-81db-4c2b-a09e-800d8eb370e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.09       180\n",
      "           1       0.81      1.00      0.89       726\n",
      "\n",
      "    accuracy                           0.81       906\n",
      "   macro avg       0.90      0.52      0.49       906\n",
      "weighted avg       0.85      0.81      0.73       906\n",
      "\n",
      "Confusion Matrix: [[  8 172]\n",
      " [  0 726]]\n",
      "AUC: 0.8582491582491583\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = nb_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = nb_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d16b298c-776b-4f41-968d-234d61cb79cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904     1\n",
       "1992    0\n",
       "1753    1\n",
       "147     1\n",
       "3249    1\n",
       "       ..\n",
       "703     1\n",
       "3499    1\n",
       "4306    1\n",
       "3236    1\n",
       "4308    1\n",
       "Name: target, Length: 906, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
