{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a73b598f-1104-4df8-90d9-c82df6eafe44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing copkmeans.egg-info\\PKG-INFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Documents\\DS 6013\\setup.py\", line 3, in <module>\n",
      "    setup(\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\__init__.py\", line 107, in setup\n",
      "    return distutils.core.setup(**attrs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "    return run_commands(dist)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "    dist.run_commands()\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "    self.run_command(cmd)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\dist.py\", line 1234, in run_command\n",
      "    super().run_command(command)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "    cmd_obj.run()\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\command\\install.py\", line 80, in run\n",
      "    self.do_egg_install()\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\command\\install.py\", line 129, in do_egg_install\n",
      "    self.run_command('bdist_egg')\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "    self.distribution.run_command(command)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\dist.py\", line 1234, in run_command\n",
      "    super().run_command(command)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "    cmd_obj.run()\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\command\\bdist_egg.py\", line 155, in run\n",
      "    self.run_command(\"egg_info\")\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "    self.distribution.run_command(command)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\dist.py\", line 1234, in run_command\n",
      "    super().run_command(command)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "    cmd_obj.run()\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 307, in run\n",
      "    writer(self, ep.name, os.path.join(self.egg_info, ep.name))\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 677, in write_pkg_info\n",
      "    metadata.write_pkg_info(cmd.egg_info)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 1137, in write_pkg_info\n",
      "    self.write_pkg_file(pkg_info)\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\dist.py\", line 191, in write_pkg_file\n",
      "    write_field('License', rfc822_escape(license))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anacondatake2\\Lib\\site-packages\\setuptools\\_distutils\\util.py\", line 511, in rfc822_escape\n",
      "    lines = header.split('\\n')\n",
      "            ^^^^^^^^^^^^\n",
      "AttributeError: '_Printer' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce6883-ced1-487f-95dd-76d112469515",
   "metadata": {},
   "source": [
    "## Imports and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dd558e4-2d6e-417f-b11e-cad7eb49668e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np #for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')#for model-building\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer#for word embedding\n",
    "# Word2Vec (may deal with this later)\n",
    "#! pip install gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from copkmeans.cop_kmeans import cop_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8abc00ec-03fe-4706-b063-ecfad9ec7f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>The huge variety of planetary systems discover...</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>The emergence of complex organic molecules in ...</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>A great variety in gas composition is observed...</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>We propose the first ever statistical survey o...</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>A radio survey of red giant SiO sources in the...</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       project_title  \\\n",
       "0  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "1  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "3  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "4  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                    project_abstract  \\\n",
       "0  The huge variety of planetary systems discover...   \n",
       "1  The emergence of complex organic molecules in ...   \n",
       "2  A great variety in gas composition is observed...   \n",
       "3  We propose the first ever statistical survey o...   \n",
       "4  A radio survey of red giant SiO sources in the...   \n",
       "\n",
       "                                                text  \n",
       "0  Fifty AU STudy of the chemistry in the disk/en...  \n",
       "1  COMPASS: Complex Organic Molecules in Protosta...  \n",
       "2  ALCHEMI: the ALMA Comprehensive High-resolutio...  \n",
       "3  ALMA JELLY - Survey of Nearby Jellyfish and Ra...  \n",
       "4  Bulge symmetry or not? The hidden dynamics of ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nrao_projects_unlabeled.csv')\n",
    "#df['target'] = pd.get_dummies(df['fs_type'], dtype=int)['line']\n",
    "df['text'] = df.project_title + df.project_abstract\n",
    "df['text'] = df['text'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12a3780a-53f7-4e70-a54f-9dd9d524b8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a91256-d4a7-43cb-a77f-ed3605684ea2",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dff8bba-e85a-4f46-b6fd-ffdee55226d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    " \n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "252864c1-7521-48f8-8e1b-dcac8e297ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>The huge variety of planetary systems discover...</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>fifty au study chemistry disk envelope system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>The emergence of complex organic molecules in ...</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>compass complex organic molecule protostars al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>A great variety in gas composition is observed...</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>alchemi alma comprehensive high resolution ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>We propose the first ever statistical survey o...</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>alma jelly survey nearby jellyfish ram pressur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>A radio survey of red giant SiO sources in the...</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>bulge symmetry hidden dynamic far sidea radio ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       project_title  \\\n",
       "0  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "1  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "3  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "4  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                    project_abstract  \\\n",
       "0  The huge variety of planetary systems discover...   \n",
       "1  The emergence of complex organic molecules in ...   \n",
       "2  A great variety in gas composition is observed...   \n",
       "3  We propose the first ever statistical survey o...   \n",
       "4  A radio survey of red giant SiO sources in the...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "1  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "3  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "4  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  fifty au study chemistry disk envelope system ...  \n",
       "1  compass complex organic molecule protostars al...  \n",
       "2  alchemi alma comprehensive high resolution ext...  \n",
       "3  alma jelly survey nearby jellyfish ram pressur...  \n",
       "4  bulge symmetry hidden dynamic far sidea radio ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df_train['clean_text'] = df_train['text'].apply(lambda x: finalpreprocess(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a01d65-df18-4d3f-b306-7e49ba585eff",
   "metadata": {},
   "source": [
    "## Extracting Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d58f66-59c0-4f91-a8e9-7c34a124b454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_train[\"clean_text\"],df_train[\"target\"],test_size=0.2,shuffle=True)#Word2Vec\n",
    "# Word2Vec runs on tokenized sentences\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in df_train[\"clean_text\"]]  \n",
    "#X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f58e48-22fb-40fe-b126-90a92161dded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(df_train) \n",
    "#X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "df['clean_text_tok']=[nltk.word_tokenize(i) for i in df['clean_text']]\n",
    "\n",
    "model = Word2Vec(df['clean_text_tok'],min_count=1) \n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors)) ## CHANGE model.wv._____\n",
    "\n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "#X_test_vectors_w2v = modelw.transform(X_test_tok) # CHANGE var name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93f6b51b-bdf4-4be2-9206-47207a61e3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43659714, -0.06955937,  0.01061684, ..., -0.24160674,\n",
       "         0.10435159, -0.14715746],\n",
       "       [-0.22946283, -0.0376877 ,  0.29437652, ..., -0.30333504,\n",
       "         0.32472518,  0.03589132],\n",
       "       [ 0.21404347,  0.25308576,  0.3628998 , ..., -0.23857297,\n",
       "         0.21672946,  0.04336225],\n",
       "       ...,\n",
       "       [-0.16680756,  0.27049297,  0.17251848, ...,  0.0441983 ,\n",
       "         0.08360934, -0.15190113],\n",
       "       [-0.13058499,  0.36921644,  0.07829084, ...,  0.11240532,\n",
       "        -0.00583314, -0.13323224],\n",
       "       [ 0.04436465,  0.2864441 ,  0.15862204, ..., -0.20103566,\n",
       "         0.09721981, -0.02091009]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93187d57-1e87-4a3a-b6b7-fe0b0522fd9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_matrix = X_train_vectors_tfidf\n",
    "must_link = [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), \n",
    "             (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), \n",
    "             (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), \n",
    "             (0, 22), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), \n",
    "             (0, 30), (0, 31), (0, 32), (0, 33), (0, 34), (0, 35), (0, 36), (0, 37), \n",
    "             (0, 38), (0, 39), (0, 40), (0, 41), (0, 42), (0, 43), (0, 44), \n",
    "             (0, 45), (0, 46), (0, 47), (0, 48), (0, 49), (0, 50), (0, 51), \n",
    "             (0, 52), (0, 53), (0, 54), (0, 55), (0, 56), (0, 57), (0, 58), \n",
    "             (0, 59), (0, 60), (0, 61), (0, 62), (0, 63), (0, 64), (0, 65), \n",
    "             (0, 66), (0, 67), (0, 68), (0, 69), (0, 70), (0, 71), (0, 72), \n",
    "             (0, 73), (0, 74), (0, 75), (0, 76), (0, 77), (0, 78), (0, 79), \n",
    "             (0, 80), (0, 81), (0, 82), (0, 83), (0, 84), (0, 85), (0, 86), (0, 87),\n",
    "             (0, 88), (0, 89), (0, 90)]\n",
    "cannot_link = [(0, 23), (0, 757), (0, 1123), (0, 1124), (0, 1125), (0, 1126),\n",
    "              (0, 1127), (0, 1128), (0, 1129), (0, 1130), (0, 1131), (0, 1132),\n",
    "              (0, 1133), (0, 1134), (0, 1135), (0, 1136), (0, 1137), (0, 1138),\n",
    "              (0, 1139), (0, 1140), (0, 1141), (0, 1142), (0, 1143), (0, 1144),\n",
    "              (0, 1145), (0, 1146), (0, 1147),(0, 1148), (0, 1149), (0, 1150),\n",
    "              (0, 1151), (0, 1152), (0, 1153), (0, 1154), (0, 1155), (0, 1156),\n",
    "              (0, 1157), (0, 1158), (0, 1159), (0, 1160), (0, 1161), (0, 1162),\n",
    "              (0, 1163), (0, 1164), (0, 1165), (0, 1166), (0, 1167), (0, 1168),\n",
    "              (0, 1169), (0, 1170), (0, 1171), (0, 1172), (0, 1173), (0, 1174),\n",
    "              (0, 1175), (0, 1176), (0, 1177),(0, 1178), (0, 1179), (0, 1180),\n",
    "              (0, 1181), (0, 1182), (0, 1183),(0, 1184), (0, 1185), (0, 1186),\n",
    "              (0, 1187), (0, 1188), (0, 1189), (0, 1190), (0, 1191), (0, 1192),\n",
    "              (0, 1193), (0, 1194), (0, 1195), (0, 1196), (0, 1197), (0, 1198),\n",
    "              (0, 1199), (0, 1200), (0, 1201), (0, 1202), (0, 1203), (0, 1204),\n",
    "              (0, 1205), (0, 1206), (0, 1207), (0, 1208), (0, 1209), (0, 1210)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80165094-bc06-4e2d-b3a1-cd2199d813e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse array length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clusters, centers \u001b[38;5;241m=\u001b[39m \u001b[43mcop_kmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmust_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcannot_link\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\DS 6013\\copkmeans\\cop_kmeans.py:8\u001b[0m, in \u001b[0;36mcop_kmeans\u001b[1;34m(dataset, k, ml, cl, initialization, max_iter, tol)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcop_kmeans\u001b[39m(dataset, k, ml\u001b[38;5;241m=\u001b[39m[], cl\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m      5\u001b[0m                initialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmpp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     ml, cl \u001b[38;5;241m=\u001b[39m transitive_closure(ml, cl, \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[0;32m      9\u001b[0m     ml_info \u001b[38;5;241m=\u001b[39m get_ml_info(ml, dataset)\n\u001b[0;32m     10\u001b[0m     tol \u001b[38;5;241m=\u001b[39m tolerance(tol, dataset)\n",
      "File \u001b[1;32m~\\anacondatake2\\Lib\\site-packages\\scipy\\sparse\\_base.py:340\u001b[0m, in \u001b[0;36m_spbase.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse array length is ambiguous; use getnnz()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    341\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or shape[0]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: sparse array length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "clusters, centers = cop_kmeans(dataset=input_matrix, k=2, ml=must_link,cl=cannot_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32a15060-3d11-4839-baa3-c9cd8e69c218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_df = pd.read_csv('nrao_projects.csv')\n",
    "for i in range(len(true_df)):\n",
    "    if true_df.iloc[i,3] == \"line\":\n",
    "        true_df.iloc[i,3] = 1\n",
    "    else:\n",
    "        true_df.iloc[i,3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c15f4b5-7d27-4300-a2f6-7ecc6a961308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(true_df.iloc[:,3] - clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dd7a0f4-3d19-4896-8386-0f45c1abea20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477031802120141"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(2048/len(true_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
