{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Data Discretization\n",
    "\n",
    "The goal of this notebook is to further explore options and develop a method/ function to discretize the possible frequency ranges to build targets for a deep learning/ other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to fix\n",
    "- Drop ranges that are \"Impossible\"- ranges that have not been observed at\n",
    "- probably convert to numpy for stuff instead of base pytho \n",
    "- return a matrix instead of a list/ vector of probabilities (this may not be necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "\n",
    "measurements = pd.read_csv('./nrao_measurements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_code</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_abstract</th>\n",
       "      <th>fs_type</th>\n",
       "      <th>low_freq</th>\n",
       "      <th>high_freq</th>\n",
       "      <th>target</th>\n",
       "      <th>diff_freq</th>\n",
       "      <th>med_freq</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>standardized_text</th>\n",
       "      <th>no_sw_text</th>\n",
       "      <th>lemmatized_sw_text</th>\n",
       "      <th>lemmatized_no_sw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011.0.00010.S</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>Centaurus A with its host NGC5128 is the most ...</td>\n",
       "      <td>line</td>\n",
       "      <td>90.38</td>\n",
       "      <td>90.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>90.500</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>the physics and chemisty of gas in centaurus a...</td>\n",
       "      <td>physics chemisty gas centaurus host v centauru...</td>\n",
       "      <td>the physic and chemisty of gas in centaurus a ...</td>\n",
       "      <td>physic chemisty gas centaurus host v centaurus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011.0.00010.S</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>Centaurus A with its host NGC5128 is the most ...</td>\n",
       "      <td>line</td>\n",
       "      <td>90.70</td>\n",
       "      <td>90.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>90.815</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>the physics and chemisty of gas in centaurus a...</td>\n",
       "      <td>physics chemisty gas centaurus host v centauru...</td>\n",
       "      <td>the physic and chemisty of gas in centaurus a ...</td>\n",
       "      <td>physic chemisty gas centaurus host v centaurus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011.0.00010.S</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>Centaurus A with its host NGC5128 is the most ...</td>\n",
       "      <td>line</td>\n",
       "      <td>91.69</td>\n",
       "      <td>91.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>91.805</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>the physics and chemisty of gas in centaurus a...</td>\n",
       "      <td>physics chemisty gas centaurus host v centauru...</td>\n",
       "      <td>the physic and chemisty of gas in centaurus a ...</td>\n",
       "      <td>physic chemisty gas centaurus host v centaurus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011.0.00010.S</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>Centaurus A with its host NGC5128 is the most ...</td>\n",
       "      <td>line</td>\n",
       "      <td>92.89</td>\n",
       "      <td>93.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>93.005</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>the physics and chemisty of gas in centaurus a...</td>\n",
       "      <td>physics chemisty gas centaurus host v centauru...</td>\n",
       "      <td>the physic and chemisty of gas in centaurus a ...</td>\n",
       "      <td>physic chemisty gas centaurus host v centaurus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011.0.00010.S</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>Centaurus A with its host NGC5128 is the most ...</td>\n",
       "      <td>line</td>\n",
       "      <td>217.59</td>\n",
       "      <td>218.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>218.060</td>\n",
       "      <td>The Physics and Chemisty of Gas in Centaurus A...</td>\n",
       "      <td>the physics and chemisty of gas in centaurus a...</td>\n",
       "      <td>physics chemisty gas centaurus host v centauru...</td>\n",
       "      <td>the physic and chemisty of gas in centaurus a ...</td>\n",
       "      <td>physic chemisty gas centaurus host v centaurus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67430</th>\n",
       "      <td>2023.A.00009.S</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>Recent JWST observations serendipitously revea...</td>\n",
       "      <td>line</td>\n",
       "      <td>345.20</td>\n",
       "      <td>345.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>345.435</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>finding t tracing the origins of rocky planete...</td>\n",
       "      <td>finding tracing origins rocky planetesimals jw...</td>\n",
       "      <td>find t trace the origin of rocky planetesimal ...</td>\n",
       "      <td>find trace origin rocky planetesimal jwst rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67431</th>\n",
       "      <td>2023.A.00009.S</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>Recent JWST observations serendipitously revea...</td>\n",
       "      <td>line</td>\n",
       "      <td>345.55</td>\n",
       "      <td>346.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>345.785</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>finding t tracing the origins of rocky planete...</td>\n",
       "      <td>finding tracing origins rocky planetesimals jw...</td>\n",
       "      <td>find t trace the origin of rocky planetesimal ...</td>\n",
       "      <td>find trace origin rocky planetesimal jwst rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67432</th>\n",
       "      <td>2023.A.00009.S</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>Recent JWST observations serendipitously revea...</td>\n",
       "      <td>line</td>\n",
       "      <td>346.02</td>\n",
       "      <td>346.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>346.490</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>finding t tracing the origins of rocky planete...</td>\n",
       "      <td>finding tracing origins rocky planetesimals jw...</td>\n",
       "      <td>find t trace the origin of rocky planetesimal ...</td>\n",
       "      <td>find trace origin rocky planetesimal jwst rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67433</th>\n",
       "      <td>2023.A.00009.S</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>Recent JWST observations serendipitously revea...</td>\n",
       "      <td>line</td>\n",
       "      <td>346.85</td>\n",
       "      <td>347.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>347.320</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>finding t tracing the origins of rocky planete...</td>\n",
       "      <td>finding tracing origins rocky planetesimals jw...</td>\n",
       "      <td>find t trace the origin of rocky planetesimal ...</td>\n",
       "      <td>find trace origin rocky planetesimal jwst rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67434</th>\n",
       "      <td>2023.A.00009.S</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>Recent JWST observations serendipitously revea...</td>\n",
       "      <td>line</td>\n",
       "      <td>344.01</td>\n",
       "      <td>344.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>344.240</td>\n",
       "      <td>Finding t=0: Tracing the Origins of Rocky Plan...</td>\n",
       "      <td>finding t tracing the origins of rocky planete...</td>\n",
       "      <td>finding tracing origins rocky planetesimals jw...</td>\n",
       "      <td>find t trace the origin of rocky planetesimal ...</td>\n",
       "      <td>find trace origin rocky planetesimal jwst rece...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67435 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         project_code                                      project_title  \\\n",
       "0      2011.0.00010.S  The Physics and Chemisty of Gas in Centaurus A...   \n",
       "1      2011.0.00010.S  The Physics and Chemisty of Gas in Centaurus A...   \n",
       "2      2011.0.00010.S  The Physics and Chemisty of Gas in Centaurus A...   \n",
       "3      2011.0.00010.S  The Physics and Chemisty of Gas in Centaurus A...   \n",
       "4      2011.0.00010.S  The Physics and Chemisty of Gas in Centaurus A...   \n",
       "...               ...                                                ...   \n",
       "67430  2023.A.00009.S  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67431  2023.A.00009.S  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67432  2023.A.00009.S  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67433  2023.A.00009.S  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67434  2023.A.00009.S  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "\n",
       "                                        project_abstract fs_type  low_freq  \\\n",
       "0      Centaurus A with its host NGC5128 is the most ...    line     90.38   \n",
       "1      Centaurus A with its host NGC5128 is the most ...    line     90.70   \n",
       "2      Centaurus A with its host NGC5128 is the most ...    line     91.69   \n",
       "3      Centaurus A with its host NGC5128 is the most ...    line     92.89   \n",
       "4      Centaurus A with its host NGC5128 is the most ...    line    217.59   \n",
       "...                                                  ...     ...       ...   \n",
       "67430  Recent JWST observations serendipitously revea...    line    345.20   \n",
       "67431  Recent JWST observations serendipitously revea...    line    345.55   \n",
       "67432  Recent JWST observations serendipitously revea...    line    346.02   \n",
       "67433  Recent JWST observations serendipitously revea...    line    346.85   \n",
       "67434  Recent JWST observations serendipitously revea...    line    344.01   \n",
       "\n",
       "       high_freq  target  diff_freq  med_freq  \\\n",
       "0          90.62       1       0.24    90.500   \n",
       "1          90.93       1       0.23    90.815   \n",
       "2          91.92       1       0.23    91.805   \n",
       "3          93.12       1       0.23    93.005   \n",
       "4         218.53       1       0.94   218.060   \n",
       "...          ...     ...        ...       ...   \n",
       "67430     345.67       1       0.47   345.435   \n",
       "67431     346.02       1       0.47   345.785   \n",
       "67432     346.96       1       0.94   346.490   \n",
       "67433     347.79       1       0.94   347.320   \n",
       "67434     344.47       1       0.46   344.240   \n",
       "\n",
       "                                                raw_text  \\\n",
       "0      The Physics and Chemisty of Gas in Centaurus A...   \n",
       "1      The Physics and Chemisty of Gas in Centaurus A...   \n",
       "2      The Physics and Chemisty of Gas in Centaurus A...   \n",
       "3      The Physics and Chemisty of Gas in Centaurus A...   \n",
       "4      The Physics and Chemisty of Gas in Centaurus A...   \n",
       "...                                                  ...   \n",
       "67430  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67431  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67432  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67433  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "67434  Finding t=0: Tracing the Origins of Rocky Plan...   \n",
       "\n",
       "                                       standardized_text  \\\n",
       "0      the physics and chemisty of gas in centaurus a...   \n",
       "1      the physics and chemisty of gas in centaurus a...   \n",
       "2      the physics and chemisty of gas in centaurus a...   \n",
       "3      the physics and chemisty of gas in centaurus a...   \n",
       "4      the physics and chemisty of gas in centaurus a...   \n",
       "...                                                  ...   \n",
       "67430  finding t tracing the origins of rocky planete...   \n",
       "67431  finding t tracing the origins of rocky planete...   \n",
       "67432  finding t tracing the origins of rocky planete...   \n",
       "67433  finding t tracing the origins of rocky planete...   \n",
       "67434  finding t tracing the origins of rocky planete...   \n",
       "\n",
       "                                              no_sw_text  \\\n",
       "0      physics chemisty gas centaurus host v centauru...   \n",
       "1      physics chemisty gas centaurus host v centauru...   \n",
       "2      physics chemisty gas centaurus host v centauru...   \n",
       "3      physics chemisty gas centaurus host v centauru...   \n",
       "4      physics chemisty gas centaurus host v centauru...   \n",
       "...                                                  ...   \n",
       "67430  finding tracing origins rocky planetesimals jw...   \n",
       "67431  finding tracing origins rocky planetesimals jw...   \n",
       "67432  finding tracing origins rocky planetesimals jw...   \n",
       "67433  finding tracing origins rocky planetesimals jw...   \n",
       "67434  finding tracing origins rocky planetesimals jw...   \n",
       "\n",
       "                                      lemmatized_sw_text  \\\n",
       "0      the physic and chemisty of gas in centaurus a ...   \n",
       "1      the physic and chemisty of gas in centaurus a ...   \n",
       "2      the physic and chemisty of gas in centaurus a ...   \n",
       "3      the physic and chemisty of gas in centaurus a ...   \n",
       "4      the physic and chemisty of gas in centaurus a ...   \n",
       "...                                                  ...   \n",
       "67430  find t trace the origin of rocky planetesimal ...   \n",
       "67431  find t trace the origin of rocky planetesimal ...   \n",
       "67432  find t trace the origin of rocky planetesimal ...   \n",
       "67433  find t trace the origin of rocky planetesimal ...   \n",
       "67434  find t trace the origin of rocky planetesimal ...   \n",
       "\n",
       "                                   lemmatized_no_sw_text  \n",
       "0      physic chemisty gas centaurus host v centaurus...  \n",
       "1      physic chemisty gas centaurus host v centaurus...  \n",
       "2      physic chemisty gas centaurus host v centaurus...  \n",
       "3      physic chemisty gas centaurus host v centaurus...  \n",
       "4      physic chemisty gas centaurus host v centaurus...  \n",
       "...                                                  ...  \n",
       "67430  find trace origin rocky planetesimal jwst rece...  \n",
       "67431  find trace origin rocky planetesimal jwst rece...  \n",
       "67432  find trace origin rocky planetesimal jwst rece...  \n",
       "67433  find trace origin rocky planetesimal jwst rece...  \n",
       "67434  find trace origin rocky planetesimal jwst rece...  \n",
       "\n",
       "[67435 rows x 14 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44230"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = measurements[measurements.diff_freq < 5]\n",
    "lines = measurements.query('fs_type == \"line\"')\n",
    "lines = lines[['project_code', 'diff_freq', 'med_freq']]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(lines['diff_freq'].round(2).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14800"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(lines['med_freq'].round(2).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44230"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.06,\n",
       " 0.07,\n",
       " 0.08,\n",
       " 0.09,\n",
       " 0.1,\n",
       " 0.11,\n",
       " 0.12,\n",
       " 0.13,\n",
       " 0.14,\n",
       " 0.15,\n",
       " 0.17,\n",
       " 0.18,\n",
       " 0.23,\n",
       " 0.24,\n",
       " 0.25,\n",
       " 0.26,\n",
       " 0.27,\n",
       " 0.28,\n",
       " 0.29,\n",
       " 0.3,\n",
       " 0.39,\n",
       " 0.46,\n",
       " 0.47,\n",
       " 0.48,\n",
       " 0.49,\n",
       " 0.5,\n",
       " 0.51,\n",
       " 0.52,\n",
       " 0.53,\n",
       " 0.59,\n",
       " 0.63,\n",
       " 0.93,\n",
       " 0.94,\n",
       " 0.95,\n",
       " 0.96,\n",
       " 0.97,\n",
       " 0.98,\n",
       " 0.99,\n",
       " 1.0,\n",
       " 1.01,\n",
       " 1.02,\n",
       " 1.03,\n",
       " 1.05,\n",
       " 1.06,\n",
       " 1.43,\n",
       " 1.86,\n",
       " 1.87,\n",
       " 1.88,\n",
       " 1.89,\n",
       " 1.9,\n",
       " 1.91,\n",
       " 1.92,\n",
       " 1.93,\n",
       " 1.94,\n",
       " 1.97,\n",
       " 1.98,\n",
       " 1.99,\n",
       " 2.0,\n",
       " 2.01,\n",
       " 2.02,\n",
       " 2.03,\n",
       " 2.04,\n",
       " 2.05,\n",
       " 2.06,\n",
       " 2.07,\n",
       " 2.08,\n",
       " 2.09,\n",
       " 2.1,\n",
       " 2.12,\n",
       " 2.13,\n",
       " 2.14,\n",
       " 2.15,\n",
       " 3.89]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lines['diff_freq'].round(2).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the greatest number of targets (when rounding to 2 decimal places) is 74 x 14800 = 1095200diffs = sorted(lines['diff_freq'].round(2).unique())\n",
    "meds = sorted(lines['med_freq'].round(2).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = sorted(lines['diff_freq'].round(2).unique())\n",
    "meds = sorted(lines['med_freq'].round(2).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below are to create the possible ranges based off desired windows.\n",
    "- group_values_by_range: helper function to create ranges for both median frequency and frequency difference. starts based off lowest unique value in above lists, and only creates \"ranges\" for possible values (i.e doesn't create windows where no project has an observation)\n",
    "- build_range: uses group_values_by_range for both median and difference in frequency and creates a list of lists, containing each \"box\" on the graph made in the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_values_by_range(lst, group_size):\n",
    "    lst.sort()  # Sort the list first\n",
    "    ranges = []\n",
    "    start = lst[0]  # Start with the minimum value\n",
    "\n",
    "    while start < lst[-1]:\n",
    "        end = start + group_size\n",
    "        values_in_range = [val for val in lst if start <= val < end]\n",
    "        ranges.append([start, end])\n",
    "        \n",
    "        # Move to the next value that's greater than the current end\n",
    "        start = next((val for val in lst if val >= end), lst[-1] + 1)\n",
    "        \n",
    "    return ranges\n",
    "\n",
    "def build_range(med_vals, diff_vals=0.2, remove_imp= True):\n",
    "    '''\n",
    "    Returns ranges with the range set by med_vals and diff_vals\n",
    "    '''\n",
    "    diff_range = group_values_by_range(diffs, diff_vals)\n",
    "    med_range = group_values_by_range(meds, med_vals)\n",
    "    \n",
    "    ranges = []\n",
    "    for item1 in diff_range:\n",
    "        for item2 in med_range :\n",
    "            ranges.append([item1, item2])\n",
    "    \n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to create a new table with new target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_discretization(df, ranges):\n",
    "    '''\n",
    "    This function creates a new dataframe with project code and a new target variable vector,\n",
    "    which will represent the target probabilities of a given project code\n",
    "    to use for a machine learning model. It will discretize a large range of values (in this case, frequencies)\n",
    "    into categories set in the ranges parameter.\n",
    "    \n",
    "    param df, pandas.dataframe: dataframe of measurements\n",
    "    \n",
    "    param ranges, 2- D array: Nested list of ranges to sort values into for each project. The length\n",
    "    of the first dimension of this list will determine the length of the truth vector returned.\n",
    "    [[[0.05, 0.25], [36.08, 41.08]],]\n",
    "    '''\n",
    "    df_new = pd.DataFrame(columns=['project_code', 'target']) # new df to return\n",
    "    for pc in df.project_code.unique(): # loop through all line projects\n",
    "        truth_vals = [0 for _ in range(len(ranges))] # create initial truth value list\n",
    "        df_small = df[df['project_code'] == pc] # subset to correct observations\n",
    "        for i in range(len(df_small)): # loop through all oobservations\n",
    "            diff_f = df_small.iloc[i]['diff_freq']\n",
    "            med_f = df_small.iloc[i]['med_freq']\n",
    "            for a in range(len(ranges)): # Loop through ranges and match observation to range\n",
    "                if diff_f >= ranges[a][0][0] and diff_f < ranges[a][0][1] and \\\n",
    "                med_f >= ranges[a][1][0] and med_f < ranges[a][1][1]:\n",
    "                    truth_vals[a] = truth_vals[a] + 1 # add 1 for each observation in given range\n",
    "        pos = sum(truth_vals) # now we change to probabilities\n",
    "        for a in range(len(truth_vals)):\n",
    "            if truth_vals[a] != 0:\n",
    "                truth_vals[a] = truth_vals[a]/pos\n",
    "        df_new.loc[len(df_new)] = [pc, truth_vals] # append to return dataframe\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target_discretization(lines, build_range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0.3,\n",
       " 0.2,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0,\n",
       " 0.2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.iloc[0]['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target.iloc[84]['target']) # sum to 1, good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target.iloc[0]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2400000000000091"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.iloc[0]['diff_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(build_range(5)) # yes! shape of target array should match number of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0, 0, 0, 0.3, 0.2, 0.05, 0.05, 0, 0.2, 0, 0, ...\n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                              ...                        \n",
       "3623    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3624    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3625    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3626    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3627    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: target, Length: 3628, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check to see if it correctly created probabilities for a random project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project_code                                       2016.1.00854.S\n",
       "target          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: 1234, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.iloc[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_code</th>\n",
       "      <th>diff_freq</th>\n",
       "      <th>med_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18518</th>\n",
       "      <td>2016.1.00854.S</td>\n",
       "      <td>1.87</td>\n",
       "      <td>228.435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         project_code  diff_freq  med_freq\n",
       "18518  2016.1.00854.S       1.87   228.435"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['project_code'] == '2016.1.00854.S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.iloc[1234]['target'].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.86, 2.06], [226.76, 231.76]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_range(5)[640]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textparser   # For potential use later\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_abstract</th>\n",
       "      <th>fs_type</th>\n",
       "      <th>target</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>standardized_text</th>\n",
       "      <th>no_sw_text</th>\n",
       "      <th>lemmatized_sw_text</th>\n",
       "      <th>lemmatized_no_sw_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018.1.01205.L</th>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>The huge variety of planetary systems discover...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>Fifty AU STudy of the chemistry in the disk/en...</td>\n",
       "      <td>fifty au study of the chemistry in the disk en...</td>\n",
       "      <td>fifty au study chemistry disk envelope system ...</td>\n",
       "      <td>fifty au study of the chemistry in the disk en...</td>\n",
       "      <td>fifty au study chemistry disk envelope system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022.1.00316.L</th>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>The emergence of complex organic molecules in ...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPASS: Complex Organic Molecules in Protosta...</td>\n",
       "      <td>compass complex organic molecules in protostar...</td>\n",
       "      <td>compass complex organic molecules protostars s...</td>\n",
       "      <td>compass complex organic molecule in protostars...</td>\n",
       "      <td>compass complex organic molecule protostars sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.1.00161.L</th>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>A great variety in gas composition is observed...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>ALCHEMI: the ALMA Comprehensive High-resolutio...</td>\n",
       "      <td>alchemi the comprehensive high resolution extr...</td>\n",
       "      <td>alchemi comprehensive high resolution extragal...</td>\n",
       "      <td>alchemi the comprehensive high resolution extr...</td>\n",
       "      <td>alchemi comprehensive high resolution extragal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.1.01616.L</th>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>We propose the first ever statistical survey o...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>ALMA JELLY - Survey of Nearby Jellyfish and Ra...</td>\n",
       "      <td>jelly survey of nearby jellyfish and ram press...</td>\n",
       "      <td>jelly survey nearby jellyfish ram pressure str...</td>\n",
       "      <td>jelly survey of nearby jellyfish and ram press...</td>\n",
       "      <td>jelly survey nearby jellyfish ram pressure str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.1.00869.L</th>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>A radio survey of red giant SiO sources in the...</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulge symmetry or not? The hidden dynamics of ...</td>\n",
       "      <td>bulge symmetry or not the hidden dynamics of t...</td>\n",
       "      <td>bulge symmetry hidden dynamics far side radio ...</td>\n",
       "      <td>bulge symmetry or not the hidden dynamic of th...</td>\n",
       "      <td>bulge symmetry hidden dynamic far side radio s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    project_title  \\\n",
       "project_code                                                        \n",
       "2018.1.01205.L  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "2022.1.00316.L  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2017.1.00161.L  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "2021.1.01616.L  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "2021.1.00869.L  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                                 project_abstract fs_type  \\\n",
       "project_code                                                                \n",
       "2018.1.01205.L  The huge variety of planetary systems discover...    line   \n",
       "2022.1.00316.L  The emergence of complex organic molecules in ...    line   \n",
       "2017.1.00161.L  A great variety in gas composition is observed...    line   \n",
       "2021.1.01616.L  We propose the first ever statistical survey o...    line   \n",
       "2021.1.00869.L  A radio survey of red giant SiO sources in the...    line   \n",
       "\n",
       "                target                                           raw_text  \\\n",
       "project_code                                                                \n",
       "2018.1.01205.L       1  Fifty AU STudy of the chemistry in the disk/en...   \n",
       "2022.1.00316.L       1  COMPASS: Complex Organic Molecules in Protosta...   \n",
       "2017.1.00161.L       1  ALCHEMI: the ALMA Comprehensive High-resolutio...   \n",
       "2021.1.01616.L       1  ALMA JELLY - Survey of Nearby Jellyfish and Ra...   \n",
       "2021.1.00869.L       1  Bulge symmetry or not? The hidden dynamics of ...   \n",
       "\n",
       "                                                standardized_text  \\\n",
       "project_code                                                        \n",
       "2018.1.01205.L  fifty au study of the chemistry in the disk en...   \n",
       "2022.1.00316.L  compass complex organic molecules in protostar...   \n",
       "2017.1.00161.L  alchemi the comprehensive high resolution extr...   \n",
       "2021.1.01616.L  jelly survey of nearby jellyfish and ram press...   \n",
       "2021.1.00869.L  bulge symmetry or not the hidden dynamics of t...   \n",
       "\n",
       "                                                       no_sw_text  \\\n",
       "project_code                                                        \n",
       "2018.1.01205.L  fifty au study chemistry disk envelope system ...   \n",
       "2022.1.00316.L  compass complex organic molecules protostars s...   \n",
       "2017.1.00161.L  alchemi comprehensive high resolution extragal...   \n",
       "2021.1.01616.L  jelly survey nearby jellyfish ram pressure str...   \n",
       "2021.1.00869.L  bulge symmetry hidden dynamics far side radio ...   \n",
       "\n",
       "                                               lemmatized_sw_text  \\\n",
       "project_code                                                        \n",
       "2018.1.01205.L  fifty au study of the chemistry in the disk en...   \n",
       "2022.1.00316.L  compass complex organic molecule in protostars...   \n",
       "2017.1.00161.L  alchemi the comprehensive high resolution extr...   \n",
       "2021.1.01616.L  jelly survey of nearby jellyfish and ram press...   \n",
       "2021.1.00869.L  bulge symmetry or not the hidden dynamic of th...   \n",
       "\n",
       "                                            lemmatized_no_sw_text  \n",
       "project_code                                                       \n",
       "2018.1.01205.L  fifty au study chemistry disk envelope system ...  \n",
       "2022.1.00316.L  compass complex organic molecule protostars sp...  \n",
       "2017.1.00161.L  alchemi comprehensive high resolution extragal...  \n",
       "2021.1.01616.L  jelly survey nearby jellyfish ram pressure str...  \n",
       "2021.1.00869.L  bulge symmetry hidden dynamic far side radio s...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects = pd.read_csv('nrao_projects.csv')\n",
    "projects = projects.set_index('project_code')\n",
    "projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3628, 9)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_projects = projects[projects['fs_type'] == 'line']\n",
    "line_projects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_no_sw_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018.1.01205.L</th>\n",
       "      <td>fifty au study chemistry disk envelope system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022.1.00316.L</th>\n",
       "      <td>compass complex organic molecule protostars sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.1.00161.L</th>\n",
       "      <td>alchemi comprehensive high resolution extragal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.1.01616.L</th>\n",
       "      <td>jelly survey nearby jellyfish ram pressure str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.1.00869.L</th>\n",
       "      <td>bulge symmetry hidden dynamic far side radio s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lemmatized_no_sw_text\n",
       "project_code                                                     \n",
       "2018.1.01205.L  fifty au study chemistry disk envelope system ...\n",
       "2022.1.00316.L  compass complex organic molecule protostars sp...\n",
       "2017.1.00161.L  alchemi comprehensive high resolution extragal...\n",
       "2021.1.01616.L  jelly survey nearby jellyfish ram pressure str...\n",
       "2021.1.00869.L  bulge symmetry hidden dynamic far side radio s..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_projects = line_projects[['lemmatized_no_sw_text']]\n",
    "line_projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aalto', 'ab', 'abandance', 'abandunce', 'abc', 'abell',\n",
       "       'aberrant', 'ability', 'ablate', 'ablation', 'ablative', 'able',\n",
       "       'abmag', 'abnormally', 'aboard', 'abode', 'aborption', 'abound',\n",
       "       'abrupt', 'abruptely', 'abruptly', 'absence', 'absent', 'absolute',\n",
       "       'absolutely', 'absorb', 'absorbed', 'absorber', 'absorbing',\n",
       "       'absorption', 'absortion', 'abstract', 'abundace', 'abundance',\n",
       "       'abundances', 'abundant', 'abundantly', 'abut', 'ac', 'aca',\n",
       "       'acccessible', 'accelerate', 'accelerated', 'acceleratedmaterial',\n",
       "       'accelerates', 'acceleration', 'accelerations', 'accelerator',\n",
       "       'accept', 'accepted', 'acces', 'access', 'accessibe',\n",
       "       'accessibility', 'accessible', 'accidentally', 'accociated',\n",
       "       'accommodate', 'accompany', 'accomplish', 'accord', 'accordingly',\n",
       "       'account', 'accountable', 'accounting', 'accreation', 'accrection',\n",
       "       'accrete', 'accretes', 'accreting', 'accretion', 'accretional',\n",
       "       'accross', 'accumulate', 'accumulated', 'accumulation', 'accuracy',\n",
       "       'accurate', 'accurately', 'accustom', 'ace', 'acetaldehyde',\n",
       "       'acetamide', 'acetonitrile', 'acfs', 'acheive', 'achievable',\n",
       "       'achieve', 'achievement', 'achive', 'achromaticity', 'acid',\n",
       "       'acomparison', 'acos', 'acquire', 'acquisition', 'acretion',\n",
       "       'across', 'act', 'action', 'activate', 'activation', 'active',\n",
       "       'actively', 'activites', 'activity', 'actor', 'actual', 'actually',\n",
       "       'ad', 'adapatation', 'adapt', 'adaptation', 'adapted', 'adaptive',\n",
       "       'add', 'addditional', 'added', 'addintion', 'addition',\n",
       "       'additional', 'additionally', 'address', 'addressed', 'addtion',\n",
       "       'adenine', 'adept', 'adequate', 'adequately', 'adf', 'adfs',\n",
       "       'adiabatic', 'adjacent', 'adjust', 'admit', 'admits', 'adopt',\n",
       "       'adress', 'adressed', 'adresses', 'adressing', 'advance',\n",
       "       'advanced', 'advancement', 'advantage', 'advect', 'advent',\n",
       "       'advocate', 'ae', 'aebe', 'aerial', 'aerosol', 'af', 'affair',\n",
       "       'affect', 'affected', 'affirmative', 'afflict', 'afford',\n",
       "       'affords', 'afgl', 'aforementioned', 'africa', 'afterglow',\n",
       "       'afterglows', 'aftermath', 'afterwards', 'ag', 'agains', 'agb',\n",
       "       'agbs', 'age', 'agent', 'aggregate', 'aggregation', 'agn', 'agns',\n",
       "       'ago', 'agree', 'agreement', 'ahead', 'aibs', 'aid', 'aim', 'aims',\n",
       "       'airborne', 'ak', 'aka', 'akari', 'akatski', 'akatsuki',\n",
       "       'akatuski', 'akin', 'al', 'ala', 'alactic', 'albedo', 'albeit',\n",
       "       'alchemi', 'alchemic', 'alcohol', 'aldose', 'ale', 'alens',\n",
       "       'aless', 'alf', 'alfalfa', 'alfocs', 'algorithm', 'alhtough',\n",
       "       'align', 'alignment', 'alike', 'aliphatic', 'aliphatics', 'alkyl',\n",
       "       'allegedly', 'alleviate', 'allo', 'allocate', 'allocation',\n",
       "       'allotrope', 'allotropes', 'allow', 'allows', 'almost', 'alo',\n",
       "       'aloh', 'alone', 'along', 'alongside', 'alpha', 'alphaco',\n",
       "       'alpine', 'alpps', 'already', 'also', 'alter', 'altered',\n",
       "       'alternately', 'alternative', 'alternatively', 'alterntively',\n",
       "       'alters', 'although', 'altitude', 'altitudes', 'altogether',\n",
       "       'alumina', 'aluminum', 'alves', 'always', 'amaze', 'amazing',\n",
       "       'amazingly', 'amber', 'ambient', 'ambients', 'ambiguity',\n",
       "       'ambiguous', 'ambipolar', 'ambitious', 'amd', 'ame', 'amenable',\n",
       "       'american', 'amid', 'amide', 'amiga', 'amine', 'amino', 'ammonia',\n",
       "       'ammounts', 'among', 'amongst', 'amorphous', 'amount', 'ample',\n",
       "       'amplification', 'amplified', 'amplify', 'amplitude', 'amplitudes',\n",
       "       'amply', 'analog', 'analogous', 'analogously', 'analogs',\n",
       "       'analogue', 'analogy', 'analyse', 'analysis', 'analysisin',\n",
       "       'analytic', 'analytical', 'analyze', 'analyzed', 'anatomy',\n",
       "       'ancestor', 'anchor', 'ancilary', 'ancillary', 'ancilliary',\n",
       "       'andd', 'anderson', 'andes', 'andrew', 'andromeda', 'andrÃ©',\n",
       "       'anecdote', 'anemic', 'anemone', 'angel', 'angle', 'angluar',\n",
       "       'angular', 'anion', 'anisotropic', 'anisotropy', 'anlyzed',\n",
       "       'announce', 'annular', 'anomalous', 'anomalously', 'anomaly',\n",
       "       'another', 'answer', 'ant', 'antenna', 'antennae', 'antennas',\n",
       "       'anti', 'anticenter', 'anticipate', 'anticipated',\n",
       "       'anticorrelated', 'anticorrelation', 'antlia', 'anxious',\n",
       "       'anymore', 'anything', 'anyway', 'ao', 'aots', 'apart',\n",
       "       'aperiodic', 'aperture', 'apex', 'apj', 'apjl', 'apo', 'apocenter',\n",
       "       'apogee', 'apolar', 'apparent', 'apparently', 'apparition',\n",
       "       'appeal', 'appear', 'appearance', 'appearence', 'apperarance',\n",
       "       'apple', 'applicability', 'applicable', 'applicated',\n",
       "       'application', 'applied', 'applies', 'apply', 'apportion',\n",
       "       'appreciable', 'appreciably', 'appreciate', 'approach',\n",
       "       'appropriate', 'appropriately', 'approve', 'approved', 'approx',\n",
       "       'approximate', 'approximately', 'approximation', 'apressure',\n",
       "       'april', 'aqr', 'aquarii', 'aqueously', 'aquila', 'aquilla', 'ar',\n",
       "       'arc', 'arce', 'arcec', 'arch', 'archetypal', 'archetype',\n",
       "       'archetypical', 'architectural', 'architecture', 'architectures',\n",
       "       'archival', 'archive', 'arcmin', 'arcminute', 'arcs', 'arcsec',\n",
       "       'arcsecond', 'arcseconds', 'arcseond', 'area', 'arefrozen',\n",
       "       'arepo', 'argonium', 'arguably', 'argue', 'argument', 'argus',\n",
       "       'arh', 'arise', 'arises', 'arising', 'arizona', 'ark', 'arks',\n",
       "       'arm', 'aro', 'aromatic', 'around', 'arounf', 'arp', 'arq',\n",
       "       'arrange', 'arrangement', 'array', 'arrival', 'arrive', 'art',\n",
       "       'artemis', 'article', 'artifact', 'arxiv', 'asai', 'asas',\n",
       "       'asassn', 'ascent', 'ascertain', 'asec', 'ash', 'asian', 'aside',\n",
       "       'ask', 'askap', 'aspecs', 'aspect', 'aspects', 'aspherical',\n",
       "       'aspire', 'ass', 'assemblage', 'assemble', 'assembly', 'assert',\n",
       "       'asses', 'assess', 'assessed', 'assessment', 'assign',\n",
       "       'assignment', 'assist', 'assisted', 'associate', 'associated',\n",
       "       'association', 'assume', 'assumed', 'assumes', 'assumption',\n",
       "       'assure', 'assymetric', 'aste', 'asteroid', 'asteroidal',\n",
       "       'asteroids', 'asthey', 'astonish', 'astonishingly', 'astound',\n",
       "       'astro', 'astrobiological', 'astrobiology', 'astrochemical',\n",
       "       'astrochemically', 'astrochemistry', 'astrochemists',\n",
       "       'astrometric', 'astrometrically', 'astrometry', 'astronomer',\n",
       "       'astronomical', 'astronomy', 'astrophysical', 'astrophysics',\n",
       "       'astrosat', 'asymetries', 'asymmetric', 'asymmetrical',\n",
       "       'asymmetrically', 'asymmetries', 'asymmetry', 'asympotic',\n",
       "       'asymptotic', 'asymptotoc', 'atacama', 'atca', 'atlas', 'atlasgal',\n",
       "       'atmosphere', 'atmospheres', 'atmospheric', 'atmospherically',\n",
       "       'atom', 'atomic', 'atomium', 'atoms', 'atreya', 'attack', 'attain',\n",
       "       'attainable', 'attemp', 'attempt', 'attention', 'attenuate',\n",
       "       'attenuated', 'attenuation', 'attract', 'attractive', 'attribute',\n",
       "       'attributed', 'atypical', 'atypically', 'au', 'aug', 'auger',\n",
       "       'augment', 'august', 'aur', 'aurigae', 'auroral', 'aus',\n",
       "       'auseparations', 'australia', 'australian', 'australis', 'author',\n",
       "       'authoritative', 'autocorrelation', 'auxiliary', 'av',\n",
       "       'availability', 'available', 'avenue', 'avenues', 'average',\n",
       "       'averaged', 'avert', 'avoid', 'avoids', 'await', 'awaited',\n",
       "       'award', 'aware', 'away', 'ax', 'axi', 'axial', 'aximuthal',\n",
       "       'axion', 'axionic', 'axions', 'axis', 'axisymmetric',\n",
       "       'axisymmetry', 'az', 'azimuth', 'azimuthal', 'azimuthally',\n",
       "       'aztec', 'baade', 'baby', 'back', 'backbone', 'backdrop',\n",
       "       'background', 'backlight', 'backyard', 'bad', 'badgrs', 'badly',\n",
       "       'balance', 'balanced', 'balancing', 'balck', 'ballistic',\n",
       "       'balloon', 'bally', 'balmer', 'balqsos', 'band', 'bandhead',\n",
       "       'bandheads', 'bandpass', 'bandwidth', 'bandwidths', 'bang',\n",
       "       'bania', 'bank', 'banzatti', 'bar', 'bare', 'barely', 'barnard',\n",
       "       'barred', 'barrel', 'barrier', 'baryon', 'baryonic', 'base',\n",
       "       'basebands', 'baseline', 'basic', 'basically', 'basis', 'bass',\n",
       "       'bat', 'bate', 'battersby', 'battlefield', 'bayesian', 'bbh',\n",
       "       'bbn', 'bcd', 'bcds', 'bcg', 'bcgs', 'bd', 'bdf', 'bds', 'beacon',\n",
       "       'bead', 'beam', 'beamsize', 'bear', 'bearing', 'beat', 'beautiful',\n",
       "       'beautifully', 'becklin', 'become', 'becomes', 'bed', 'bedrock',\n",
       "       'beem', 'beetter', 'beforehand', 'begin', 'beginning', 'behave',\n",
       "       'behaves', 'behavior', 'behaviour', 'behind', 'beleived',\n",
       "       'beliefs', 'believe', 'belong', 'belonging', 'belt', 'benchmark',\n",
       "       'benchmarked', 'benchmarking', 'benchmarks', 'bend', 'beneath',\n",
       "       'beneficial', 'benefit', 'benign', 'bent', 'benzene', 'beside',\n",
       "       'besides', 'best', 'bet', 'beta', 'betelgeuse', 'betelguese',\n",
       "       'betray', 'better', 'betweeen', 'betweem', 'beuther', 'beyond',\n",
       "       'bf', 'bgps', 'bh', 'bhb', 'bhr', 'bhs', 'bhxb', 'bhxbs', 'bi',\n",
       "       'bias', 'biased', 'biconical', 'big', 'billion', 'bima', 'bimodal',\n",
       "       'bimodality', 'bin', 'binares', 'binarity', 'binary', 'bind',\n",
       "       'binding', 'bio', 'biochemical', 'biochemistry', 'bioelement',\n",
       "       'biological', 'biologically', 'biology', 'biomarker', 'biomarkers',\n",
       "       'biomolecules', 'biosignature', 'biosphere', 'biotic', 'bipolar',\n",
       "       'bipolarity', 'bird', 'birth', 'birthline', 'birthplace',\n",
       "       'birthsite', 'birthsites', 'bistro', 'bisymmetric', 'bit',\n",
       "       'bizzare', 'bl', 'black', 'blackbody', 'blackhole', 'blackholes',\n",
       "       'blackman', 'blame', 'bland', 'blandford', 'blank', 'blanketing',\n",
       "       'blast', 'blastpol', 'blazar', 'blazars', 'blaze', 'blend',\n",
       "       'bless', 'blg', 'blind', 'blindly', 'bllac', 'bloat', 'blob',\n",
       "       'block', 'blow', 'blowin', 'blown', 'blr', 'blue', 'blueshifted',\n",
       "       'bluk', 'blur', 'bn', 'board', 'body', 'boizelle', 'bok', 'bol',\n",
       "       'bolatto', 'bold', 'bolo', 'bolocam', 'bolometric',\n",
       "       'bolometrically', 'bolster', 'boltzmann', 'bombardment', 'bona',\n",
       "       'bonafide', 'bond', 'bondi', 'bone', 'bonnell', 'bonner', 'bonus',\n",
       "       'book', 'bookended', 'boom', 'boomerang', 'boost', 'boosting',\n",
       "       'booth', 'bop', 'bopp', 'border', 'borisov', 'born', 'borne',\n",
       "       'bottleneck', 'bottom', 'boulder', 'bound', 'boundary',\n",
       "       'boundedness', 'boundness', 'bounty', 'bout', 'bovino', 'bow',\n",
       "       'bowl', 'box', 'boyajian', 'bp', 'bpi', 'bpmg', 'br', 'braid',\n",
       "       'brake', 'braking', 'branch', 'branched', 'brand', 'breadth',\n",
       "       'break', 'breakdown', 'breaking', 'breakthrough', 'breakup',\n",
       "       'breed', 'breeding', 'bremsstrahlung', 'breuck', 'brg', 'bri',\n",
       "       'brick', 'bridge', 'brief', 'briefly', 'brighest', 'bright',\n",
       "       'brighten', 'brightened', 'brightening', 'brighter', 'brightest',\n",
       "       'brightly', 'brightness', 'brightnesses', 'brigth', 'brigtness',\n",
       "       'bring', 'brink', 'broad', 'broadband', 'broaden', 'broadening',\n",
       "       'broader', 'broadly', 'broken', 'brown', 'bubble', 'budget',\n",
       "       'buffer', 'build', 'building', 'buildup', 'bulge', 'bulgeless',\n",
       "       'bulk', 'bullet', 'bulleted', 'bump', 'bundle', 'bundy',\n",
       "       'buoyantly', 'bure', 'buried', 'burillo', 'burn', 'burning',\n",
       "       'burried', 'burst', 'bury', 'butler', 'butterfield', 'butterfly',\n",
       "       'butyl', 'bw', 'bx', 'byond', 'bypass', 'byproduct', 'bz', 'ca',\n",
       "       'cadence', 'caha', 'caii', 'cairn', 'cake', 'calculate',\n",
       "       'calculation', 'calibrate', 'calibrated', 'calibrating',\n",
       "       'calibration', 'calibrator', 'calibrators', 'califa', 'call',\n",
       "       'callisto', 'calm', 'calmonte', 'calorimetry', 'calypso', 'cam',\n",
       "       'campaign', 'can', 'cancel', 'cancellation', 'candels',\n",
       "       'candidate', 'candle', 'canis', 'canonical', 'canyon', 'cao',\n",
       "       'caoh', 'cap', 'capability', 'capable', 'capablities', 'capacity',\n",
       "       'capitalise', 'capitalize', 'capture', 'car', 'carbide', 'carbon',\n",
       "       'carbonaceous', 'carboxilic', 'careful', 'carefully', 'carina',\n",
       "       'carinae', 'carlo', 'carma', 'carniae', 'carninae', 'carrasco',\n",
       "       'carried', 'carrier', 'carroll', 'carry', 'cartwheel', 'carve',\n",
       "       'carved', 'carving', 'casa', 'cascade', 'case', 'cash', 'cassini',\n",
       "       'cast', 'casted', 'castellano', 'cat', 'cataclysmic', 'cataldi',\n",
       "       'catalog', 'catalogue', 'catalysis', 'catalyst', 'catalytic',\n",
       "       'catastrophe', 'catastrophic', 'catch', 'categorically',\n",
       "       'category', 'cation', 'caught', 'causal', 'causality', 'causally',\n",
       "       'cause', 'caused', 'caustic', 'cavity', 'cb', 'cc', 'ccc', 'cccs',\n",
       "       'cch', 'ccms', 'ccn', 'ccp', 'ccs', 'cd', 'cdf', 'cdfs', 'cdm',\n",
       "       'ce', 'cease', 'cee', 'celestial', 'cell', 'cen', 'cena', 'census',\n",
       "       'cent', 'centaral', 'centarus', 'centaur', 'centaurs', 'centaurus',\n",
       "       'center', 'centimeter', 'centimetre', 'central', 'centralize',\n",
       "       'centralized', 'centrally', 'centre', 'centric', 'centrifugal',\n",
       "       'centrifugally', 'centroid', 'century', 'cepheid', 'cepheids',\n",
       "       'cere', 'cernicharo', 'certain', 'certainly', 'cesaroni',\n",
       "       'cessation', 'cet', 'ceti', 'cf', 'cfa', 'cfe', 'cgm', 'cgms',\n",
       "       'ch', 'cha', 'chain', 'challenge', 'challenging', 'cham',\n",
       "       'chamaeleon', 'chamaeleontis', 'chameleon', 'chameleonis', 'champ',\n",
       "       'chance', 'chandra', 'chandrasekhar', 'chang', 'change', 'channel',\n",
       "       'chaotic', 'chapter', 'character', 'characterisation',\n",
       "       'characterise', 'characterised', 'characterisic', 'characteristic',\n",
       "       'characterization', 'characterize', 'characterized',\n",
       "       'characterizing', 'characterstics', 'charaterisation', 'charbon',\n",
       "       'charge', 'chariklo', 'charon', 'chart', 'chase', 'chcn',\n",
       "       'cheaply', 'check', 'chemcail', 'chemial', 'chemical',\n",
       "       'chemically', 'chemistry', 'chemisty', 'chemo', 'chemodynamical',\n",
       "       'chemsitry', 'cherchneff', 'cherry', 'cheung', 'chicken', 'chief',\n",
       "       'chiefly', 'child', 'chilean', 'chill', 'chiral', 'chloride',\n",
       "       'chlorine', 'chlorinity', 'chnops', 'cho', 'choice', 'chondrites',\n",
       "       'chondritic', 'chondrules', 'choose', 'chose', 'chosen',\n",
       "       'chromatic', 'chromosphere', 'chromospheres', 'chromospheric',\n",
       "       'chronology', 'churn', 'churyumov', 'ci', 'cicone', 'cid', 'cida',\n",
       "       'cieza', 'cii', 'cimatti', 'circ', 'circimbinary',\n",
       "       'circimplanetary', 'circinus', 'circle', 'circular', 'circularize',\n",
       "       'circularly', 'circulation', 'circum', 'circumbinaries',\n",
       "       'circumbinary', 'circumburst', 'circumgalactic', 'circumnuclear',\n",
       "       'circumnucler', 'circumplanetary', 'circumplanetry',\n",
       "       'circumprimary', 'circumprotostellar', 'circumsecondary',\n",
       "       'circumstance', 'circumstantial', 'circumstellar', 'circumtriple',\n",
       "       'circumvent', 'circumvents', 'ciritical', 'cirs', 'cirumbinary',\n",
       "       'cirumnuclear', 'cirumprimary', 'cirumstellar', 'cis', 'cit',\n",
       "       'civ', 'cj', 'ck', 'cl', 'claim', 'claimed', 'clancy',\n",
       "       'clarification', 'clarifing', 'clarify', 'clarity', 'clash',\n",
       "       'clasical', 'class', 'classic', 'classical', 'classification',\n",
       "       'classified', 'classify', 'classy', 'clcox', 'clean', 'cleanly',\n",
       "       'clear', 'cleared', 'clearest', 'clearing', 'clearly', 'climate',\n",
       "       'climatic', 'clj', 'clo', 'cloak', 'clock', 'clog', 'close',\n",
       "       'closely', 'closeness', 'closer', 'closest', 'closure', 'cloud',\n",
       "       'cloudless', 'cloudlet', 'cloudlets', 'clouds', 'cloudy', 'clould',\n",
       "       'cloverleaf', 'clox', 'clue', 'clueter', 'clump', 'clumpiness',\n",
       "       'clumps', 'clumpy', 'cluste', 'cluster', 'clustered', 'clustering',\n",
       "       'clutered', 'clycle', 'cm', 'cma', 'cmb', 'cmc', 'cmcs', 'cmf',\n",
       "       'cmfs', 'cmm', 'cmpc', 'cmz', 'cmzoom', 'cmzs', 'cn', 'cnd',\n",
       "       'cnds', 'cnm', 'cno', 'cnr', 'cnrs', 'co', 'coagulate',\n",
       "       'coagulation', 'coalesce', 'coalescence', 'coalescent', 'coarse',\n",
       "       'coarser', 'coat', 'coccon', 'coch', 'cocoa', 'cocoon', 'code',\n",
       "       'codella', 'coefficient', 'coeval', 'coevolution', 'coexist',\n",
       "       'coexistence', 'coexistent', 'coexists', 'coherence', 'coherent',\n",
       "       'coil', 'coincide', 'coincidence', 'coincident', 'coincidentally',\n",
       "       'coincides', 'coj', 'cola', 'cold', 'colder', 'coldest',\n",
       "       'coldgass', 'coldz', 'collaboration', 'collaborative', 'collapse',\n",
       "       'collapsing', 'collect', 'collection', 'collectively', 'collide',\n",
       "       'collimate', 'collimated', 'collimation', 'collinear', 'collision',\n",
       "       'collisional', 'collisionally', 'colocated', 'color', 'colossal',\n",
       "       'colour', 'colum', 'columinous', 'column', 'com', 'coma',\n",
       "       'comapred', 'combes', 'combination', 'combine', 'combined',\n",
       "       'combining', 'combustion', 'come', 'comet', 'cometary', 'comets',\n",
       "       'comfirm', 'comic', 'comm', 'commensal', 'commensurate', 'comment',\n",
       "       'commisioning', 'commission', 'commit', 'committee', 'common',\n",
       "       'commonality', 'commonly', 'communication', 'community',\n",
       "       'comoving', 'compact', 'compaction', 'compactness', 'companion',\n",
       "       'companionship', 'company', 'comparable', 'comparably',\n",
       "       'comparative', 'compare', 'comparing', 'comparison', 'comparitive',\n",
       "       'compass', 'compatible', 'compel', 'compelling', 'compellingly',\n",
       "       'compensate', 'compete', 'competition', 'competitive',\n",
       "       'competitively', 'compilation', 'compile', 'complement',\n",
       "       'complementarily', 'complementary', 'complete', 'completely',\n",
       "       'completeness', 'completes', 'completion', 'complex', 'complexes',\n",
       "       'complexity', 'complicate', 'complicated', 'complication',\n",
       "       'compliment', 'complimentary', 'compoenent', 'componenet',\n",
       "       'component', 'compose', 'composed', 'composite', 'composition',\n",
       "       'compositional', 'compositionin', 'compoton', 'compound',\n",
       "       'comprehension', 'comprehensive', 'comprehensively', 'compress',\n",
       "       'compressed', 'compression', 'compressive', 'comprise',\n",
       "       'comprises', 'comprising', 'compromise', 'compsositions',\n",
       "       'compton', 'compute', 'coms', 'con', 'concave', 'conceal',\n",
       "       'conceivable', 'concentrate', 'concentrated', 'concentration',\n",
       "       'concentric', 'concept', 'conceptualize', 'concern', 'concerned',\n",
       "       'concert', 'concetration', 'conclude', 'conclusion', 'conclusive',\n",
       "       'conclusively', 'concomitance', 'concomitant', 'concrete',\n",
       "       'concurrent', 'concurrently', 'condensation', 'condense',\n",
       "       'condenses', 'condidates', 'condirtion', 'conditins', 'condition',\n",
       "       'condtions', 'conducive', 'conduct', 'conducted', 'conductivity',\n",
       "       'conduit', 'cone', 'conf', 'confidence', 'confident',\n",
       "       'confidently', 'config', 'configuration', 'configuretion',\n",
       "       'confimation', 'confine', 'confined', 'confinement', 'confirm',\n",
       "       'confirmation', 'confirmed', 'conflict', 'conform', 'conformity',\n",
       "       'confound', 'confront', 'confuse', 'confused', 'confusion',\n",
       "       'conic', 'conical', 'conjecture', 'conjunction', 'conjunctionwith',\n",
       "       'connect', 'connected', 'connecting', 'connection', 'connects',\n",
       "       'connexion', 'conscious', 'consecutive', 'consensus',\n",
       "       'consequence', 'consequences', 'consequently', 'conservation',\n",
       "       'conservative', 'conserve', 'consider', 'considerable',\n",
       "       'considerably', 'considers', 'consist', 'consistency',\n",
       "       'consistent', 'consistentency', 'consistently', 'consists',\n",
       "       'consolidate', 'consortium', 'conspicuous', 'constant',\n",
       "       'constantly', 'constituent', 'constitute', 'constitutes',\n",
       "       'constitution', 'constrain', 'constrained', 'constraing',\n",
       "       'constraining', 'constrains', 'constrainst', 'constraint',\n",
       "       'constraints', 'construct', 'construction', 'consume',\n",
       "       'consumption', 'contact', 'contain', 'contains', 'contaminant',\n",
       "       'contaminate', 'contaminates', 'contamination', 'contemporaneous',\n",
       "       'contemporaneously', 'contemporary', 'contend', 'contender',\n",
       "       'content', 'contentious', 'context', 'contextualize', 'contiguous',\n",
       "       'continnium', 'continnum', 'continually', 'continuation',\n",
       "       'continue', 'continued', 'continumm', 'continuous', 'continuously',\n",
       "       'continuum', 'contiuum', 'contour', 'contract', 'contraction',\n",
       "       'contradict', 'contradiction', 'contradictory', 'contradicts',\n",
       "       'contraints', 'contrary', 'contrast', 'contraversial',\n",
       "       'contribuites', 'contribute', 'contributes', 'contribution',\n",
       "       'contributor', 'control', 'controlled', 'controversial',\n",
       "       'controversy', 'conundrum', 'convection', 'convective',\n",
       "       'convenction', 'convenient', 'conveniently', 'conventional',\n",
       "       'converge', 'convergence', 'convergent', 'converging',\n",
       "       'convergnet', 'conversely', 'conversion', 'convert', 'converting',\n",
       "       'convey', 'conveyor', 'convincingly', 'convinving', 'coo', 'cooh',\n",
       "       'cook', 'cooked', 'cool', 'coolant', 'cooled', 'cooler', 'cooling',\n",
       "       'cooperative', 'coordinate', 'coordinated', 'coordination',\n",
       "       'copious', 'coplanar', 'cor', 'cordiner', 'core', 'corino',\n",
       "       'corinos', 'cornerstone', 'cornish', 'corona', 'coronagraphic',\n",
       "       'coronal', 'coronography', 'corotate', 'corranulene', 'correct',\n",
       "       'correction', 'correctly', 'correlate', 'correlated',\n",
       "       'correlation', 'correlator', 'correponding', 'correspond',\n",
       "       'correspondence', 'correspondig', 'corresponding',\n",
       "       'correspondingly', 'corresponds', 'corroborate', 'corrupt',\n",
       "       'corvi', 'cos', 'cosentino', 'cosic', 'cosmic', 'cosmochemistry',\n",
       "       'cosmography', 'cosmological', 'cosmologically', 'cosmology',\n",
       "       'cosmos', 'cospatial', 'cospatiality', 'cost', 'costly',\n",
       "       'costrain', 'could', 'count', 'counter', 'counterjet',\n",
       "       'counterpart', 'counterparts', 'counterrotating',\n",
       "       'counterrotation', 'counterrotator', 'counterrotators',\n",
       "       'countervail', 'couple', 'coupled', 'coupling', 'course', 'cousin',\n",
       "       'couterpart', 'cover', 'coverage', 'cox', 'cp', 'cpd', 'cpds',\n",
       "       'cq', 'cqgs', 'cr', 'cra', 'crab', 'cradle', 'crater', 'cratering',\n",
       "       'crazy', 'create', 'creates', 'creation', 'credence', 'crescent',\n",
       "       'crir', 'crisis', 'cristal', 'criteria', 'criterion', 'critical',\n",
       "       'criticality', 'critically', 'crl', 'cross', 'crossing',\n",
       "       'crossroad', 'crowd', 'crowded', 'crs', 'crss', 'crt', 'crucial',\n",
       "       'crucially', 'crude', 'cruel', 'crusial', 'crust', 'crutial',\n",
       "       'crux', 'cryo', 'cryogenic', 'cryovolcanic', 'cryovolcanism',\n",
       "       'crystallization', 'crystallize', 'cs', 'cse', 'cses', 'csfh',\n",
       "       'csfrd', 'csj', 'cso', 'ct', 'ctts', 'cttss', 'cub', 'cube',\n",
       "       'cubic', 'cull', 'culminate', 'culprit', 'cumulative', 'curated',\n",
       "       'curiosity', 'curious', 'current', 'currently', 'currentlyunknown',\n",
       "       'curtail', 'curtain', 'curvature', 'curve', 'cusp', 'cuspy',\n",
       "       'custom', 'customize', 'cut', 'cw', 'cy', 'cyanide',\n",
       "       'cyanoacetylene', 'cyanopolyynes', 'cyc', 'cycle', 'cyclic',\n",
       "       'cyclical', 'cycling', 'cyclopropenylidene', 'cyg', 'cygni',\n",
       "       'cygnus', 'cyle', 'cylinder', 'cylindrical', 'cytosine', 'daily',\n",
       "       'damage', 'damp', 'damped', 'dark', 'darkness', 'dart', 'data',\n",
       "       'database', 'datacubes', 'dataset', 'datasets', 'date', 'datsaset',\n",
       "       'daughter', 'davis', 'dawn', 'day', 'dayside', 'daytime',\n",
       "       'dazzling', 'dc', 'dcn', 'dco', 'ddt', 'de', 'dead', 'deadline',\n",
       "       'deadzone', 'deadzones', 'deal', 'dearth', 'death', 'deathstar',\n",
       "       'debatable', 'debate', 'debated', 'deblended', 'deblending',\n",
       "       'debris', 'dec', 'decadal', 'decade', 'decades', 'decam',\n",
       "       'decarli', 'decay', 'decelerate', 'decelerates', 'deceleration',\n",
       "       'december', 'decent', 'decide', 'decimate', 'decin', 'decipher',\n",
       "       'decisive', 'decisively', 'deck', 'decl', 'declination', 'decline',\n",
       "       'deco', 'decode', 'decompose', 'decomposition', 'decouple',\n",
       "       'decoupled', 'decrease', 'decrement', 'dectect', 'dedi',\n",
       "       'dedicate', 'dedicated', 'deduce', 'deem', 'deep', 'deepen',\n",
       "       'deeper', 'deepest', 'deeply', 'deference', 'deficiency',\n",
       "       'deficient', 'deficit', 'defies', 'define', 'defined', 'defines',\n",
       "       'definite', 'definitely', 'definitevely', 'definitive',\n",
       "       'definitively', 'definitly', 'deflect', 'deflection', 'deflector',\n",
       "       'defuse', 'defy', 'deg', 'degeneracy', 'degenerate', 'degradation',\n",
       "       'degree', 'degrees', 'delay', 'delayed', 'delensed', 'delgado',\n",
       "       'delineate', 'deliver', 'delivers', 'delivery', 'delta', 'delve',\n",
       "       'demand', 'demographic', 'demographics', 'demography',\n",
       "       'demonstrate', 'demonstrated', 'demonstrates', 'demonstrating',\n",
       "       'demonstration', 'dendrogram', 'denebola', 'dens', 'dense',\n",
       "       'densely', 'denser', 'densest', 'denset', 'densities', 'density',\n",
       "       'denstribution', 'deny', 'departure', 'depend', 'dependance',\n",
       "       'dependant', 'dependence', 'dependency', 'dependent', 'depends',\n",
       "       'depict', 'depl', 'deplete', 'depletion', 'deploy',\n",
       "       'depolarization', 'deposit', 'deposition', 'depress', 'depression',\n",
       "       'deprive', 'depsite', 'depth', 'depths', 'derivation', 'derive',\n",
       "       'derived', 'derives', 'deriving', 'descend', 'descendant',\n",
       "       'descrepancy', 'describe', 'described', 'describes', 'description',\n",
       "       'desert', 'deserve', 'design', 'designate', 'desirable', 'desire',\n",
       "       'desorb', 'desorbs', 'desorpted', 'desorption', 'desperately',\n",
       "       'despite', 'destine', 'destiny', 'destroy', 'destroyed',\n",
       "       'destroys', 'destruct', 'destruction', 'destructive', 'destructs',\n",
       "       'detach', 'detached', 'detachment', 'detail', 'detailed',\n",
       "       'detalied', 'detect', 'detectability', 'detectable', 'detected',\n",
       "       'detecting', 'detection', 'detections', 'detectios', 'detector',\n",
       "       'detects', 'deteriorate', 'determin', 'determination', 'determine',\n",
       "       'determined', 'determines', 'determing', 'determining',\n",
       "       'deterministic', 'detetected', 'deurated', 'deuterated',\n",
       "       'deuteration', 'deuterium', 'develop', 'developed', 'development',\n",
       "       'deviate', 'deviation', 'devoid', 'devote', 'dex', 'dfrac', 'dg',\n",
       "       'dgr', 'dgrs', 'diagnose', 'diagnosis', 'diagnostic',\n",
       "       'diagnostics', 'diagnozing', 'diagram', 'diameter', 'diamond',\n",
       "       'dianostic', 'diatomic', 'dibs', 'dichotomy', 'dicipher',\n",
       "       'dictate', 'dictated', 'didymos', 'die', 'diesks', 'dif',\n",
       "       'diferent', 'differ', 'difference', 'differences', 'different',\n",
       "       'differentiable', 'differential', 'differentiate',\n",
       "       'differentiation', 'differently', 'differs', 'difficult',\n",
       "       'difficulty', 'diffrent', 'diffuse', 'diffusion', 'diffusive',\n",
       "       'difinitive', 'dig', 'digest', 'dilemma', 'dilute', 'dilution',\n",
       "       'dim', 'dimension', 'dimensional', 'dimer', 'dimethyl', 'diminish',\n",
       "       'diminished', 'dimly', 'dimming', 'dingo', 'dioxide', 'dip',\n",
       "       'dipole', 'dipper', 'dire', 'direct', 'direction', 'directional',\n",
       "       'directionally', 'directly', 'director', 'dis', 'disagree',\n",
       "       'disagreement', 'disappear', 'disappearance', 'disc', 'discard',\n",
       "       'discern', 'discernible', 'disciminate', 'discless',\n",
       "       'discontinuity', 'discover', 'discovere', 'discovered',\n",
       "       'discoveries', 'discovery', 'discrepancies', 'discrepancy',\n",
       "       'discrepant', 'discrepency', 'discrete', 'discretionary',\n",
       "       'discriminant', 'discriminate', 'discrimination', 'discriminator',\n",
       "       'discs', 'discus', 'discuss', 'discussed', 'discussion', 'disect',\n",
       "       'disentangle', 'disentangled', 'disentanglement', 'disfavor',\n",
       "       'disfavour', 'dish', 'disintegrate', 'disk', 'diskless',\n",
       "       'disklike', 'disks', 'diskss', 'disky', 'dismiss', 'disntict',\n",
       "       'disorder', 'disordered', 'disp', 'disparate', 'dispersal',\n",
       "       'disperse', 'dispersed', 'dispersion', 'displace', 'displacement',\n",
       "       'display', 'disposal', 'dispose', 'disproportionally', 'disprove',\n",
       "       'disputable', 'dispute', 'disrupt', 'disruption', 'dissect',\n",
       "       'dissimilar', 'dissipate', 'dissipated', 'dissipates',\n",
       "       'dissipation', 'dissipative', 'dissipatively', 'dissociate',\n",
       "       'dissociates', 'dissociation', 'dissociative', 'dissolution',\n",
       "       'distance', 'distant', 'distantly', 'distinc', 'distinct',\n",
       "       'distinction', 'distinctive', 'distinctively', 'distinctly',\n",
       "       'distinguish', 'distinguishing', 'distort', 'distortion',\n",
       "       'distribute', 'distributed', 'distribution', 'disturb',\n",
       "       'disturbance', 'disturbed', 'diurnal', 'diusion', 'dive',\n",
       "       'diverge', 'divergence', 'diverse', 'diversify', 'diversion',\n",
       "       'diversity', 'divide', 'division', 'dla', 'dlas', 'dm', 'dna',\n",
       "       'dnc', 'dnm', 'do', 'doar', 'document', 'doeleman', 'dog', 'doh',\n",
       "       'domain', 'dominance', 'dominant', 'dominantly', 'dominate',\n",
       "       'dominated', 'dominates', 'donate', 'dong', 'dont', 'donut',\n",
       "       'door', 'dootstep', 'doppler', 'dor', 'doradus', 'dot', 'double',\n",
       "       'doublet', 'doubly', 'doubt', 'doubtful', 'doug', 'dovich',\n",
       "       'downfall', 'downsizing', 'downstream', 'downward', 'dozen',\n",
       "       'dpda', 'dpi', 'dpr', 'dprs', 'dq', 'dr', 'drag', 'dragged',\n",
       "       'dragonfly', 'dramatic', 'dramatically', 'drastic', 'drastically',\n",
       "       'dratistically', 'draw', 'drawback', 'drawn', 'drc', 'dredge',\n",
       "       'drier', 'drift', 'drill', 'drink', 'drive', 'driven', 'driver',\n",
       "       'driving', 'drop', 'droplet', 'dropout', 'dropouts', 'drouart',\n",
       "       'dry', 'ds', 'dsfg', 'dsfgs', 'dsharp', 'dsp', 'dual', 'duality',\n",
       "       'dub', 'dude', 'due', 'dunham', 'dunne', 'duplicate',\n",
       "       'duplication', 'durability', 'duration', 'dust', 'dusty', 'dusy',\n",
       "       'dut', 'duty', 'duvet', 'dv', 'dwarf', 'dwarfs', 'dyhamics', 'dyn',\n",
       "       'dyna', 'dynamic', 'dynamical', 'dynamically', 'dynamics',\n",
       "       'dynamo', 'dyncamical', 'dyncamics', 'dz', 'eaerly', 'ealry',\n",
       "       'eao', 'earendel', 'earlest', 'earlier', 'earliest', 'early',\n",
       "       'earth', 'earths', 'eary', 'easilty', 'easily', 'easiness', 'east',\n",
       "       'eastern', 'eastward', 'easy', 'ebert', 'ec', 'eccentric',\n",
       "       'eccentricity', 'eccentricties', 'ecdfs', 'echelle', 'echo',\n",
       "       'eclipse', 'eclosion', 'ecmzs', 'ecology', 'economic',\n",
       "       'economical', 'economically', 'ecosystem', 'edd', 'eddington',\n",
       "       'eddy', 'edge', 'edisk', 'editor', 'edu', 'effciency', 'effcient',\n",
       "       'effect', 'effective', 'effectively', 'effectiveness',\n",
       "       'effelsberg', 'efficacy', 'efficency', 'efficiencies',\n",
       "       'efficiency', 'efficient', 'efficiently', 'effiencies', 'effort',\n",
       "       'effortlessly', 'eg', 'egami', 'egde', 'egg', 'eggs', 'egm', 'ego',\n",
       "       'egos', 'eh', 'eht', 'ehv', 'eight', 'eighty', 'einstein',\n",
       "       'either', 'eject', 'ejecta', 'ejected', 'ejection', 'ejective',\n",
       "       'ekin', 'el', 'elaborate', 'elane', 'elapse', 'electric',\n",
       "       'electro', 'electromagnetic', 'electron', 'element', 'elemental',\n",
       "       'elementary', 'elevate', 'elevated', 'elevation', 'eleven', 'elia',\n",
       "       'elias', 'elliptical', 'ellipticals', 'ellison', 'elongate',\n",
       "       'elongated', 'elongation', 'elpis', 'else', 'elsewhere', 'elt',\n",
       "       'elts', 'elucidate', 'elude', 'elusive', 'em', 'emanate', 'emb',\n",
       "       'embark', 'embed', 'embeddd', 'embedded', 'embeddedness',\n",
       "       'emblematic', 'embryo', 'embryos', 'emerge', 'emergence',\n",
       "       'emergent', 'emiiting', 'eminent', 'emipirally', 'emision',\n",
       "       'emisison', 'emissiion', 'emission', 'emissionsources', 'emissive',\n",
       "       'emissivities', 'emissivity', 'emissoin', 'emisssion', 'emit',\n",
       "       'emits', 'emitter', 'emitting', 'emonts', 'emphasis', 'emphasize',\n",
       "       'empire', 'empirical', 'empirically', 'employ', 'employed',\n",
       "       'emprical', 'empty', 'emu', 'emulate', 'en', 'enable', 'enabled',\n",
       "       'enables', 'encase', 'enceladus', 'encircle', 'encke', 'enclose',\n",
       "       'enclosed', 'encloses', 'encode', 'encompass', 'encounter',\n",
       "       'encourage', 'end', 'endeavor', 'endemic', 'endsley', 'endure',\n",
       "       'energetic', 'energetics', 'energize', 'energy', 'enevlopes',\n",
       "       'enforce', 'enforced', 'engage', 'engagement', 'engine', 'engrave',\n",
       "       'engulf', 'enhance', 'enhanced', 'enhancement', 'enhancements',\n",
       "       'enhances', 'enichment', 'enigma', 'enigmatic', 'enlarge',\n",
       "       'enlighten', 'ennvironment', 'enormous', 'enough', 'enourmous',\n",
       "       'enrich', 'enriched', 'enrichement', 'enrichemnt', 'enrichment',\n",
       "       'ensemble', 'enshroud', 'enshrouded', 'ensue', 'ensure', 'ensures',\n",
       "       'entail', 'entangled', 'enter', 'entered', 'entering', 'enters',\n",
       "       'enthusiastic', 'entire', 'entirely', 'entirety', 'entity',\n",
       "       'entourage', 'entrain', 'entrainment', 'entrains', 'entropy',\n",
       "       'entry', 'entwine', 'envelop', 'envelope', 'envelopes',\n",
       "       'enveloppe', 'enviroment', 'enviromental', 'enviromnent',\n",
       "       'enviromnents', 'environment', 'environmental', 'environmentally',\n",
       "       'environments', 'environmnent', 'environmnets', 'environs',\n",
       "       'envisage', 'envision', 'envrionments', 'eor', 'ep', 'epectation',\n",
       "       'ephemeral', 'epidosic', 'episode', 'episodes', 'episodic',\n",
       "       'episodically', 'epitomize', 'epoch', 'epochs', 'eponymous',\n",
       "       'epsilon', 'equal', 'equally', 'equate', 'equation', 'equator',\n",
       "       'equatorial', 'equidistant', 'equilibrium', 'equip', 'equivalence',\n",
       "       'equivalent', 'equivalently', 'er', 'era', 'erase', 'erg', 'ergs',\n",
       "       'eri', 'eridani', 'eridanus', 'ero', 'erode', 'erosion', 'erosive',\n",
       "       'erratic', 'error', 'erupt', 'eruption', 'eruptive', 'es', 'esa',\n",
       "       'esc', 'escape', 'eses', 'esimal', 'esimtate', 'esma', 'eso',\n",
       "       'espada', 'especially', 'essence', 'essential', 'essentially',\n",
       "       'estabilsh', 'establised', 'establish', 'establishment',\n",
       "       'estensive', 'estiablish', 'estimate', 'estimated', 'estimation',\n",
       "       'estimator', 'et', 'eta', 'etc', 'etg', 'etgs', 'ether',\n",
       "       'ethylene', 'europa', 'europas', 'european', 'euv', 'ev',\n",
       "       'evacuate', 'evaluate', 'evaluation', 'evalulate', 'evans',\n",
       "       'evaporate', 'evaporated', 'evaporation', 'evaporative',\n",
       "       'evaulate', 'evelopes', 'even', 'evenly', 'event', 'eventual',\n",
       "       'eventually', 'ever', 'every', 'everywhere', 'everyyoung',\n",
       "       'evidence', 'evidenced', 'evident', 'evidently', 'evindence',\n",
       "       'evla', 'evoke', 'evolution', 'evolutional', 'evolutionarily',\n",
       "       'evolutionary', 'evolutive', 'evolutonary', 'evolve', 'evolved',\n",
       "       'evolves', 'ew', 'ex', 'exact', 'exactly', 'exam', 'examination',\n",
       "       'examine', 'examined', 'examines', 'example', 'examples',\n",
       "       'excavate', 'exccess', 'exceed', 'exceedingly', 'exceeds',\n",
       "       'excellent', 'except', 'exception', 'exceptional', 'exceptionally',\n",
       "       'excess', 'excesses', 'excessive', 'excessively', 'exchange',\n",
       "       'excitation', 'excitatory', 'excite', 'excited', 'exciting',\n",
       "       'excitingly', 'exclude', 'exclusive', 'exclusively', 'excursion',\n",
       "       'execllent', 'execute', 'executed', 'execution', 'executive',\n",
       "       'exemplary', 'exert', 'exhaust', 'exhaustion', 'exhibit',\n",
       "       'exibits', 'exisiting', 'exist', 'existence', 'existent', 'exists',\n",
       "       'exit', 'exo', 'exocomet', 'exocometary', 'exocomets', 'exogenic',\n",
       "       'exokuiper', 'exomars', 'exomoon', 'exomoons', 'exoplanet',\n",
       "       'exoplanetary', 'exoplanets', 'exor', 'exors', 'exosphere',\n",
       "       'exospheric', 'exothermically', 'exotic', 'expand', 'expanded',\n",
       "       'expands', 'expansion', 'expect', 'expectatinos', 'expectation',\n",
       "       'expected', 'expel', 'expelled', 'expels', 'expense', 'expensive',\n",
       "       'experience', 'experienced', 'experiment', 'experimental',\n",
       "       'experimentally', 'expert', 'expertise', 'explain', 'explainable',\n",
       "       'explained', 'explanation', 'explanations', 'explicitly',\n",
       "       'explode', 'explodes', 'exploit', 'exploitation', 'exploration',\n",
       "       'explorational', 'exploratory', 'explore', 'explored', 'explosion',\n",
       "       'explosive', 'exploting', 'exponent', 'exponentially', 'expose',\n",
       "       'exposure', 'express', 'expulsed', 'expulsion', 'exquisit',\n",
       "       'exquisite', 'exquisitely', 'extant', 'extend', 'extended',\n",
       "       'extending', 'extends', 'extension', 'extensive', 'extensively',\n",
       "       'extent', 'extention', 'exterior', 'external', 'externally',\n",
       "       'extincted', 'extinction', 'extinguish', 'extra', 'extract',\n",
       "       'extracted', 'extraction', 'extragalactic', 'extragalatic',\n",
       "       'extranal', 'extraordinarily', 'extraordinary', 'extraplanar',\n",
       "       'extrapolate', 'extrapolation', 'extrasolar', 'extraterrestrial',\n",
       "       'extravagant', 'extrem', 'extreme', 'extremely', 'extremelyrecent',\n",
       "       'extremes', 'extrude', 'eye', 'eyebrow', 'eyelash', 'fab', 'face',\n",
       "       'facet', 'faceted', 'facilitate', 'facilitates', 'facility',\n",
       "       'facillitating', 'facor', 'fact', 'factor', 'factory', 'fade',\n",
       "       'fading', 'fail', 'failure', 'faint', 'fainter', 'faintness',\n",
       "       'fair', 'fairly', 'faithful', 'fake', 'fall', 'false', 'falsify',\n",
       "       'fame', 'familiar', 'family', 'famous', 'famously', 'fanaroff',\n",
       "       'fantastic', 'far', 'faraday', 'fascinate', 'fashion', 'fast',\n",
       "       'faster', 'fate', 'fathom', 'fault', 'faust', 'favor',\n",
       "       'favorability', 'favorable', 'favoring', 'favour', 'favourable',\n",
       "       'fc', 'fe', 'fear', 'feasibility', 'feasible', 'feat', 'feature',\n",
       "       'featureless', 'february', 'fed', 'fee', 'feeback', 'feebdack',\n",
       "       'feed', 'feedback', 'feeding', 'feeds', 'feel', 'feii', 'feirrera',\n",
       "       'fell', 'fellowship', 'feo', 'feoh', 'fermi', 'ferreira',\n",
       "       'fertile', 'fest', 'few', 'fewer', 'fgas', 'fgk', 'fhsc', 'fhscs',\n",
       "       'fiber', 'fibre', 'fibres', 'fide', 'fidelity', 'field', 'fiels',\n",
       "       'fiery', 'fifteen', 'fifth', 'fifty', 'fig', 'figs', 'figure',\n",
       "       'filament', 'filamentary', 'filaments', 'file', 'fill', 'filler',\n",
       "       'fillet', 'filling', 'filter', 'filtered', 'filtering',\n",
       "       'filtration', 'final', 'finalize', 'finally', 'find', 'finder',\n",
       "       'finding', 'findings', 'fine', 'finely', 'finer', 'finger',\n",
       "       'fingerprint', 'fingertip', 'finish', 'finished', 'finnaly', 'fir',\n",
       "       'fire', 'firm', 'firmly', 'firs', 'first', 'firstly', 'firsts',\n",
       "       'fisher', 'fist', 'fit', 'fiteen', 'fitting', 'five', 'fix',\n",
       "       'flagship', 'flagships', 'flare', 'flared', 'flash', 'flat',\n",
       "       'flatness', 'flatten', 'flattened', 'flatter', 'fledge',\n",
       "       'flexibility', 'flexible', 'flip', 'float', 'flocculent', 'flow',\n",
       "       'fluctuate', 'fluctuation', 'fluences', 'fluid', 'fluorescence',\n",
       "       'fluoride', 'fluorine', 'flux', 'fluxes', 'fluxratio', 'fly',\n",
       "       'flyby', 'flybys', 'fmf', 'fmos', 'focus', 'focused', 'focusing',\n",
       "       'focussing', 'fold', 'follow', 'followed', 'followup', 'fom',\n",
       "       'fomalhaut', 'fomation', 'fontani', 'foot', 'foothold', 'footing',\n",
       "       'footprint', 'foramtion', 'forbid', 'forbidden', 'forcast',\n",
       "       'force', 'forego', 'foreground', 'foremost', 'foresee',\n",
       "       'foreseeable', 'foreseen', 'forest', 'forge', 'forgotten', 'form',\n",
       "       'formaing', 'formaiton', 'formaldehyde', 'formaldeyde',\n",
       "       'formamide', 'format', 'formate', 'formatin', 'formation',\n",
       "       'formatoin', 'formaton', 'formed', 'former', 'formerly', 'formic',\n",
       "       'forming', 'formulate', 'formulation', 'formyl', 'fornax', 'fors',\n",
       "       'forsake', 'forsaken', 'forsee', 'forthcoming', 'fortuitous',\n",
       "       'fortuitously', 'fortunately', 'fortunetelly', 'forward', 'fossil',\n",
       "       'foster', 'found', 'foundation', 'foundational', 'fountain',\n",
       "       'four', 'fourier', 'fourth', 'fov', 'fox', 'fr', 'fractal',\n",
       "       'fraction', 'fractional', 'fractionation', 'fracture',\n",
       "       'fragementation', 'fragment', 'fragmentation', 'fragmented',\n",
       "       'fragmentiation', 'frame', 'framework', 'franco', 'frb', 'frbs',\n",
       "       'free', 'freeze', 'freezeout', 'freezes', 'fregg', 'freggs',\n",
       "       'frequency', 'frequent', 'frequently', 'fresh', 'freshly', 'fri',\n",
       "       'friction', 'frii', 'frisa', 'froming', 'front', 'frontal',\n",
       "       'frontier', 'frost', 'frozen', 'fruitful', 'fry', 'frying', 'fs',\n",
       "       'ft', 'fu', 'fuel', 'fueling', 'fuelling', 'fukui', 'fulfill',\n",
       "       'full', 'fullfill', 'fully', 'funciton', 'function', 'functiona',\n",
       "       'functional', 'fund', 'fundamental', 'fundamentally',\n",
       "       'fundamentional', 'fundermental', 'funding', 'funnel', 'fuor',\n",
       "       'fuors', 'furnace', 'further', 'furthermore', 'furthest',\n",
       "       'furthing', 'fuse', 'futher', 'futrue', 'future', 'fuv', 'fuzzy',\n",
       "       'fw', 'fwhm', 'fwhms', 'fwzi', 'gaalxies', 'gahm', 'gaia', 'gain',\n",
       "       'gaining', 'gal', 'galactic', 'galactocentric', 'galaixes',\n",
       "       'galatic', 'galaxies', 'galaxis', 'galaxxy', 'galaxy', 'galdla',\n",
       "       'galdlas', 'gale', 'galex', 'galilean', 'galileo', 'gama', 'game',\n",
       "       'gamma', 'gandhi', 'gao', 'gap', 'gapped', 'gaps', 'gar', 'garcia',\n",
       "       'garcÃ­a', 'garner', 'garrod', 'gas', 'gasdynamics', 'gaseous',\n",
       "       'gasoues', 'gasp', 'gass', 'gassing', 'gather', 'gatos', 'gauge',\n",
       "       'gauss', 'gaussian', 'gaz', 'gb', 'gbpne', 'gbps', 'gbt', 'gc',\n",
       "       'gcms', 'gcps', 'gcs', 'geature', 'geballe', 'gecko', 'geckos',\n",
       "       'gem', 'geminga', 'gemini', 'gems', 'general', 'generality',\n",
       "       'generalize', 'generally', 'generate', 'generates', 'generation',\n",
       "       'generic', 'genesis', 'genetic', 'gently', 'genuine', 'genuinely',\n",
       "       'genzel', 'geocentric', 'geochemistry', 'geological',\n",
       "       'geologically', 'geometric', 'geometrical', 'geometrically',\n",
       "       'geometry', 'gerasimenko', 'gerin', 'get', 'gev', 'geyser', 'gg',\n",
       "       'ggd', 'ggtau', 'ghost', 'ghr', 'ghrs', 'ghz', 'gi', 'giacobini',\n",
       "       'giant', 'gift', 'gigamaser', 'gigantic', 'gigayear', 'gint',\n",
       "       'giraffe', 'give', 'gk', 'glass', 'glaxies', 'glazebrook', 'gleam',\n",
       "       'gleaned', 'glimpse', 'global', 'globally', 'globular', 'globule',\n",
       "       'globulette', 'globulettes', 'glow', 'glt', 'glyceraldehyde',\n",
       "       'glycerol', 'glycine', 'glycol', 'glycolaldehyde', 'glz', 'gm',\n",
       "       'gma', 'gmas', 'gmc', 'gmcs', 'gmrt', 'gmva', 'gnz', 'go', 'goal',\n",
       "       'goham', 'gold', 'golden', 'goldmine', 'goldreich', 'goldriech',\n",
       "       'gomez', 'gonzalez', 'good', 'gordo', 'gould', 'govern',\n",
       "       'governed', 'governs', 'gq', 'gr', 'gracias', 'grade', 'gradec',\n",
       "       'graded', 'gradience', 'gradient', 'gradual', 'gradually', 'grail',\n",
       "       'grain', 'grand', 'grant', 'grasp', 'gravisphere',\n",
       "       'gravitaionally', 'gravitate', 'gravitatinally', 'gravitation',\n",
       "       'gravitational', 'gravitationally', 'gravitationnaly', 'gravition',\n",
       "       'gravitionally', 'gravititional', 'gravito', 'gravity', 'graze',\n",
       "       'grb', 'grbs', 'great', 'greatly', 'greaves', 'green',\n",
       "       'greenhouse', 'gregarious', 'gregory', 'grid', 'griffith', 'grind',\n",
       "       'grinding', 'grism', 'grmhd', 'grobally', 'groenewegen', 'gross',\n",
       "       'ground', 'groundbreaking', 'groundwork', 'group', 'grow', 'grown',\n",
       "       'growth', 'grs', 'gs', 'gsc', 'gst', 'gtc', 'gtd', 'gto', 'guage',\n",
       "       'guapos', 'guarantee', 'guess', 'guest', 'guidance', 'guide',\n",
       "       'guideline', 'guidepost', 'guiding', 'gun', 'gust', 'gv', 'gw',\n",
       "       'gx', 'gy', 'gyr', 'gyrs', 'gz', 'ha', 'habitability', 'habitable',\n",
       "       'habors', 'hadley', 'hae', 'haebe', 'haebes', 'haes', 'hair',\n",
       "       'hale', 'half', 'halfway', 'hall', 'halley', 'hallmark',\n",
       "       'hallmarks', 'halo', 'haloes', 'halos', 'halpha', 'halt',\n",
       "       'hamburger', 'hamper', 'hampered', 'hand', 'handful', 'handle',\n",
       "       'happen', 'happens', 'harassment', 'harbor', 'harbour', 'hard',\n",
       "       'hardly', 'hardness', 'harikane', 'harness', 'haro', 'harsh',\n",
       "       'harsher', 'harvard', 'harvest', 'hasa', 'hashimoto', 'hatlas',\n",
       "       'hava', 'have', 'hawc', 'hawk', 'haystack', 'haze', 'hb', 'hbc',\n",
       "       'hc', 'hccc', 'hcccn', 'hccn', 'hccnc', 'hcg', 'hchii', 'hcl',\n",
       "       'hcn', 'hco', 'hcooch', 'hcooh', 'hcp', 'hcs', 'hd', 'hdco', 'hdf',\n",
       "       'hdo', 'heabe', 'head', 'headstream', 'heart', 'heat', 'heated',\n",
       "       'heating', 'heavier', 'heavily', 'heavy', 'height', 'heii',\n",
       "       'heirarchical', 'helical', 'helicity', 'helicoidal',\n",
       "       'heliocentric', 'helium', 'helix', 'hello', 'help', 'helpdesk',\n",
       "       'helpful', 'hemisphere', 'hemispheres', 'hen', 'hence', 'henize',\n",
       "       'hennawi', 'hennebelle', 'heracles', 'herald', 'herbig',\n",
       "       'hercules', 'herczeg', 'hereafter', 'hereby', 'heretofore',\n",
       "       'heritage', 'hermes', 'hero', 'herschel', 'hershel', 'hertz',\n",
       "       'hertzsprung', 'heschel', 'hess', 'heterodyne', 'heterogeneities',\n",
       "       'heterogeneity', 'heterogeneous', 'heyday', 'hf', 'hff', 'hfls',\n",
       "       'hfs', 'hfss', 'hh', 'hht', 'hi', 'hiatus', 'hiciao', 'hickson',\n",
       "       'hid', 'hidden', 'hide', 'hids', 'hierachical', 'hierarchal',\n",
       "       'hierarchical', 'hierarchy', 'hifi', 'higal', 'high', 'higher',\n",
       "       'highlight', 'highly', 'highz', 'higuchi', 'hii', 'himiko',\n",
       "       'hinder', 'hinders', 'hinge', 'hint', 'hinting', 'hip', 'hippo',\n",
       "       'hirano', 'hisaki', 'historic', 'historical', 'historically',\n",
       "       'history', 'hit', 'hitherto', 'hitomi', 'hix', 'hizels', 'hl',\n",
       "       'hls', 'hltau', 'hm', 'hmc', 'hmcs', 'hmp', 'hmpo', 'hmps',\n",
       "       'hmpsc', 'hmpscs', 'hmscs', 'hmsf', 'hmsfr', 'hmsfrs', 'hmsfsio',\n",
       "       'hmyso', 'hmysos', 'hn', 'hnalpha', 'hnc', 'hnccc', 'hncnh',\n",
       "       'hnco', 'ho', 'hobys', 'hoc', 'hoff', 'hogg', 'hold', 'holder',\n",
       "       'hole', 'holistic', 'hollow', 'holy', 'home', 'homgeneous',\n",
       "       'homogeneity', 'homogeneous', 'homogeneously', 'homogenious',\n",
       "       'homogenize', 'homogenous', 'homunculus', 'hop', 'hope',\n",
       "       'hopefully', 'hor', 'horizon', 'horizontal', 'horse', 'horsehead',\n",
       "       'horseshoe', 'hospitality', 'host', 'hostile', 'hosting', 'hot',\n",
       "       'hotdog', 'hotdogs', 'hotly', 'hots', 'hotspot', 'hotter', 'houde',\n",
       "       'hour', 'hourglass', 'hourly', 'however', 'hpbw', 'hr', 'hrks',\n",
       "       'hrl', 'hrls', 'hrs', 'hsc', 'hsieh', 'hst', 'ht', 'http', 'hub',\n",
       "       'hubble', 'hubs', 'hudf', 'huge', 'hugely', 'human', 'humbly',\n",
       "       'humid', 'hundred', 'hundreds', 'hunt', 'hunter', 'hurdle',\n",
       "       'huygens', 'hvc', 'hvcc', 'hvccs', 'hvcs', 'hya', 'hyadrae',\n",
       "       'hybrid', 'hybriod', 'hyde', 'hydra', 'hydride', 'hydro',\n",
       "       'hydrocarbon', 'hydrodynamic', 'hydrodynamical', 'hydrodynamics',\n",
       "       'hydrogen', 'hydrogenation', 'hydronium', 'hydrostatic',\n",
       "       'hydrothermal', 'hydroxide', 'hydroxyl', 'hydroxylamine', 'hylirg',\n",
       "       'hylirgs', 'hyper', 'hypercompact', 'hyperdimensional',\n",
       "       'hyperfine', 'hypergiant', 'hypergiants', 'hyperluminous',\n",
       "       'hypotesys', 'hypotheses', 'hypothesis', 'hypothesise',\n",
       "       'hypothesize', 'hypothetical', 'hypothetically', 'hz', 'hzrg',\n",
       "       'hzrgs', 'hÎ±', 'ia', 'iar', 'ibero', 'ibis', 'ibisco', 'ic',\n",
       "       'icarus', 'ice', 'iceage', 'icecube', 'icm', 'iconic', 'icy', 'id',\n",
       "       'idea', 'ideal', 'idealization', 'ideally', 'identical',\n",
       "       'identically', 'identifed', 'identification', 'identified',\n",
       "       'identifies', 'identify', 'identifying', 'identity', 'idle', 'idv',\n",
       "       'ie', 'ifs', 'ifu', 'igm', 'ignite', 'ignition', 'ignored',\n",
       "       'igrins', 'ii', 'iii', 'iiizw', 'iizw', 'ik', 'iktau', 'ill',\n",
       "       'illuminate', 'illuminated', 'illuminates', 'illumination',\n",
       "       'illusive', 'illustrate', 'illustration', 'im', 'imacts', 'image',\n",
       "       'imaged', 'imager', 'imagers', 'imagery', 'images', 'imaging',\n",
       "       'imbalance', 'imbh', 'imbhs', 'imf', 'imfs', 'immeasurably',\n",
       "       'immediable', 'immediate', 'immediately', 'immense', 'immerse',\n",
       "       'imminent', 'imminently', 'impact', 'impacted', 'impactor',\n",
       "       'impart', 'impartial', 'impede', 'impedes', 'imperative',\n",
       "       'impinge', 'impinges', 'implement', 'implication', 'implications',\n",
       "       'implicit', 'implicitly', 'implied', 'implies', 'impling',\n",
       "       'implosion', 'imply', 'implying', 'importance', 'important',\n",
       "       'importantly', 'impose', 'impossible', 'impractical', 'impressive',\n",
       "       'impressively', 'imprint', 'improve', 'improved', 'improvement',\n",
       "       'improves', 'improving', 'impulse', 'impulsive', 'ina',\n",
       "       'inability', 'inaccessibility', 'inaccessible', 'inaccurate',\n",
       "       'inaction', 'inactive', 'inadequate', 'incapable', 'incidence',\n",
       "       'incident', 'incidentally', 'incipient', 'incisive', 'incite',\n",
       "       'inclination', 'incline', 'inclined', 'include', 'includign',\n",
       "       'includin', 'inclusion', 'incoming', 'incompatible', 'incomplete',\n",
       "       'incompleteness', 'inconceivable', 'inconclusive', 'inconsistency',\n",
       "       'inconsistent', 'incorporate', 'incorporated', 'incorporation',\n",
       "       'incorportating', 'incorrect', 'increading', 'increase',\n",
       "       'increased', 'increasingly', 'incredible', 'incredibly',\n",
       "       'increment', 'incrementally', 'incresing', 'indeed', 'indended',\n",
       "       'indepedent', 'independantly', 'independent', 'independently',\n",
       "       'indepenent', 'index', 'indicate', 'indicates', 'indicating',\n",
       "       'indication', 'indicative', 'indicator', 'indicies', 'indirect',\n",
       "       'indirectly', 'indispensable', 'individual', 'individually',\n",
       "       'induce', 'induced', 'induction', 'industry', 'ineffective',\n",
       "       'inefficiency', 'inefficient', 'inefficiently', 'inegligible',\n",
       "       'inequivocably', 'inert', 'inertial', 'inevitable', 'inextricably',\n",
       "       'infall', 'infallen', 'infalling', 'infalls', 'infant', 'infared',\n",
       "       'infer', 'inference', 'inferred', 'inflate', 'inflation',\n",
       "       'inflection', 'inflow', 'inflowing', 'inflows', 'influence',\n",
       "       'influenced', 'influential', 'influx', 'inforamtions', 'inform',\n",
       "       'information', 'informative', 'informed', 'informs', 'infrafred',\n",
       "       'infrared', 'ingredient', 'inhabit', 'inherent', 'inherently',\n",
       "       'inherit', 'inheritance', 'inherited', 'inhertance', 'inhibit',\n",
       "       'inhibition', 'inhomogeneity', 'inhomogeneous', 'inital',\n",
       "       'initial', 'initially', 'initiate', 'initiation', 'inject',\n",
       "       'injected', 'injection', 'injects', 'inms', 'innate', 'inner',\n",
       "       'innermost', 'innovative', 'inorganic', 'inoue', 'input', 'inputs',\n",
       "       'inscrutable', 'insect', 'insensitive', 'insert', 'inside',\n",
       "       'insight', 'insightful', 'inspect', 'inspection', 'inspire',\n",
       "       'instability', 'instance', 'instantaneous', 'instantaneously',\n",
       "       'instead', 'instrinsic', 'instructive', 'instrument',\n",
       "       'instrumental', 'instrumentation', 'insufficient', 'int',\n",
       "       'inteferometer', 'inteferometric', 'integral', 'integrate',\n",
       "       'integrated', 'integration', 'intence', 'intend', 'intended',\n",
       "       'intense', 'intensely', 'intensified', 'intensity', 'intensive',\n",
       "       'intensively', 'intentionally', 'inter', 'interact', 'interacting',\n",
       "       'interaction', 'interacts', 'interarm', 'interation',\n",
       "       'intercepted', 'interchangeably', 'interclump', 'intercluster',\n",
       "       'interconnected', 'intercting', 'interest', 'interestellar',\n",
       "       'interesting', 'interestingly', 'interface', 'interfere',\n",
       "       'interferometer', 'interferometric', 'interferometrically',\n",
       "       'interferometry', 'interferomter', 'intergalactic', 'intergral',\n",
       "       'interior', 'interloper', 'intermediate', 'intermediately',\n",
       "       'intermittent', 'internal', 'internally', 'international',\n",
       "       'internuclear', 'interplay', 'interplays', 'interpret',\n",
       "       'interpretation', 'interpreted', 'interpreting', 'interpretion',\n",
       "       'interrelation', 'interrupt', 'intersect', 'intersection',\n",
       "       'interstellar', 'intertwine', 'intertwined', 'interval',\n",
       "       'intervene', 'inthe', 'intimate', 'intimately', 'intitially',\n",
       "       'intoplanetary', 'intra', 'intracluster', 'intragroup',\n",
       "       'intricate', 'intricately', 'intrigue', 'intriguing',\n",
       "       'intriguingly', 'intrinsic', 'intrinsically', 'introduce',\n",
       "       'introduces', 'intruder', 'intruiging', 'inturn', 'invalidity',\n",
       "       'invaluable', 'invariance', 'invent', 'inventory', 'inverse',\n",
       "       'inversely', 'invert', 'invest', 'invested', 'investigate',\n",
       "       'investigated', 'investigates', 'investigation', 'investment',\n",
       "       'invetigate', 'invigorate', 'invisible', 'invloves', 'invoke',\n",
       "       'invoked', 'involve', 'involved', 'inward', 'inwards', 'io', 'ion',\n",
       "       'ionian', 'ionic', 'ionisation', 'ionise', 'ionised', 'ionising',\n",
       "       'ionization', 'ionize', 'ionized', 'ionizes', 'ionizing',\n",
       "       'ionizsation', 'ionosphere', 'ionzing', 'ios', 'ir', 'ira', 'irac',\n",
       "       'iram', 'iras', 'irc', 'irdc', 'irdcs', 'irdis', 'ire', 'irlf',\n",
       "       'iron', 'irradiate', 'irradiated', 'irradiation', 'irrc',\n",
       "       'irregular', 'irregulars', 'irreplaceable', 'irrespective', 'irs',\n",
       "       'irsf', 'irtf', 'irtz', 'irx', 'isella', 'isf', 'island', 'ism',\n",
       "       'isms', 'iso', 'isocyanate', 'isocyanide', 'isocyanides',\n",
       "       'isolate', 'isolated', 'isolation', 'isomer', 'isomeric', 'ison',\n",
       "       'isothermal', 'isotope', 'isotopes', 'isotopic', 'isotoplogues',\n",
       "       'isotopolgues', 'isotopolog', 'isotopologies', 'isotopologue',\n",
       "       'isotopologues', 'isotopomer', 'isototopologue', 'isotropic',\n",
       "       'isotropically', 'isovelocity', 'israel', 'isrf', 'issue', 'item',\n",
       "       'iterated', 'iv', 'iw', 'jade', 'james', 'jan', 'jansky',\n",
       "       'january', 'janurary', 'japanese', 'jcmt', 'jd', 'jean', 'jelly',\n",
       "       'jellyfish', 'jeo', 'jet', 'jetsfrom', 'jfc', 'jfcs', 'jflow',\n",
       "       'jhk', 'jingle', 'job', 'johnson', 'johnstone', 'join', 'joint',\n",
       "       'jointly', 'jorgensen', 'joule', 'journey', 'jovian', 'jth',\n",
       "       'judge', 'judgement', 'judging', 'jug', 'juice', 'july', 'jump',\n",
       "       'june', 'juno', 'jup', 'jupiter', 'jupp', 'justificataion',\n",
       "       'justification', 'justified', 'justify', 'jvla', 'jwst', 'jwsts',\n",
       "       'jy', 'ka', 'kaplerian', 'karim', 'kashz', 'kau', 'kava', 'kbos',\n",
       "       'kcl', 'kcrb', 'kcwi', 'kea', 'keck', 'keep', 'kellogg',\n",
       "       'kennicutt', 'kenyon', 'keplarian', 'kepler', 'keplerian',\n",
       "       'kepleriand', 'kernel', 'ketene', 'keto', 'kev', 'key', 'keywords',\n",
       "       'kges', 'ki', 'kick', 'kickstart', 'kilo', 'kilograms',\n",
       "       'kilometer', 'kilometre', 'kiloparsec', 'kiloparsecs', 'kin',\n",
       "       'kind', 'kinematic', 'kinematical', 'kinematically', 'kinematics',\n",
       "       'kinemetry', 'kinetic', 'kinetically', 'kingfish', 'kink',\n",
       "       'kinship', 'kitt', 'kiv', 'kl', 'klaassen', 'kleinmann',\n",
       "       'kleinnmann', 'km', 'kmos', 'kn', 'knee', 'knot', 'know',\n",
       "       'knowledge', 'known', 'koelligan', 'kohno', 'kolmogorov', 'korean',\n",
       "       'kos', 'kp', 'kpc', 'kpcs', 'kral', 'kruijssen', 'krumholz', 'ks',\n",
       "       'kuan', 'kuiper', 'kuno', 'kvn', 'kylafis', 'kyr', 'lab', 'label',\n",
       "       'laboatry', 'laboca', 'laboratory', 'labs', 'lac', 'lacertae',\n",
       "       'lack', 'lacking', 'lacunary', 'ladder', 'lae', 'laes', 'lag',\n",
       "       'lagadec', 'lager', 'lagrangian', 'lambda', 'lambdacdm',\n",
       "       'lamdacdm', 'lander', 'lane', 'lanes', 'larg', 'large', 'largely',\n",
       "       'largerly', 'larson', 'laser', 'last', 'lasting', 'lastly', 'late',\n",
       "       'lately', 'later', 'lateral', 'laterally', 'latitude',\n",
       "       'latitudinal', 'latter', 'launch', 'launched', 'launching', 'law',\n",
       "       'lay', 'layer', 'layered', 'lbas', 'lbc', 'lbg', 'lbgs', 'lbol',\n",
       "       'lbv', 'lbvs', 'lcdm', 'lco', 'ldn', 'le', 'lead', 'leading',\n",
       "       'leaf', 'leak', 'leakage', 'leap', 'learn', 'least', 'leave',\n",
       "       'ledd', 'lee', 'left', 'leftover', 'leg', 'lega', 'legacy',\n",
       "       'legus', 'lellouch', 'lemmon', 'lend', 'lending', 'lends',\n",
       "       'length', 'lengths', 'lens', 'lensed', 'lenses', 'lensing',\n",
       "       'lenssource', 'lenticular', 'lenticulars', 'leo', 'leonard',\n",
       "       'leonis', 'leroy', 'less', 'lessen', 'lesson', 'let', 'letter',\n",
       "       'level', 'lever', 'leverage', 'levy', 'lf', 'lfir', 'lfs', 'lgs',\n",
       "       'lha', 'lhb', 'li', 'liberate', 'library', 'librate', 'lie',\n",
       "       'life', 'lifecycle', 'lifecycles', 'lifespan', 'lifetime',\n",
       "       'lifetimes', 'lift', 'light', 'lighthouse', 'lih', 'like',\n",
       "       'likelihood', 'likely', 'likewise', 'limb', 'lime', 'liminal',\n",
       "       'limit', 'limitation', 'limited', 'limits', 'limted', 'line',\n",
       "       'linear', 'linearity', 'linearly', 'liner', 'linescan',\n",
       "       'linescans', 'linewidth', 'linewidths', 'ling', 'linger', 'link',\n",
       "       'linkage', 'liquid', 'lir', 'lirg', 'lirgs', 'lisenfeld', 'list',\n",
       "       'literatue', 'literature', 'lithium', 'little', 'liu', 'live',\n",
       "       'lived', 'lkca', 'lkha', 'llo', 'llos', 'llqso', 'llqsos', 'lmc',\n",
       "       'lmcs', 'lmt', 'lnd', 'lo', 'load', 'lob', 'lobe', 'lobes',\n",
       "       'local', 'localise', 'localised', 'localization', 'localize',\n",
       "       'localized', 'locally', 'locate', 'located', 'location', 'lock',\n",
       "       'locked', 'locking', 'lockstep', 'locus', 'lofar', 'log',\n",
       "       'logical', 'logl', 'logms', 'logo', 'long', 'longer', 'longevity',\n",
       "       'longitude', 'longitudinal', 'longmore', 'longstanding',\n",
       "       'longward', 'longwave', 'look', 'lookback', 'loop', 'loose',\n",
       "       'loosely', 'lopsided', 'lord', 'lorentz', 'lorenz', 'lose',\n",
       "       'loses', 'losfr', 'loss', 'lossing', 'lot', 'loud', 'louvet',\n",
       "       'low', 'lower', 'lowering', 'lowest', 'lp', 'lpc', 'lsol', 'lsr',\n",
       "       'lss', 'lst', 'lsun', 'lsz', 'lte', 'ltg', 'ltgs', 'luck',\n",
       "       'luminal', 'luminosities', 'luminosity', 'luminoty', 'luminous',\n",
       "       'lumninous', 'lunar', 'lup', 'lupi', 'lupus', 'lurk', 'lv', 'lvg',\n",
       "       'ly', 'lya', 'lyalpha', 'lying', 'lyman', 'lynds', 'lyÎ±', 'ma',\n",
       "       'mac', 'mach', 'machine', 'machinery', 'macleod', 'macroscopic',\n",
       "       'macs', 'macsj', 'maelstrom', 'mag', 'magellan', 'magellanic',\n",
       "       'maging', 'magma', 'magn', 'magnesium', 'magnetar', 'magnetars',\n",
       "       'magnetic', 'magnetically', 'magnetise', 'magnetism',\n",
       "       'magnetization', 'magnetize', 'magnetized', 'magneto',\n",
       "       'magnetocentrifugal', 'magnetohydrodynamic',\n",
       "       'magnetohydrodynamical', 'magnetohydrodynamically',\n",
       "       'magnetohydrodynamics', 'magnetorotational', 'magnetosphere',\n",
       "       'magnetospheric', 'magnification', 'magnified', 'magnify',\n",
       "       'magnitude', 'magnum', 'magtnetic', 'mahalo', 'mahao', 'main',\n",
       "       'mainly', 'maintain', 'maintenance', 'maiolino', 'major',\n",
       "       'majoris', 'majority', 'make', 'makeup', 'making', 'mambo',\n",
       "       'mammoth', 'manage', 'mandatory', 'manga', 'manifest',\n",
       "       'manifestation', 'manner', 'mantle', 'many', 'map', 'mapp',\n",
       "       'mapped', 'mapping', 'maps', 'mar', 'march', 'marginal',\n",
       "       'marginally', 'mark', 'markarian', 'marked', 'markedly', 'marker',\n",
       "       'marking', 'markov', 'marrone', 'martian', 'martÃ­n', 'mas',\n",
       "       'maser', 'masering', 'masing', 'mask', 'masosa', 'masquerader',\n",
       "       'mass', 'masse', 'massive', 'massively', 'massse', 'masx', 'match',\n",
       "       'matched', 'material', 'maternal', 'matisse', 'matsuda', 'matter',\n",
       "       'matthee', 'matthew', 'mature', 'maud', 'mauna', 'maven', 'maxi',\n",
       "       'maxima', 'maximal', 'maximally', 'maximise', 'maximize',\n",
       "       'maximum', 'may', 'maybe', 'mbar', 'mbh', 'mbhmgal', 'mc',\n",
       "       'mcclure', 'mcfost', 'mcguire', 'mckee', 'mcore', 'mcs', 'md',\n",
       "       'mdcs', 'mdisk', 'mdrs', 'mdust', 'mdyn', 'meachnism', 'mean',\n",
       "       'meaning', 'meaningful', 'meaningfully', 'meanwhile', 'mearth',\n",
       "       'meassure', 'measurable', 'measure', 'measured', 'measurement',\n",
       "       'measuring', 'measurment', 'measurments', 'meaure', 'meaurement',\n",
       "       'mechaism', 'mechamism', 'mechanic', 'mechanical', 'mechanically',\n",
       "       'mechanism', 'mechanisms', 'mechansim', 'mechnanism', 'median',\n",
       "       'mediate', 'medium', 'meerkat', 'meet', 'mega', 'megallanic',\n",
       "       'megamaser', 'megamasers', 'megaparsec', 'megnetical', 'melchior',\n",
       "       'member', 'membership', 'memo', 'memory', 'menten', 'mention',\n",
       "       'mere', 'merely', 'merge', 'merger', 'mergeres', 'merging',\n",
       "       'meridional', 'merit', 'merlin', 'mesa', 'mesasurements', 'mesh',\n",
       "       'mesmerize', 'mesopause', 'mesosphere', 'mesospheric', 'mess',\n",
       "       'messager', 'messenger', 'messier', 'metal', 'metalicity',\n",
       "       'metallcity', 'metallic', 'metallicities', 'metallicity',\n",
       "       'metamorphosis', 'metastable', 'meteorite', 'meteorites',\n",
       "       'meteoritic', 'meteorology', 'meter', 'methanamine', 'methane',\n",
       "       'methanol', 'method', 'methodology', 'methyl', 'methylamine',\n",
       "       'meticulously', 'metre', 'metric', 'mev', 'mg', 'mgas', 'mgf',\n",
       "       'mgii', 'mgm', 'mgo', 'mgoh', 'mh', 'mhd', 'mhi', 'mhongoose',\n",
       "       'mhz', 'mic', 'mico', 'micro', 'microarcsec', 'microarcseconds',\n",
       "       'microarseconds', 'microbe', 'microjet', 'microjy', 'microlensing',\n",
       "       'micrometeorite', 'micrometeoroid', 'micrometer', 'micrometric',\n",
       "       'micron', 'micronic', 'microphysical', 'microphysics',\n",
       "       'microquasar', 'microscope', 'microscopic', 'microwave', 'mid',\n",
       "       'middle', 'midi', 'midlife', 'midplane', 'midpoint', 'midst',\n",
       "       'might', 'mightee', 'migrate', 'migrated', 'migration', 'miii',\n",
       "       'miknowski', 'milam', 'mild', 'milestone', 'milestones', 'miliky',\n",
       "       'milky', 'mill', 'milli', 'milliarcsec', 'milliarcsecond',\n",
       "       'milliarcseconds', 'millilensing', 'millimeter', 'millimetre',\n",
       "       'millimetric', 'millimiter', 'million', 'millisecond', 'millky',\n",
       "       'mimic', 'min', 'mind', 'mineralogically', 'mini', 'miniature',\n",
       "       'minimal', 'minimally', 'minimise', 'minimize', 'minimum',\n",
       "       'mininal', 'minisurvey', 'minkowski', 'minor', 'minority',\n",
       "       'minute', 'mips', 'mir', 'mira', 'miras', 'miri', 'miro', 'mirror',\n",
       "       'misalign', 'misaligned', 'misalignment', 'misidentification',\n",
       "       'misidentifications', 'misinterpretation', 'mislead', 'mismatch',\n",
       "       'miss', 'missed', 'missing', 'mission', 'mistery', 'mix', 'mixed',\n",
       "       'mixing', 'mixture', 'mj', 'mjup', 'mjy', 'mk', 'mlr', 'mm', 'mme',\n",
       "       'mmol', 'mms', 'mmtf', 'mmvlbi', 'mnras', 'mo', 'mob', 'mock',\n",
       "       'mode', 'model', 'modeling', 'modelling', 'moderate', 'moderately',\n",
       "       'modern', 'modes', 'modest', 'modestly', 'modification',\n",
       "       'modified', 'modifies', 'modify', 'modular', 'modulated',\n",
       "       'modulation', 'moelcular', 'mohegs', 'mol', 'mold', 'molecuar',\n",
       "       'molecues', 'moleculaes', 'molecular', 'molecularly', 'molecule',\n",
       "       'molecules', 'molinari', 'molsphere', 'momemtum', 'moment',\n",
       "       'momenta', 'momentum', 'mon', 'monitor', 'monitoring',\n",
       "       'monnitoring', 'mono', 'monoceros', 'monochromatic', 'monolithic',\n",
       "       'monopolar', 'monosaccharide', 'monotonically', 'monotonicaly',\n",
       "       'monoxide', 'monr', 'monreal', 'monster', 'monte', 'month',\n",
       "       'monthly', 'monumental', 'moon', 'mop', 'mophology', 'mopra',\n",
       "       'moreli', 'moreover', 'morita', 'morning', 'morpho',\n",
       "       'morphological', 'morphologically', 'morphology', 'morpohology',\n",
       "       'mortions', 'mosacing', 'mosaic', 'mosaicing', 'mosaicking',\n",
       "       'mosdef', 'mosfire', 'mostly', 'motion', 'motivate', 'motivated',\n",
       "       'motivates', 'motivation', 'motte', 'mount', 'mountain', 'move',\n",
       "       'movement', 'movie', 'mp', 'mpc', 'mpcs', 'mpec', 'mqg', 'mqgs',\n",
       "       'mrc', 'mri', 'mrk', 'mroe', 'ms', 'msf', 'msfr', 'msfrs', 'msol',\n",
       "       'msolar', 'msrfs', 'mstar', 'msun', 'msx', 'mu', 'much', 'mudf',\n",
       "       'mudgilg', 'mueller', 'mult', 'multi', 'multiband', 'multicolor',\n",
       "       'multifrequency', 'multigapped', 'multiphase', 'multiple',\n",
       "       'multiplet', 'multiplexed', 'multiplexing', 'multiplicity',\n",
       "       'multiplicy', 'multiply', 'multipolar', 'multipolarmorphologies',\n",
       "       'multiscale', 'multitude', 'multiwavelength', 'multiwavelentgh',\n",
       "       'multiwavelngth', 'multiwavength', 'mum', 'murmur', 'musca',\n",
       "       'muse', 'must', 'mustang', 'muti', 'mutual', 'mutually', 'muv',\n",
       "       'mvir', 'mw', 'mwa', 'mwc', 'mylup', 'myr', 'myriad', 'myrs',\n",
       "       'myso', 'mysos', 'mysterious', 'mystery', 'mystic', 'mz', 'na',\n",
       "       'nacl', 'naco', 'nad', 'nagao', 'nagging', 'nai', 'naid', 'naive',\n",
       "       'naively', 'nakamura', 'naked', 'name', 'namely', 'nano', 'nanten',\n",
       "       'narayanan', 'narrow', 'narrowband', 'narrower', 'narrowness',\n",
       "       'nasa', 'nasas', 'nascent', 'natal', 'national', 'natural',\n",
       "       'naturally', 'nature', 'navigate', 'nb', 'nc', 'ncg', 'nco', 'nd',\n",
       "       'ne', 'near', 'nearby', 'nearer', 'nearest', 'nearir', 'nearly',\n",
       "       'nearness', 'nearst', 'neatly', 'nebula', 'nebulae', 'nebulairas',\n",
       "       'nebular', 'nebule', 'nebulosity', 'necesary', 'necessarily',\n",
       "       'necessary', 'necessaty', 'necessity', 'need', 'needed',\n",
       "       'neededto', 'needle', 'negative', 'neglect', 'neglectable',\n",
       "       'neglected', 'negligible', 'negrello', 'neighbor', 'neighborhood',\n",
       "       'neighboring', 'neighbourhood', 'neirborhood', 'neither',\n",
       "       'neowise', 'neptune', 'neptunian', 'ness', 'nessie', 'nest',\n",
       "       'nested', 'nestle', 'net', 'network', 'neugebauer', 'neutral',\n",
       "       'neutrino', 'neutron', 'never', 'nevertheless', 'new', 'newborn',\n",
       "       'newest', 'newly', 'news', 'newton', 'next', 'ngc', 'ngvla', 'nh',\n",
       "       'nhd', 'nice', 'nicely', 'niche', 'nickname', 'nifs', 'night',\n",
       "       'nightside', 'nii', 'nine', 'nir', 'nircam', 'nirs', 'nirspec',\n",
       "       'nitric', 'nitride', 'nitrile', 'nitrogen', 'nitrous', 'nixon',\n",
       "       'nkalakatha', 'nlr', 'nlte', 'nm', 'nma', 'nml', 'nn', 'nnh',\n",
       "       'nobeyama', 'noble', 'node', 'noema', 'noise', 'noisy', 'noma',\n",
       "       'nominal', 'nominally', 'non', 'noncircular', 'nondetected',\n",
       "       'nondetections', 'none', 'nonetheless', 'nonexistent',\n",
       "       'nonthermal', 'noon', 'norm', 'norma', 'normal', 'normalisation',\n",
       "       'normalize', 'normalized', 'normally', 'north', 'northeast',\n",
       "       'northeastern', 'norther', 'northern', 'northwest', 'not',\n",
       "       'notable', 'notably', 'note', 'notice', 'notion', 'notoriously',\n",
       "       'notsu', 'notwithstanding', 'nov', 'nova', 'novae', 'noval',\n",
       "       'novel', 'november', 'nowadays', 'nozzle', 'nro', 'nsf', 'ntt',\n",
       "       'nu', 'nucelar', 'nuclear', 'nucleate', 'nucleation', 'nuclei',\n",
       "       'nucleic', 'nucleobase', 'nucleobases', 'nucleosynthesis',\n",
       "       'nucleosynthetic', 'nucleosysntesys', 'nucleosythesis',\n",
       "       'nucleotide', 'nucleus', 'nuga', 'nugget', 'null', 'number',\n",
       "       'numerical', 'numerous', 'nursery', 'nurture', 'nustar', 'nw',\n",
       "       'oasis', 'ob', 'obervation', 'obervations', 'oberve',\n",
       "       'obesrvations', 'obey', 'obeys', 'object', 'objective',\n",
       "       'objectives', 'oblique', 'obscuration', 'obscure', 'obscuread',\n",
       "       'obscured', 'obscures', 'obseration', 'obserations',\n",
       "       'observability', 'observable', 'observables', 'observating',\n",
       "       'observatinos', 'observation', 'observational', 'observationally',\n",
       "       'observations', 'observatios', 'observatons', 'observatory',\n",
       "       'observe', 'observed', 'observer', 'observered', 'observervations',\n",
       "       'observes', 'observing', 'observtions', 'obseved', 'obsject',\n",
       "       'obsolete', 'obstacle', 'obsuring', 'obtain', 'obtainable',\n",
       "       'obttain', 'obvious', 'obviously', 'occ', 'occasion',\n",
       "       'occasionally', 'occult', 'occultation', 'occupation', 'occupy',\n",
       "       'occur', 'occurance', 'occurence', 'occurr', 'occurrence',\n",
       "       'occurring', 'occurs', 'ocean', 'oceans', 'ocs', 'october', 'od',\n",
       "       'odd', 'odds', 'odin', 'offer', 'offering', 'offersa',\n",
       "       'officially', 'offset', 'ofiras', 'ofstreamers', 'ofstrongly',\n",
       "       'often', 'ogas', 'oh', 'ohcho', 'ohm', 'ohms', 'oi', 'oii', 'oiii',\n",
       "       'oir', 'oj', 'ojbects', 'oka', 'okuda', 'old', 'older', 'oldest',\n",
       "       'omc', 'omega', 'omi', 'omit', 'omnipresence', 'omnipresent',\n",
       "       'onc', 'one', 'onghia', 'ongoing', 'onir', 'onnection', 'onset',\n",
       "       'onthe', 'onto', 'oort', 'opacity', 'opaque', 'open', 'opening',\n",
       "       'operate', 'operation', 'operational', 'oph', 'ophb', 'ophiuchi',\n",
       "       'ophiuchius', 'ophiuchus', 'opinion', 'opitical', 'opitmized',\n",
       "       'oportunity', 'opportunity', 'oppose', 'opposed', 'opposite',\n",
       "       'oppositely', 'oppoturnity', 'opr', 'opt', 'optic', 'optical',\n",
       "       'optically', 'optimal', 'optimally', 'optimise', 'optimization',\n",
       "       'optimize', 'optimized', 'optimum', 'option', 'orbit', 'orbital',\n",
       "       'orbiter', 'order', 'orderd', 'ordered', 'orderly', 'ordinarily',\n",
       "       'ordinary', 'organ', 'organic', 'organics', 'organization',\n",
       "       'organize', 'orgins', 'orgreater', 'orho', 'ori', 'oribupfil',\n",
       "       'orient', 'orientate', 'orientation', 'origin', 'original',\n",
       "       'originally', 'originate', 'originated', 'originates', 'origins',\n",
       "       'orinois', 'orion', 'orionis', 'orionxis', 'oriorins', 'oris',\n",
       "       'orphan', 'ortho', 'orthogonal', 'osberved', 'oscillate',\n",
       "       'oscillation', 'osiris', 'osorio', 'osso', 'others', 'otherwise',\n",
       "       'ots', 'ouchi', 'ouflow', 'ouflowing', 'ouflows', 'oumuamua',\n",
       "       'ourburst', 'ourflows', 'out', 'outbreak', 'outburst',\n",
       "       'outbursting', 'outbursts', 'outburts', 'outcome', 'outer',\n",
       "       'outermost', 'outflow', 'outflowing', 'outflows', 'outgassing',\n",
       "       'outkirts', 'outlier', 'outliers', 'outline', 'outlook', 'output',\n",
       "       'outshine', 'outshines', 'outside', 'outskirst', 'outskirt',\n",
       "       'outskirts', 'outstanding', 'outward', 'outwards', 'oved', 'oveer',\n",
       "       'over', 'overabundance', 'overabundant', 'overall', 'overcome',\n",
       "       'overcooling', 'overdense', 'overdensities', 'overdensity',\n",
       "       'overestimate', 'overestimation', 'overhead', 'overheads',\n",
       "       'overlap', 'overlapped', 'overlapping', 'overlook', 'overlooked',\n",
       "       'overluminous', 'overly', 'overproduce', 'overshoot', 'overtone',\n",
       "       'overture', 'overview', 'overwhelm', 'ovro', 'owe', 'own',\n",
       "       'oxidaniumyl', 'oxidation', 'oxide', 'oxidization', 'oxidizer',\n",
       "       'oxygen', 'oxygenate', 'oxygenated', 'oxygeni', 'ozdes', 'pa',\n",
       "       'pac', 'pace', 'pacs', 'padoan', 'pagb', 'pah', 'pahs',\n",
       "       'painstakingly', 'paint', 'pair', 'pairing', 'pale', 'palomar',\n",
       "       'pan', 'panchromatic', 'pandora', 'panel', 'panoramic',\n",
       "       'panstarrs', 'panta', 'paper', 'par', 'para', 'parabolic',\n",
       "       'paradigm', 'paradox', 'paradoxically', 'parallax', 'parallel',\n",
       "       'paramagnetic', 'parameter', 'parameterised', 'parametric',\n",
       "       'paramount', 'paramters', 'parent', 'parental', 'parkes', 'parlup',\n",
       "       'parsec', 'parsecs', 'part', 'partial', 'partially', 'partialy',\n",
       "       'participate', 'particle', 'particles', 'particular',\n",
       "       'particularly', 'particulary', 'partition', 'partly', 'partner',\n",
       "       'pas', 'paschen', 'pass', 'passage', 'passing', 'passive',\n",
       "       'passively', 'past', 'patch', 'patchy', 'patern', 'path',\n",
       "       'pathfinder', 'pathfinding', 'paths', 'pathway', 'pathways',\n",
       "       'pattens', 'pattern', 'paucity', 'pause', 'pave', 'paw', 'pay',\n",
       "       'payne', 'pbrss', 'pc', 'pcc', 'pccs', 'pceb', 'pcebs', 'pd',\n",
       "       'pdb', 'pdbi', 'pdf', 'pdla', 'pdr', 'pdrs', 'pds', 'pe', 'pea',\n",
       "       'peak', 'peaked', 'peakers', 'peanut', 'pearl', 'pebble',\n",
       "       'peculiar', 'peculiarity', 'peer', 'pei', 'pencil', 'pending',\n",
       "       'penellope', 'penetrate', 'penetration', 'people', 'peptide',\n",
       "       'per', 'percent', 'percentage', 'percolate', 'perez', 'perfect',\n",
       "       'perfectly', 'perform', 'performance', 'performing', 'perhaps',\n",
       "       'periastron', 'pericenter', 'perihelion', 'period', 'periodic',\n",
       "       'periodicity', 'periphery', 'permanent', 'permeate', 'permit',\n",
       "       'perpendicular', 'perpendicularly', 'perseus', 'persist',\n",
       "       'persistence', 'persistent', 'persists', 'perspective', 'pertain',\n",
       "       'pertinent', 'perturb', 'perturbation', 'perturbed', 'perturber',\n",
       "       'perturbing', 'pervasive', 'pesce', 'peter', 'pety', 'pevatron',\n",
       "       'pg', 'pgc', 'ph', 'phangs', 'phase', 'phased', 'phasing', 'phd',\n",
       "       'phenomena', 'phenomenal', 'phenomenological', 'phenomenology',\n",
       "       'phenomenon', 'phibss', 'phillips', 'phoenix', 'phoshorus',\n",
       "       'phosphine', 'phospholipid', 'phosphorous', 'phosphorus',\n",
       "       'phosphrous', 'phosporous', 'phot', 'photo', 'photoablation',\n",
       "       'photochemical', 'photochemically', 'photochemistry',\n",
       "       'photochemisty', 'photodesorbed', 'photodesorption',\n",
       "       'photodestruction', 'photodissiciation', 'photodissocation',\n",
       "       'photodissociate', 'photodissociated', 'photodissociation',\n",
       "       'photoelectric', 'photoevaporating', 'photoevaporation',\n",
       "       'photoevaporative', 'photogenic', 'photoionisation',\n",
       "       'photoionising', 'photoionization', 'photoionized',\n",
       "       'photoionizing', 'photolysis', 'photometer', 'photometric',\n",
       "       'photometrically', 'photometry', 'photon', 'photonionized',\n",
       "       'photoprocessed', 'photopshere', 'photosphere', 'photospheric',\n",
       "       'photoveporation', 'phse', 'phsyical', 'physcial', 'physic',\n",
       "       'physical', 'physically', 'physico', 'physicochemical', 'physics',\n",
       "       'pi', 'pic', 'pick', 'pictoris', 'picture', 'piece', 'piecemeal',\n",
       "       'pierce', 'pierre', 'pii', 'pile', 'pillar', 'pillars', 'pilot',\n",
       "       'pils', 'pin', 'pinch', 'pinched', 'pinilla', 'pinnacle',\n",
       "       'pinpoint', 'pinpointed', 'pinte', 'pioneer', 'pioneering', 'pipe',\n",
       "       'pipeline', 'piscium', 'pitch', 'pivot', 'pivotal', 'pixel',\n",
       "       'pixelated', 'pixels', 'pj', 'pks', 'pl', 'place', 'plague',\n",
       "       'plain', 'plan', 'planar', 'planck', 'plane', 'planet',\n",
       "       'planetary', 'planetarynebulae', 'planetesimal', 'planetesimals',\n",
       "       'planetestimals', 'planetoid', 'planetry', 'planets', 'plank',\n",
       "       'planning', 'plasma', 'plateau', 'plausibility', 'plausible',\n",
       "       'plausibly', 'play', 'played', 'player', 'please', 'pleiades',\n",
       "       'plentiful', 'plenty', 'plethora', 'plis', 'plough', 'plow',\n",
       "       'plume', 'plumes', 'plunge', 'plural', 'plus', 'pluto', 'pm',\n",
       "       'pmc', 'pmcs', 'pmf', 'pmn', 'pmo', 'pmos', 'pms', 'pn', 'pne',\n",
       "       'pns', 'po', 'pocket', 'point', 'pointing', 'pointings', 'poise',\n",
       "       'pol', 'polar', 'polarimeter', 'polarimetric', 'polarimetry',\n",
       "       'polarisation', 'polarise', 'polarised', 'polarity',\n",
       "       'polarization', 'polarize', 'polarized', 'pole', 'poll', 'pollute',\n",
       "       'poloidal', 'polute', 'polyacetylenes', 'polyatomic', 'polycyclic',\n",
       "       'polyvalent', 'pool', 'pooly', 'poor', 'poorer', 'poorly',\n",
       "       'popiii', 'popular', 'popularity', 'populate', 'populatio',\n",
       "       'population', 'populaton', 'populous', 'popultion', 'porous',\n",
       "       'portfolio', 'portion', 'porto', 'portrait', 'pose', 'posit',\n",
       "       'position', 'positional', 'positive', 'positively', 'posse',\n",
       "       'possess', 'possibilities', 'possibility', 'possibilty',\n",
       "       'possible', 'possiblity', 'possibly', 'possily', 'post', 'poster',\n",
       "       'postpone', 'postulate', 'pot', 'potential', 'potentially',\n",
       "       'power', 'powered', 'powerful', 'powerfully', 'powering',\n",
       "       'poynting', 'ppd', 'ppds', 'ppn', 'ppne', 'ppv', 'practical',\n",
       "       'practically', 'practice', 'pragmatically', 'pre', 'prebiotic',\n",
       "       'prebiotically', 'precede', 'precedent', 'precess', 'precession',\n",
       "       'precessional', 'precious', 'precipitate', 'precipitation',\n",
       "       'precise', 'precisely', 'precision', 'preclude', 'precludes',\n",
       "       'precluster', 'precursor', 'precursors', 'predecessor',\n",
       "       'predetermine', 'predication', 'predict', 'predictable',\n",
       "       'predictably', 'predicted', 'predictins', 'prediction',\n",
       "       'predictive', 'predictor', 'predicts', 'predominant',\n",
       "       'predominantly', 'predominately', 'predominatly', 'preexist',\n",
       "       'prefer', 'preferable', 'preferably', 'preference', 'preferential',\n",
       "       'preferentially', 'preferred', 'preliminar', 'preliminary',\n",
       "       'prelude', 'premier', 'premiere', 'prep', 'preparatory', 'prepare',\n",
       "       'preplanetary', 'preponderant', 'prepose', 'prerequisite',\n",
       "       'prescription', 'preselected', 'preselection', 'presence',\n",
       "       'present', 'presently', 'preserve', 'press', 'pressaging',\n",
       "       'pressing', 'pressure', 'prestellar', 'presumable', 'presumably',\n",
       "       'presume', 'presuming', 'prevail', 'prevalance', 'prevalenace',\n",
       "       'prevalence', 'prevalent', 'prevent', 'preventative', 'preventing',\n",
       "       'prevents', 'previous', 'previously', 'previsouly', 'prg',\n",
       "       'primarily', 'primary', 'prime', 'primeval', 'primitive',\n",
       "       'primordial', 'principal', 'principally', 'principle', 'prior',\n",
       "       'priority', 'prismas', 'pristine', 'priv', 'privide', 'privilege',\n",
       "       'pro', 'probability', 'probable', 'probably', 'probe', 'probed',\n",
       "       'probes', 'problem', 'procedure', 'proceed', 'proceeded',\n",
       "       'proceeds', 'procees', 'proceses', 'process', 'processing',\n",
       "       'prodigious', 'produce', 'product', 'production', 'productive',\n",
       "       'profile', 'profound', 'profoundly', 'progenitor', 'progenitors',\n",
       "       'progeny', 'prograde', 'program', 'programme', 'programn',\n",
       "       'progress', 'progression', 'progressively', 'prohibit',\n",
       "       'prohibitively', 'prohibits', 'project', 'projection', 'prolific',\n",
       "       'prolong', 'prolonged', 'prominent', 'promise', 'promising',\n",
       "       'promissing', 'promote', 'promotes', 'promoting', 'promotion',\n",
       "       'prompt', 'promptly', 'prone', 'prong', 'pronged', 'pronounce',\n",
       "       'pronounced', 'proof', 'propagate', 'propagation', 'propanol',\n",
       "       'proper', 'properies', 'properites', 'properly', 'properteis',\n",
       "       'property', 'proplyd', 'proplyds', 'propoerties', 'proportion',\n",
       "       'proportional', 'proposal', 'propose', 'proposed', 'proposer',\n",
       "       'propperties', 'proprietary', 'propse', 'propsed', 'propsoe',\n",
       "       'propsoed', 'propylene', 'propyne', 'prospect', 'prospective',\n",
       "       'prospose', 'protection', 'proteins', 'proto', 'protobinaries',\n",
       "       'protobinary', 'protocluster', 'protoclusters', 'protogalaxies',\n",
       "       'protogalaxy', 'protolunar', 'proton', 'protonated',\n",
       "       'protoplaneary', 'protoplanet', 'protoplanetary', 'protoplanetray',\n",
       "       'protoplanets', 'protoplantary', 'protoplanteray',\n",
       "       'protopolanetary', 'protosellar', 'protosolar', 'protostar',\n",
       "       'protostars', 'protostellar', 'protostellarcore', 'prototar',\n",
       "       'prototstars', 'prototype', 'prototypical', 'prototypycal',\n",
       "       'protoype', 'protoypical', 'protplanetary', 'protrude', 'prove',\n",
       "       'proved', 'proven', 'provenance', 'provide', 'providing',\n",
       "       'provoke', 'provokes', 'proxima', 'proximate', 'proximity',\n",
       "       'proxy', 'proyect', 'ps', 'psb', 'psbs', 'psc', 'pscmf', 'pscs',\n",
       "       'pseudo', 'pseudobulges', 'pseudodisk', 'pseudodisks', 'psf',\n",
       "       'pshycal', 'pso', 'psz', 'public', 'publication', 'publicity',\n",
       "       'publicize', 'publicly', 'publish', 'puff', 'pull', 'pulsar',\n",
       "       'pulsate', 'pulsation', 'pulsationally', 'pulse', 'pump',\n",
       "       'pumping', 'pup', 'puppis', 'pure', 'purely', 'purpose', 'pursue',\n",
       "       'push', 'put', 'putative', 'puzzle', 'puzzling', 'pv', 'pvd',\n",
       "       'pyridine', 'pyrimidine', 'pyx', 'pz', 'qa', 'qi', 'qj', 'qm',\n",
       "       'qso', 'qsos', 'quadrant', 'quadruple', 'quadruply', 'quadrupole',\n",
       "       'qualify', 'qualitative', 'quality', 'quanitified',\n",
       "       'quantification', 'quantified', 'quantify', 'quantitative',\n",
       "       'quantitatively', 'quantities', 'quantity', 'quanz', 'quarter',\n",
       "       'quartile', 'quasar', 'quasars', 'quasi', 'quench', 'quenched',\n",
       "       'quenches', 'quenching', 'quest', 'question', 'questionable',\n",
       "       'queue', 'quick', 'quickly', 'quiescence', 'quiescent',\n",
       "       'quiescently', 'quiet', 'quintessential', 'quintet', 'quintuple',\n",
       "       'quintuplet', 'quite', 'quntify', 'qx', 'qz', 'ra', 'rad',\n",
       "       'radaitive', 'radex', 'radial', 'radially', 'radiate', 'radiation',\n",
       "       'radiative', 'radiatively', 'radical', 'radically', 'radii',\n",
       "       'radio', 'radioactive', 'radioastron', 'radiogalaxies',\n",
       "       'radiogalaxy', 'radiojets', 'radiolytic', 'radionuclides',\n",
       "       'radiotelescopes', 'radius', 'raft', 'rail', 'rain', 'rainbow',\n",
       "       'raise', 'ralatively', 'raleigh', 'ram', 'ramification', 'ramp',\n",
       "       'ramstedt', 'random', 'randomly', 'range', 'rangwala', 'rank',\n",
       "       'ranked', 'rapid', 'rapidly', 'rare', 'rarely', 'rarer', 'rarest',\n",
       "       'rarified', 'rarity', 'rat', 'rate', 'rathborne', 'rather',\n",
       "       'ratii', 'ratio', 'ratios', 'raw', 'ray', 'rayet', 'rayets',\n",
       "       'rayleigh', 'rays', 'razor', 'rcs', 'rcw', 'rd', 'rdi', 're',\n",
       "       'reaccreted', 'reaccretion', 'reach', 'reachable', 'reached',\n",
       "       'react', 'reaction', 'reactive', 'readable', 'readily', 'ready',\n",
       "       'real', 'realise', 'realistic', 'reality', 'realization',\n",
       "       'realize', 'really', 'realm', 'reanalizing', 'reanalyse',\n",
       "       'reanalysed', 'reappear', 'reason', 'reasonable', 'reasonably',\n",
       "       'reasonnably', 'reaveling', 'rebel', 'rebels', 'recalibrate',\n",
       "       'recalibrated', 'recede', 'receipt', 'receive', 'received',\n",
       "       'receiver', 'recent', 'recently', 'reception', 'recieved',\n",
       "       'recognise', 'recognition', 'recognize', 'recoil', 'recollimation',\n",
       "       'recombination', 'recombine', 'recommend', 'reconcile',\n",
       "       'reconsider', 'reconstruct', 'reconstruction', 'record', 'recover',\n",
       "       'recoverable', 'recovery', 'rectangle', 'rectangular', 'rectify',\n",
       "       'rectilinear', 'recur', 'recurrent', 'recycle', 'red', 'redden',\n",
       "       'reddening', 'redder', 'reddest', 'redistribute', 'redistribution',\n",
       "       'redsfhit', 'redshifr', 'redshift', 'redshifted', 'redshifts',\n",
       "       'reduce', 'reduced', 'reduces', 'reduction', 'reemerge', 'reesult',\n",
       "       'reexamine', 'refer', 'referee', 'reference', 'refine',\n",
       "       'refinement', 'reflect', 'reflection', 'reflector', 'reform',\n",
       "       'reformation', 'refract', 'refractive', 'refractory', 'refreeze',\n",
       "       'refute', 'regard', 'regardless', 'regenerate', 'regime',\n",
       "       'regimes', 'regin', 'regio', 'region', 'regional', 'registered',\n",
       "       'registration', 'regolith', 'regular', 'regularly', 'regulate',\n",
       "       'regulated', 'regulates', 'regulation', 'regulatory', 'reheat',\n",
       "       'reheating', 'rei', 'reignite', 'reimaged', 'reimers', 'reinforce',\n",
       "       'reinstate', 'reinvigorate', 'reioniation', 'reionisation',\n",
       "       'reionised', 'reionization', 'reionize', 'reionized',\n",
       "       'reionzation', 'reject', 'rejection', 'rejuvenate', 'rejuvenation',\n",
       "       'relate', 'related', 'relates', 'relation', 'relationship',\n",
       "       'relative', 'relatively', 'relativistic', 'relativity',\n",
       "       'relatvely', 'relax', 'relaxed', 'release', 'relevance',\n",
       "       'relevant', 'reliability', 'reliable', 'reliably', 'reliance',\n",
       "       'reliant', 'relic', 'relies', 'rely', 'remain', 'remainder',\n",
       "       'remained', 'remains', 'remarkable', 'remarkably', 'remedy',\n",
       "       'reminiscent', 'remnant', 'remote', 'remotely', 'removal',\n",
       "       'remove', 'remy', 'render', 'rendezvous', 'rendition', 'renovate',\n",
       "       'reobserve', 'reorientation', 'repeat', 'repeatable', 'repeatedly',\n",
       "       'repel', 'repercussion', 'repetitive', 'replace', 'replenish',\n",
       "       'replenishment', 'replicate', 'replicated', 'reponsible', 'report',\n",
       "       'reprensentative', 'represent', 'representative',\n",
       "       'representatively', 'representive', 'represesent', 'reprocess',\n",
       "       'reprocessed', 'reprocessing', 'reproduce', 'reproduced',\n",
       "       'reproduction', 'request', 'requested', 'requiered', 'require',\n",
       "       'required', 'requirement', 'requisite', 'rescale', 'research',\n",
       "       'researcher', 'resemblance', 'resemble', 'resembles', 'reserve',\n",
       "       'reserviors', 'reservoir', 'reservoirs', 'reset', 'resevoir',\n",
       "       'reshape', 'reshift', 'reside', 'resides', 'residual', 'resilient',\n",
       "       'resist', 'resoliution', 'resolution', 'resolutionrequired',\n",
       "       'resolutios', 'resolvable', 'resolve', 'resolved', 'resolving',\n",
       "       'resonance', 'resonant', 'resource', 'respect', 'respective',\n",
       "       'respectively', 'respond', 'responds', 'response', 'responsible',\n",
       "       'resposible', 'rest', 'restframe', 'restore', 'restrict',\n",
       "       'restricted', 'resub', 'resubmission', 'resubmit', 'resubmitting',\n",
       "       'result', 'resultant', 'resupplied', 'resupply', 'retain',\n",
       "       'retention', 'rethink', 'retire', 'retrace', 'retrieval',\n",
       "       'retrieve', 'retrograde', 'retry', 'return', 'rev', 'reveal',\n",
       "       'reveald', 'revealed', 'revealing', 'reveals', 'revealved',\n",
       "       'revelead', 'reverberation', 'reversal', 'reverse', 'reversed',\n",
       "       'review', 'reviewer', 'revise', 'revision', 'revisit', 'revive',\n",
       "       'revolution', 'revolutionary', 'revolutionise', 'revolutionize',\n",
       "       'reward', 'rg', 'rgb', 'rh', 'rho', 'ribose', 'ricci', 'rich',\n",
       "       'richard', 'richest', 'richness', 'richter', 'rid', 'riddle',\n",
       "       'ridge', 'riecher', 'riechers', 'right', 'rigorous', 'rigorously',\n",
       "       'riley', 'rim', 'ring', 'ringed', 'ringlike', 'ringworld', 'ripe',\n",
       "       'rise', 'risen', 'riser', 'risk', 'risky', 'rival', 'rl', 'rlagn',\n",
       "       'rm', 'rms', 'rna', 'ro', 'road', 'roation', 'robbery', 'robust',\n",
       "       'robustly', 'robustness', 'roche', 'rock', 'rocky', 'role',\n",
       "       'roles', 'roll', 'romero', 'root', 'rooted', 'rope', 'rosetta',\n",
       "       'rosette', 'rosina', 'rossby', 'rot', 'rotaing', 'rotate',\n",
       "       'rotates', 'rotating', 'rotation', 'rotational', 'rotationally',\n",
       "       'rotator', 'rotators', 'rough', 'roughly', 'round', 'rout',\n",
       "       'route', 'routine', 'routinely', 'rover', 'roy', 'rps', 'rrl',\n",
       "       'rrls', 'rrti', 'rs', 'rsds', 'rsg', 'rsgs', 'rsoi', 'rsr',\n",
       "       'rstar', 'rt', 'ru', 'rudimentary', 'rule', 'run', 'runaway',\n",
       "       'rung', 'russell', 'rust', 'rusty', 'rw', 'rx', 'rxc', 'rxj', 'ry',\n",
       "       'sa', 'saa', 'saab', 'sab', 'saboca', 'sadly', 'safety', 'sage',\n",
       "       'sagittarius', 'sahu', 'sakurai', 'salient', 'saline', 'salinity',\n",
       "       'salpeter', 'salt', 'salts', 'sami', 'sample', 'sampling',\n",
       "       'sanchez', 'sandor', 'sandwich', 'sargent', 'satellite',\n",
       "       'satisfactorily', 'satisfactory', 'satisfy', 'satisfyingly',\n",
       "       'satrburst', 'saturate', 'saturation', 'saturn', 'saturnian',\n",
       "       'saucer', 'say', 'sb', 'sbb', 'sbmh', 'sbs', 'sc', 'scale',\n",
       "       'scaled', 'scalelength', 'scalelengths', 'scaling', 'scan',\n",
       "       'scant', 'scarce', 'scarcity', 'scatter', 'scatterd', 'scattered',\n",
       "       'scattering', 'scavenge', 'sceario', 'scenaria', 'scenarii',\n",
       "       'scenario', 'scenarios', 'sch', 'schechter', 'schedule',\n",
       "       'scheduled', 'scheme', 'schimdt', 'schmidt', 'schmitt', 'school',\n",
       "       'schwarzschild', 'schwassmann', 'science', 'scientic',\n",
       "       'scientific', 'scientifically', 'scientist', 'scl', 'sclaes',\n",
       "       'sco', 'scope', 'scorpious', 'scorpius', 'scoville', 'scratch',\n",
       "       'screen', 'scrutinize', 'sct', 'scuba', 'sculpt', 'sculpting',\n",
       "       'sculptoris', 'sculpts', 'scupol', 'sd', 'sdc', 'sdp', 'sdss',\n",
       "       'sdssj', 'sea', 'seach', 'seal', 'seamlessly', 'search', 'season',\n",
       "       'seasonal', 'seat', 'sec', 'second', 'secondary', 'secondly',\n",
       "       'seconds', 'secret', 'section', 'secular', 'secularly', 'secure',\n",
       "       'securely', 'sed', 'seds', 'see', 'seed', 'seek', 'seem',\n",
       "       'seemingly', 'seens', 'segregate', 'segregation', 'segura',\n",
       "       'seize', 'seldom', 'select', 'selected', 'selection', 'selective',\n",
       "       'selectivelty', 'selectively', 'self', 'selfconsistently',\n",
       "       'semadeni', 'semi', 'semianalytical', 'sense', 'sensible',\n",
       "       'sensinsitive', 'sensitive', 'sensitively', 'sensitivity',\n",
       "       'sensitiviy', 'sensivitiy', 'sensivity', 'seo', 'sep', 'separate',\n",
       "       'separated', 'separation', 'sepia', 'sept', 'september',\n",
       "       'sequence', 'sequential', 'sequester', 'sequestration', 'ser',\n",
       "       'serenade', 'serendipitous', 'serendipitously', 'serenity', 'serf',\n",
       "       'series', 'serious', 'seriously', 'serpens', 'sersic', 'serve',\n",
       "       'sest', 'set', 'setting', 'settle', 'settlement', 'settling',\n",
       "       'setup', 'seven', 'several', 'severe', 'severely', 'severily',\n",
       "       'severly', 'sextans', 'sextuple', 'sey', 'seyfert', 'seyferts',\n",
       "       'sf', 'sfe', 'sfes', 'sfg', 'sfgs', 'sfms', 'sfr', 'sfrd', 'sfrl',\n",
       "       'sfrs', 'sg', 'sgasj', 'sgr', 'sgra', 'sgrb', 'sgss', 'sh',\n",
       "       'shade', 'shadow', 'shadows', 'shake', 'shall', 'shallow',\n",
       "       'shallower', 'shape', 'shaped', 'share', 'sharp', 'sharply',\n",
       "       'sharpness', 'shatter', 'shc', 'shcs', 'shear', 'sheath', 'shed',\n",
       "       'sheet', 'shell', 'shepherd', 'shield', 'shielded', 'shielding',\n",
       "       'shift', 'shifted', 'shifts', 'shimonishi', 'shin', 'shioya',\n",
       "       'shirley', 'shizels', 'shock', 'shocked', 'shocks', 'shockwaves',\n",
       "       'shoe', 'shoemaker', 'shone', 'shooter', 'short', 'shortcoming',\n",
       "       'shorten', 'shorter', 'shortest', 'shortly', 'shortward', 'show',\n",
       "       'showcase', 'showcases', 'showcasing', 'showed', 'showing',\n",
       "       'shrink', 'shroud', 'shrouded', 'shu', 'shut', 'shutdown',\n",
       "       'shvccs', 'si', 'sibling', 'sic', 'side', 'sideband', 'sidelobes',\n",
       "       'sideways', 'sight', 'sightline', 'sightlines', 'sigma', 'sign',\n",
       "       'signal', 'signarure', 'signature', 'signatures', 'signficant',\n",
       "       'significance', 'significant', 'significantly', 'signify',\n",
       "       'signpost', 'silence', 'silhouette', 'silicate', 'silicates',\n",
       "       'silicon', 'silk', 'silverman', 'sim', 'simba', 'similar',\n",
       "       'similarity', 'similarly', 'simobs', 'simple', 'simpler',\n",
       "       'simplest', 'simplicity', 'simplistic', 'simply',\n",
       "       'simulataneously', 'simulate', 'simulated', 'simulation',\n",
       "       'simulator', 'simultaneolusly', 'simultaneous', 'simultaneously',\n",
       "       'simultanous', 'simutanesly', 'since', 'sinfoni', 'single',\n",
       "       'singledish', 'sings', 'singular', 'singularly', 'sink', 'sinter',\n",
       "       'sinusoidal', 'sio', 'sis', 'sistematic', 'sit', 'site', 'sits',\n",
       "       'situ', 'situate', 'situation', 'six', 'sixfold', 'sixteen',\n",
       "       'sixth', 'size', 'sizeable', 'sized', 'sizes', 'sizescale',\n",
       "       'sizescales', 'sj', 'sk', 'ska', 'skew', 'skidmark', 'skim',\n",
       "       'skin', 'sky', 'sl', 'slam', 'sled', 'slew', 'slice', 'slightly',\n",
       "       'slingshot', 'slitless', 'slop', 'slope', 'slosh', 'slow',\n",
       "       'slower', 'slowly', 'slrs', 'slsn', 'slsne', 'slug', 'slump', 'sm',\n",
       "       'sma', 'small', 'smallest', 'smbbh', 'smbbhs', 'smbh', 'smbhs',\n",
       "       'smc', 'smd', 'smg', 'smgs', 'smm', 'smmj', 'smoke', 'smoking',\n",
       "       'smooth', 'smoothed', 'smoother', 'smoothly', 'smores', 'smt',\n",
       "       'sn', 'snake', 'snapshot', 'snapshots', 'sne', 'snells', 'snl',\n",
       "       'snow', 'snowline', 'snowlines', 'snr', 'snrs', 'snyder', 'sobral',\n",
       "       'sodium', 'sofia', 'soft', 'soi', 'sol', 'sola', 'solar', 'sole',\n",
       "       'solely', 'soler', 'solid', 'solidify', 'solidly', 'solitary',\n",
       "       'solomon', 'solstice', 'solution', 'solve', 'soma', 'sombrero',\n",
       "       'somehow', 'something', 'sometime', 'sometimes', 'somewhat',\n",
       "       'somewhere', 'son', 'sonic', 'soon', 'soot', 'sophisticate',\n",
       "       'sophisticated', 'sophistication', 'sorely', 'sort', 'sought',\n",
       "       'sound', 'sourcce', 'source', 'soures', 'south', 'southeast',\n",
       "       'southern', 'southwest', 'southwestern', 'sp', 'space',\n",
       "       'spacecraft', 'spacetime', 'spacial', 'spacing', 'span',\n",
       "       'spanning', 'sparcs', 'spark', 'sparked', 'sparse', 'spatial',\n",
       "       'spatially', 'spatio', 'spatiochemically', 'spatiokinematic',\n",
       "       'spawn', 'spc', 'speak', 'spec', 'special', 'specialist',\n",
       "       'specially', 'specie', 'species', 'specific', 'specifically',\n",
       "       'specified', 'specify', 'specroscopic', 'spectacular',\n",
       "       'spectacularly', 'spectra', 'spectral', 'spectrally', 'spectro',\n",
       "       'spectroastrometry', 'spectrocopic', 'spectrograph',\n",
       "       'spectrometer', 'spectroscopic', 'spectroscopically',\n",
       "       'spectroscopy', 'spectrosocopy', 'spectrosopic', 'spectrum',\n",
       "       'speculate', 'speculation', 'speculative', 'specutacular', 'speed',\n",
       "       'speices', 'spend', 'sperical', 'sph', 'sphere', 'spheres',\n",
       "       'spherical', 'spherically', 'spheroid', 'spheroidal', 'spica',\n",
       "       'spice', 'spider', 'spiderweb', 'spin', 'spine', 'spinning',\n",
       "       'spiral', 'spire', 'spite', 'spitzer', 'splash', 'splatter',\n",
       "       'splinter', 'split', 'splitting', 'spoke', 'sponge', 'spontaneous',\n",
       "       'sporadic', 'sport', 'spot', 'spotlight', 'spread', 'sprial',\n",
       "       'spring', 'spt', 'spty', 'spur', 'sputter', 'sputtered', 'spy',\n",
       "       'sq', 'sqr', 'square', 'sr', 'srci', 'srizes', 'srmhd', 'ss',\n",
       "       'ssa', 'ssc', 'sscs', 'ssfr', 'ssfrs', 'sspherically', 'sss',\n",
       "       'sst', 'ssv', 'st', 'stability', 'stabilize', 'stabilizing',\n",
       "       'stable', 'stabursts', 'stack', 'stacked', 'staff', 'stag',\n",
       "       'stage', 'stall', 'stand', 'standalone', 'standard', 'standing',\n",
       "       'star', 'starbursst', 'starburst', 'starbursting', 'starbursts',\n",
       "       'starburstsynthesis', 'starbust', 'stardust', 'starformation',\n",
       "       'starforming', 'starformtion', 'stark', 'starless', 'starlight',\n",
       "       'starr', 'stars', 'starspots', 'start', 'started', 'starting',\n",
       "       'starvation', 'starve', 'state', 'statement', 'static',\n",
       "       'statically', 'station', 'stationary', 'statistic', 'statistical',\n",
       "       'statistically', 'status', 'stay', 'stead', 'steadily', 'steady',\n",
       "       'steam', 'steep', 'steeper', 'steeply', 'steer', 'stefan',\n",
       "       'stella', 'stellar', 'stellocentric', 'stem', 'stems', 'step',\n",
       "       'stephan', 'stephans', 'stifle', 'still', 'stimulate', 'stir',\n",
       "       'stis', 'stochasitic', 'stochastic', 'stock', 'stokes', 'stone',\n",
       "       'stop', 'storage', 'store', 'storm', 'story', 'stractual',\n",
       "       'straight', 'straightforward', 'straightforwardly', 'strange',\n",
       "       'strangulation', 'strategic', 'strategically', 'strategy',\n",
       "       'stratification', 'stratified', 'stratify', 'stratosphere',\n",
       "       'stratospheric', 'stream', 'streamer', 'streamers', 'streaming',\n",
       "       'streams', 'strenghth', 'strength', 'strengthen', 'strengthens',\n",
       "       'stress', 'stretch', 'stretched', 'striation', 'stricking',\n",
       "       'strict', 'strictly', 'stride', 'strigent', 'strike', 'striking',\n",
       "       'strikingly', 'string', 'stringent', 'strip', 'stripe',\n",
       "       'stripping', 'stromgren', 'strong', 'strongest', 'strongly',\n",
       "       'structural', 'structure', 'structured', 'structureof',\n",
       "       'strucutre', 'struggle', 'struture', 'stucture', 'student',\n",
       "       'studied', 'study', 'stumble', 'stun', 'stunning', 'stunningly',\n",
       "       'sturctures', 'stymie', 'su', 'sub', 'subarcsec', 'subarcsecond',\n",
       "       'subaru', 'subbands', 'subclusters', 'subcomponents',\n",
       "       'subcritical', 'subdisk', 'subdisks', 'subfilaments',\n",
       "       'subgalactic', 'subhalo', 'subhalos', 'subject', 'sublimate',\n",
       "       'sublimation', 'subluminous', 'submicron', 'submillimeter',\n",
       "       'submillimetre', 'submillimter', 'submission', 'submit', 'submm',\n",
       "       'subparsec', 'subpc', 'subsample', 'subsamples', 'subscribe',\n",
       "       'subscribed', 'subsequent', 'subsequently', 'subset', 'subsolar',\n",
       "       'subsonic', 'subssctructures', 'substance', 'substantial',\n",
       "       'substantially', 'substellar', 'substitute', 'substitution',\n",
       "       'substructure', 'substructured', 'substructures', 'substrucure',\n",
       "       'subsurface', 'subsystem', 'subtend', 'subtle', 'subtract',\n",
       "       'subtraction', 'subunit', 'succeed', 'succeptibility', 'succesful',\n",
       "       'succesfull', 'success', 'successes', 'successful', 'successfull',\n",
       "       'successfully', 'succession', 'successive', 'succsessfully',\n",
       "       'sucessful', 'sucessfully', 'sudden', 'suddenly', 'suffer',\n",
       "       'suffers', 'sufficent', 'sufficient', 'sufficiently', 'sufur',\n",
       "       'sugar', 'suggensing', 'suggest', 'suggesting', 'suggestion',\n",
       "       'suggestive', 'suggests', 'suggets', 'suggsets', 'suit',\n",
       "       'suitability', 'suitable', 'suitably', 'suite', 'suited',\n",
       "       'sulfide', 'sulfur', 'sulphur', 'sum', 'summarize', 'summary',\n",
       "       'summer', 'sun', 'sunburst', 'sunlight', 'sunyaev', 'suparmassive',\n",
       "       'super', 'superantennae', 'superb', 'superbright', 'superbubble',\n",
       "       'superclusters', 'supercold', 'supercritical', 'superficially',\n",
       "       'supergiant', 'supergroup', 'superiant', 'superimpose', 'superior',\n",
       "       'superiour', 'superlative', 'superlinear', 'superluminous',\n",
       "       'supermassive', 'supernova', 'supernovae', 'superpose',\n",
       "       'superposition', 'supersaturation', 'supersonic', 'supersonically',\n",
       "       'superthin', 'superwind', 'superwinds', 'supp', 'suppermassive',\n",
       "       'supplement', 'supplemental', 'supplementary', 'supply', 'support',\n",
       "       'supported', 'suppose', 'supposedly', 'suppress', 'suppressed',\n",
       "       'suppresses', 'suppressing', 'suppression', 'supreme', 'supremely',\n",
       "       'supress', 'supression', 'suprime', 'sure', 'surely', 'surface',\n",
       "       'surge', 'surpass', 'surprise', 'surprising', 'surprisingly',\n",
       "       'surrouding', 'surroudnings', 'surround', 'surrounded',\n",
       "       'surroundings', 'survey', 'surveyes', 'survivability', 'survival',\n",
       "       'survive', 'survives', 'susceptibility', 'susceptible', 'suspect',\n",
       "       'suspected', 'suspicion', 'sustain', 'sustainable', 'sustained',\n",
       "       'sustains', 'sv', 'svs', 'sw', 'swas', 'swathe', 'swbar', 'sweep',\n",
       "       'sweeping', 'sweet', 'swell', 'swept', 'swex', 'swift', 'swinbank',\n",
       "       'swing', 'switch', 'swollen', 'sxdf', 'sxds', 'sy', 'symbiotic',\n",
       "       'symbolic', 'symmetric', 'symmetry', 'symphany', 'symptom',\n",
       "       'synchronise', 'synchronize', 'synchrotron', 'synergetic',\n",
       "       'synergic', 'synergistic', 'synergy', 'synonymous', 'synoptic',\n",
       "       'synthesis', 'synthesize', 'synthesized', 'synthetic', 'system',\n",
       "       'systematic', 'systematical', 'systematically', 'systematics',\n",
       "       'systemic', 'sytems', 'sz', 'sze', 'tabone', 'tac', 'tackle',\n",
       "       'tackling', 'tad', 'tadpol', 'tadpole', 'taffy', 'tag', 'tagets',\n",
       "       'taht', 'tail', 'tailor', 'tails', 'takano', 'take', 'tale',\n",
       "       'tamplete', 'tan', 'tandem', 'tangent', 'tangle', 'tango',\n",
       "       'taniguchi', 'tantalise', 'tantalisingly', 'tantalize',\n",
       "       'tantalizing', 'tantilizaing', 'tarantula', 'target', 'targeted',\n",
       "       'targetted', 'targetting', 'task', 'tatooine', 'tau', 'tauri',\n",
       "       'taurus', 'taylor', 'tb', 'tbol', 'tboss', 'tcmb', 'td', 'tde',\n",
       "       'tdes', 'tdg', 'tdgs', 'tds', 'tdust', 'te', 'teach', 'teacup',\n",
       "       'teague', 'team', 'tear', 'tearing', 'tech', 'technical',\n",
       "       'technique', 'technology', 'teff', 'tel', 'telescope', 'tell',\n",
       "       'telluric', 'temparature', 'temperature', 'temperatures',\n",
       "       'tempertaure', 'template', 'templates', 'temporal', 'temporally',\n",
       "       'temporarily', 'tempt', 'tempting', 'ten', 'tend', 'tendril',\n",
       "       'teng', 'tens', 'tension', 'tentacle', 'tentative', 'tentatively',\n",
       "       'tenth', 'tenuous', 'terahertz', 'term', 'terminal', 'terminate',\n",
       "       'terminator', 'termine', 'terrestrial', 'terrific', 'territory',\n",
       "       'tess', 'test', 'testable', 'testbed', 'testbeds', 'testify',\n",
       "       'tev', 'texc', 'text', 'textbook', 'tgas', 'tgo', 'th',\n",
       "       'thackeray', 'thank', 'thanks', 'thaures', 'thay', 'thec',\n",
       "       'thejet', 'thelen', 'theme', 'themeasured', 'theorem',\n",
       "       'theoretical', 'theoretically', 'theoreticalmodelsof', 'theories',\n",
       "       'theorise', 'theorist', 'theorize', 'theorteically', 'theory',\n",
       "       'theproposed', 'thereby', 'therefore', 'therein', 'thereof',\n",
       "       'therfore', 'thermal', 'thermalised', 'thermally', 'thermaly',\n",
       "       'thermo', 'thermochemical', 'thermochemistry', 'thermodynamic',\n",
       "       'thermodynamical', 'thermodynamics', 'thermometer', 'thermometry',\n",
       "       'thermosphere', 'thermospheric', 'theses', 'thesis', 'thick',\n",
       "       'thicker', 'thickness', 'thight', 'thin', 'thing', 'think',\n",
       "       'thinner', 'third', 'thirteen', 'thompson', 'thorough',\n",
       "       'thoroughly', 'though', 'thought', 'thoughtfully', 'thousand',\n",
       "       'thread', 'threafter', 'three', 'threefold', 'threshold', 'thrice',\n",
       "       'throat', 'throe', 'throughly', 'throughout', 'throw', 'thrown',\n",
       "       'thus', 'thymine', 'thz', 'ti', 'ticket', 'tidal', 'tidally',\n",
       "       'tide', 'tie', 'tied', 'tiered', 'tight', 'tighten', 'tighter',\n",
       "       'tightly', 'till', 'tilt', 'time', 'timecales', 'timeline',\n",
       "       'timely', 'times', 'timescale', 'timescales', 'timing', 'tiny',\n",
       "       'tio', 'tip', 'titan', 'title', 'tk', 'tkin', 'tmc', 'tn', 'tobin',\n",
       "       'toby', 'today', 'todays', 'together', 'tomography', 'ton', 'tool',\n",
       "       'toolkit', 'toomre', 'top', 'topic', 'topology', 'tori', 'torii',\n",
       "       'toroid', 'toroidal', 'toroidally', 'toroids', 'torque', 'torres',\n",
       "       'torsionally', 'torus', 'total', 'totality', 'totally', 'totaly',\n",
       "       'toward', 'towards', 'toy', 'tp', 'tps', 'trace', 'traceable',\n",
       "       'traced', 'tracer', 'tracing', 'track', 'trade', 'traditational',\n",
       "       'traditional', 'traditionally', 'trail', 'trait', 'trajectory',\n",
       "       'tranfer', 'trans', 'transfer', 'transform', 'transformation',\n",
       "       'transformational', 'transformative', 'transforms', 'transient',\n",
       "       'transit', 'transition', 'transitional', 'transitioning',\n",
       "       'translate', 'translucent', 'transmission', 'transmit',\n",
       "       'transonic', 'transorming', 'transparency', 'transparent',\n",
       "       'transport', 'transportation', 'transported', 'transporter',\n",
       "       'transtions', 'transverse', 'transversely', 'trap', 'trapezium',\n",
       "       'trapped', 'trapping', 'trappist', 'traverse', 'treasury', 'treat',\n",
       "       'treatment', 'tremaine', 'tremendous', 'tremendously', 'trend',\n",
       "       'trial', 'triangular', 'triangulum', 'triatomic', 'triboelectric',\n",
       "       'triceps', 'trickle', 'tricky', 'trifid', 'trigger', 'triggered',\n",
       "       'triggering', 'triggerring', 'trio', 'triple', 'triplet', 'triply',\n",
       "       'tripple', 'triton', 'trivial', 'tropical', 'tropopause',\n",
       "       'troposphere', 'tropospheric', 'troublesome', 'troughout', 'true',\n",
       "       'truely', 'truly', 'truncate', 'truncation', 'trust', 'truth',\n",
       "       'try', 'ts', 'tsf', 'tt', 'ttau', 'ttauri', 'tts', 'tuc',\n",
       "       'tucanae', 'tukh', 'tully', 'tune', 'tuning', 'tunnard',\n",
       "       'turbulence', 'turbulent', 'turn', 'turnover', 'turns', 'tw',\n",
       "       'twa', 'twelve', 'twenty', 'twice', 'twin', 'twist', 'two',\n",
       "       'twofold', 'tx', 'txs', 'type', 'typei', 'types', 'typical',\n",
       "       'typically', 'uas', 'ubiquitely', 'ubiquitous', 'ubiquitously',\n",
       "       'ubiquituous', 'ubiquity', 'ubiqutous', 'ubituitous', 'uc', 'ucds',\n",
       "       'uchii', 'udf', 'udg', 'udgs', 'uds', 'ugc', 'uhecr', 'uhecrs',\n",
       "       'ujy', 'ukidss', 'ulas', 'ulirg', 'ulirgs', 'ulisses', 'ullyses',\n",
       "       'ultimate', 'ultimately', 'ultra', 'ultrabright', 'ultracompact',\n",
       "       'ultracool', 'ultradeep', 'ultradense', 'ultraluminous',\n",
       "       'ultramassive', 'ultrared', 'ultrarelativistic', 'ultraviolet',\n",
       "       'ultravista', 'ulx', 'ulxs', 'um', 'umbiquity', 'un', 'unable',\n",
       "       'unaccounted', 'unachievable', 'unaffected', 'unaltered',\n",
       "       'unambigiously', 'unambigously', 'unambiguosly', 'unambiguous',\n",
       "       'unambiguously', 'unanimously', 'unanswered', 'unassociated',\n",
       "       'unattainable', 'unattenuated', 'unavailable', 'unavoidable',\n",
       "       'unbelievable', 'unbias', 'unbiased', 'unbiasedly', 'unblended',\n",
       "       'unboscured', 'unbound', 'uncalibrated', 'uncertain',\n",
       "       'uncertainties', 'uncertainty', 'unchanged', 'uncharacterized',\n",
       "       'uncharted', 'unchartered', 'unclear', 'unclustered',\n",
       "       'uncollimated', 'uncommon', 'uncompleted', 'unconfirmed',\n",
       "       'unconfused', 'unconstrained', 'unconvincing', 'uncorrelated',\n",
       "       'uncover', 'uncovered', 'uncovering', 'uncovers', 'undefined',\n",
       "       'undelaying', 'underabunbdance', 'underconstrained',\n",
       "       'underestimate', 'underestimated', 'underestimates', 'undergo',\n",
       "       'undergoes', 'undergoing', 'undergone', 'underground', 'underlie',\n",
       "       'underline', 'underluminous', 'underlying', 'undermines',\n",
       "       'underperform', 'underpin', 'underpins', 'underpopulated',\n",
       "       'undersampled', 'understand', 'understanding', 'understandings',\n",
       "       'understandingthe', 'understood', 'understudied',\n",
       "       'undersubscribed', 'undertake', 'undertaken', 'undertanding',\n",
       "       'underwater', 'underway', 'underwent', 'undesired', 'undetectable',\n",
       "       'undetected', 'undetermined', 'undiscovered', 'undistorted',\n",
       "       'undisturbed', 'undoubtedly', 'unenriched', 'unequaled',\n",
       "       'unequalled', 'unequivocal', 'unequivocally', 'uneven',\n",
       "       'unevovled', 'unexpected', 'unexpectedly', 'unexplained',\n",
       "       'unexplored', 'unfavorable', 'unfeasible', 'unfold',\n",
       "       'unfortunatelly', 'unfortunately', 'unfrozen', 'unhampered',\n",
       "       'unic', 'unidentified', 'unification', 'unified', 'unifies',\n",
       "       'uniform', 'uniformly', 'unify', 'unique', 'uniquely',\n",
       "       'uniqueness', 'uniques', 'unit', 'uniting', 'unity', 'universal',\n",
       "       'universality', 'universally', 'universe', 'univocally', 'unknown',\n",
       "       'unknowns', 'unleash', 'unlensed', 'unless', 'unlike', 'unlikely',\n",
       "       'unlock', 'unlocking', 'unmatchable', 'unmatched', 'unobcured',\n",
       "       'unobscured', 'unobservable', 'unobserved', 'unparalleled',\n",
       "       'unperturbed', 'unpolarized', 'unprecededent', 'unprecedented',\n",
       "       'unprecedentedly', 'unprecendented', 'unprecented', 'unprecently',\n",
       "       'unpredictable', 'unprocessed', 'unproven', 'unpublished',\n",
       "       'unravel', 'unraveling', 'unreachable', 'unrecognized',\n",
       "       'unrelated', 'unreliable', 'unremarkable', 'unreported',\n",
       "       'unrepresentative', 'unresolved', 'unrevealed', 'unrivaled',\n",
       "       'unsable', 'unsaturated', 'unscathed', 'unseen', 'unsettle',\n",
       "       'unsettled', 'unsolved', 'unstable', 'unsterdanding',\n",
       "       'unstructured', 'unsuccessful', 'unsure', 'unsurpassed',\n",
       "       'untangle', 'untapped', 'untested', 'unto', 'untrue', 'unusual',\n",
       "       'unusually', 'unvail', 'unvealing', 'unveil', 'unveiled',\n",
       "       'unveiling', 'unveils', 'unviased', 'unvirialized', 'unweave',\n",
       "       'unwind', 'upcoming', 'update', 'updated', 'updraft', 'upgrade',\n",
       "       'upheaval', 'uplift', 'uplifted', 'upon', 'upper', 'uppermost',\n",
       "       'ups', 'upstream', 'upto', 'upwards', 'uranian', 'uranus', 'urge',\n",
       "       'urgent', 'urgently', 'usage', 'use', 'used', 'useful', 'usefully',\n",
       "       'usefulness', 'uss', 'usual', 'usually', 'utilise', 'utilising',\n",
       "       'utility', 'utilization', 'utilize', 'utilized', 'utilizes',\n",
       "       'utilizing', 'utter', 'utterly', 'uv', 'uves', 'uvista', 'uvlf',\n",
       "       'uvradio', 'ux', 'uy', 'uz', 'vairous', 'valid', 'validate',\n",
       "       'validation', 'validity', 'valley', 'valuable', 'value', 'van',\n",
       "       'vandam', 'vanish', 'vantage', 'vapor', 'vaporization', 'vapour',\n",
       "       'variability', 'variable', 'variance', 'variant', 'variate',\n",
       "       'variation', 'variaty', 'varibility', 'varied', 'varies',\n",
       "       'variety', 'various', 'vary', 'vast', 'vastly', 'vazquez', 'vc',\n",
       "       'vecinity', 'vector', 'vega', 'vela', 'vello', 'vellos',\n",
       "       'velocity', 'vent', 'venue', 'venus', 'venusian', 'vera',\n",
       "       'veracity', 'verge', 'verification', 'verify', 'veritable',\n",
       "       'versa', 'versatility', 'version', 'versus', 'vertical',\n",
       "       'vertically', 'vertico', 'vesc', 'vestige', 'vexp', 'vhs', 'vi',\n",
       "       'via', 'viability', 'viable', 'vib', 'vibrational',\n",
       "       'vibrationally', 'vice', 'vicinity', 'vicnity', 'view', 'viewing',\n",
       "       'viewpoint', 'vigorous', 'vigorously', 'viking', 'villanueva',\n",
       "       'vimos', 'vinyl', 'violent', 'vir', 'virgo', 'virial',\n",
       "       'virialisation', 'virialised', 'virialization', 'virialized',\n",
       "       'virtis', 'virtualized', 'virtually', 'virtue', 'virus',\n",
       "       'viscosity', 'viscous', 'viscously', 'visibility', 'visible',\n",
       "       'vision', 'visir', 'visit', 'vista', 'visual', 'visualize',\n",
       "       'visualized', 'visually', 'vital', 'viti', 'vixen', 'vla', 'vlass',\n",
       "       'vlba', 'vlbi', 'vlemmings', 'vlm', 'vlmo', 'vlms', 'vlt', 'vlti',\n",
       "       'vltp', 'vms', 'void', 'volatile', 'volatines', 'volcanic',\n",
       "       'volcanically', 'volcanism', 'volume', 'volumetric', 'voorwerp',\n",
       "       'vortex', 'vr', 'vrot', 'vs', 'vsmow', 'vuitton', 'vul',\n",
       "       'vulnerable', 'vv', 'vy', 'wa', 'wachmann', 'wada', 'waist',\n",
       "       'wait', 'waive', 'wake', 'walch', 'walk', 'wall', 'wallaby',\n",
       "       'wander', 'wang', 'want', 'waoph', 'ward', 'warm', 'warmer',\n",
       "       'warp', 'warped', 'warping', 'warps', 'warrant', 'wasy', 'watch',\n",
       "       'water', 'wave', 'waveband', 'wavelegnth', 'wavelenght',\n",
       "       'wavelenghts', 'wavelength', 'wavelengths', 'way', 'waypoint',\n",
       "       'wb', 'wccc', 'wd', 'weak', 'weaken', 'weaker', 'weakly',\n",
       "       'weakness', 'wealth', 'weather', 'web', 'webb', 'website', 'wedge',\n",
       "       'weed', 'week', 'weel', 'weigh', 'weight', 'welch', 'well', 'west',\n",
       "       'westerbork', 'western', 'wet', 'wether', 'wf', 'wfc', 'wfs',\n",
       "       'whatever', 'whereabouts', 'whereas', 'whereby', 'whether',\n",
       "       'whichever', 'whilst', 'white', 'whole', 'whose', 'whther', 'wich',\n",
       "       'wide', 'wideband', 'widely', 'widen', 'wider', 'widespread',\n",
       "       'width', 'widths', 'wiggle', 'wiggling', 'wii', 'wil', 'wild',\n",
       "       'wildly', 'wilson', 'wim', 'wind', 'winding', 'window', 'windows',\n",
       "       'wing', 'winter', 'wirtanen', 'wisdom', 'wise', 'wisej', 'wish',\n",
       "       'wisps', 'withdraw', 'withdrawn', 'within', 'without', 'withstood',\n",
       "       'witness', 'wlm', 'wobble', 'wodan', 'woitke', 'wolf', 'womb',\n",
       "       'wood', 'word', 'work', 'workable', 'workhorse', 'working',\n",
       "       'world', 'worry', 'worsens', 'worth', 'would', 'wound', 'wr',\n",
       "       'wrap', 'wrapped', 'wrapping', 'write', 'writting', 'wrong', 'wsu',\n",
       "       'wtts', 'wttss', 'wu', 'www', 'wx', 'wyatt', 'xco', 'xcsj', 'xdcp',\n",
       "       'xdr', 'xdrs', 'xid', 'xl', 'xmm', 'xqr', 'xrf', 'xrfs',\n",
       "       'xshooter', 'xuv', 'xz', 'yang', 'yardstick', 'year', 'yearly',\n",
       "       'yellow', 'yen', 'yet', 'yield', 'yim', 'ymc', 'ymcs', 'yo',\n",
       "       'york', 'yound', 'young', 'younger', 'youngest', 'youngppns',\n",
       "       'youth', 'youthful', 'ypne', 'yr', 'yrs', 'yso', 'ysos', 'zams',\n",
       "       'zanella', 'zanni', 'zapata', 'zc', 'zd', 'zeeman', 'zel',\n",
       "       'zeldovich', 'zero', 'zeus', 'zfourge', 'zhang', 'zimpol',\n",
       "       'zinnecker', 'zinner', 'znajek', 'zo', 'zodiacal', 'zombie',\n",
       "       'zonal', 'zone', 'zoo', 'zoom', 'zphot', 'zsolar', 'zspec', 'zsun',\n",
       "       'zw', 'zyjhk', 'Âµjy', 'Âµm', 'Î»cdm', 'Î¼m'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate count vectorized data frame\n",
    "count_vectorizer = CountVectorizer()\n",
    "cv_projects = count_vectorizer.fit_transform(line_projects.lemmatized_no_sw_text)\n",
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3628x8641 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 281754 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_projects = tfidf_vectorizer.fit_transform(line_projects.lemmatized_no_sw_text).toarray()\n",
    "#tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(...)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target['target'].iloc[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_code                                       2011.0.00017.S\n",
      "target          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(target.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.sparse import csr_matrix\n",
    "# import numpy as np\n",
    "\n",
    "# X = csr_matrix(tfidf_projects)  # Assuming this is your TF-IDF features matrix\n",
    "# y = np.stack(target['target'].values)  # Converting target dataframe column to a numpy matrix\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = target['target'].values\n",
    "#y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PREPARE DATA\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.sparse import csr_matrix\n",
    "# import numpy as np\n",
    "\n",
    "# # Your provided code for splitting the dataset\n",
    "# X = tfidf_projects  # Assuming this is your TF-IDF features matrix\n",
    "# y = target['target'].values\n",
    "\n",
    "\n",
    "# threshold = 0.2\n",
    "\n",
    "# y = pd.Series(y)\n",
    "\n",
    "# # Apply thresholding within each list in the series\n",
    "# y_thresholded = y.apply(lambda x: [int(item >= threshold) for item in x])\n",
    "# y = np.array(y_thresholded)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Convert the sparse matrix to dense, then to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_train_array = np.array(y_train.tolist(), dtype=np.float32)\n",
    "# y_test_array = np.array(y_test.tolist(), dtype=np.float32)\n",
    "\n",
    "# # Then convert to PyTorch tensors\n",
    "# y_train_tensor = torch.tensor(y_train_array, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test_array, dtype=torch.float32)\n",
    "\n",
    "# # Create DataLoader instances\n",
    "# train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# batch_size = 32\n",
    "# train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEFINE NN MODEL FOR TEXT CLASSIFICATION, NETWORK USES FULLY CONNECTED LAYERS \n",
    "# # W/RELU ACTIVATIONS & DROPOUT FOR REGULARIZATION \n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class TextClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, num_classes):\n",
    "#         super(TextClassifier, self).__init__()\n",
    "#         # First fully connected layer\n",
    "#         self.fc1 = nn.Linear(input_dim, 512)\n",
    "#         # Dropout layer for regularization\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         # Second fully connected layer that outputs our desired number of classes\n",
    "#         self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Input passes through the first layer, then a ReLU activation function\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         # Apply dropout\n",
    "#         x = self.dropout(x)\n",
    "#         # Pass through the second layer\n",
    "#         x = self.fc2(x)\n",
    "#         # Apply sigmoid activation function to output probabilities\n",
    "#         x = torch.sigmoid(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# # Correctly get the input dimension from the TF-IDF feature matrix\n",
    "# input_dim = X_train.shape[1]\n",
    "# # Correctly get the number of classes from the shape of y_train_numeric\n",
    "# num_classes = y_train_array.shape[1]  # Use y_train_numeric to get the correct shape\n",
    "\n",
    "# model = TextClassifier(input_dim, num_classes)\n",
    "\n",
    "# # Use GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Binary Cross-Entropy Loss for multi-label classification\n",
    "# loss_fn = nn.BCELoss()\n",
    "# # Adam optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # TRAIN MODEL\n",
    "\n",
    "# def train_model(model, dataloader, loss_fn, optimizer):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for batch, (X, y) in enumerate(dataloader):\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "        \n",
    "#         # Forward pass: Compute predicted y\n",
    "#         pred = model(X)\n",
    "#         # Compute loss\n",
    "#         loss = loss_fn(pred, y)\n",
    "        \n",
    "#         # Zero gradients, perform a backward pass, and update the weights.\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     print(f\"Average Training Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# def evaluate_model(model, dataloader, threshold=0.5):\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_targets = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in dataloader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             preds = model(X)\n",
    "            \n",
    "#             # Apply threshold to convert probabilities to binary predictions\n",
    "#             binary_preds = (preds >= threshold).float()\n",
    "            \n",
    "#             all_preds.append(binary_preds.cpu())\n",
    "#             all_targets.append(y.cpu())\n",
    "\n",
    "#     # Concatenate all batch results\n",
    "#     all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "#     all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "\n",
    "#     # Ensure binary format (multilabel-indicator)\n",
    "#     all_preds = np.round(all_preds).astype(int)\n",
    "#     all_targets = all_targets.astype(int)\n",
    "\n",
    "#     # Calculate metrics\n",
    "#     accuracy = accuracy_score(all_targets, all_preds)\n",
    "#     precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "#     recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "#     f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "#     print(f\"Accuracy: {accuracy:.4f}\")\n",
    "#     print(f\"Precision: {precision:.4f}\")\n",
    "#     print(f\"Recall: {recall:.4f}\")\n",
    "#     print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "#     # Return both predictions and targets\n",
    "#     return all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, targets = evaluate_model(model, test_dataloader, threshold=0.5)\n",
    "\n",
    "# # Now you can print or inspect predictions and targets\n",
    "# print(predictions)\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Train the model for one epoch (or more) before evaluating\n",
    "# train_model(model, train_dataloader, loss_fn, optimizer)\n",
    "\n",
    "# # Evaluate the model\n",
    "# all_preds, all_targets = evaluate_model(model, test_dataloader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#threshold = 0.2\n",
    "\n",
    "# Assuming 'y' is your series containing lists\n",
    "#y = pd.Series(y)\n",
    "\n",
    "# Apply thresholding within each list in the series\n",
    "#y_thresholded = y.apply(lambda x: [int(item >= threshold) for item in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, dataloader, threshold=0.5):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     predictions = []\n",
    "#     true_labels = []\n",
    "\n",
    "#     with torch.no_grad():  # No need to track gradients\n",
    "#         for X, y in dataloader:\n",
    "#             X = X.to(device)\n",
    "#             preds = model(X)\n",
    "#             preds_binary = (preds >= threshold).float()  # Convert to binary predictions\n",
    "#             predictions.extend(preds_binary.cpu().numpy())\n",
    "#             true_labels.extend(y.cpu().numpy())\n",
    "\n",
    "#     return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "# # Using the function to predict on the test set\n",
    "# predictions, true_labels = predict(model, test_dataloader)\n",
    "\n",
    "# # Optionally, you can evaluate the predictions to see how well your model is performing\n",
    "# accuracy = accuracy_score(true_labels, predictions)\n",
    "# precision = precision_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "# recall = recall_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "# f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_loop(dataloader, model, loss_fn, optimizer, epochs=10):\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()  # Set the model to training mode\n",
    "#         total_loss = 0\n",
    "#         for batch, (X, y) in enumerate(dataloader):\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "\n",
    "#             # Compute prediction and loss\n",
    "#             pred = model(X)\n",
    "#             loss = loss_fn(pred, y)\n",
    "\n",
    "#             # Backpropagation\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "#         print(f\"Train loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# def test_loop(dataloader, model, loss_fn):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     total_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in dataloader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             pred = model(X)\n",
    "#             total_loss += loss_fn(pred, y).item()\n",
    "\n",
    "#     print(\"Test\\n-------------------------------\")\n",
    "#     print(f\"Test loss: {total_loss/len(dataloader):.4f}\\n\")\n",
    "\n",
    "# # Example usage:\n",
    "# train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "# test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assume these lists are filled within the train_loop and test_loop\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "\n",
    "# # Call train_loop and test_loop here to fill the above lists\n",
    "# train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "# test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(test_losses, label='Test Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Test Loss Over Epochs')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Assuming X is your NumPy array\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Now, when you print the array, it should display in full\n",
    "#print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 330ms/step - accuracy: 0.0225 - loss: 0.9090 - val_accuracy: 0.0516 - val_loss: 0.0599\n",
      "Epoch 2/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 328ms/step - accuracy: 0.0384 - loss: 0.0997 - val_accuracy: 0.0929 - val_loss: 0.0166\n",
      "Epoch 3/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 341ms/step - accuracy: 0.0500 - loss: 0.0133 - val_accuracy: 0.0516 - val_loss: 0.0101\n",
      "Epoch 4/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 354ms/step - accuracy: 0.0484 - loss: 0.0104 - val_accuracy: 0.0929 - val_loss: 0.1700\n",
      "Epoch 5/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 360ms/step - accuracy: 0.0415 - loss: 0.0604 - val_accuracy: 0.0516 - val_loss: 0.0097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9344fa4c40>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Assuming you have your data ready in X and y\n",
    "\n",
    "# Check if tfidf_projects is a sparse matrix and convert it to a NumPy array if so\n",
    "if hasattr(tfidf_projects, \"toarray\"):\n",
    "    X = np.array(tfidf_projects.toarray())\n",
    "else:\n",
    "    X = np.array(tfidf_projects)  # Assuming tfidf_projects is already a dense array\n",
    "\n",
    "# Convert your target to a suitable format\n",
    "y = np.stack(target['target'].values)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1024, \n",
    "                          activation='relu', \n",
    "                          input_shape=(X_train.shape[1],),\n",
    "                          kernel_regularizer=l2(0.001)),  # Applying L2 regularization\n",
    "    tf.keras.layers.Reshape((1024, 1)),\n",
    "    tf.keras.layers.Conv1D(128, kernel_size=5, \n",
    "                           activation='relu', \n",
    "                           padding='same',\n",
    "                           kernel_regularizer=l2(0.001)),  # Increased filters and applied L2 regularization\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, \n",
    "                          activation='relu', \n",
    "                          kernel_regularizer=l2(0.001)),  # Increased nodes and applied L2 regularization\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(y_train.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have your data ready in X and y\n",
    "# Check if tfidf_projects is a sparse matrix and convert it to a NumPy array if so\n",
    "if hasattr(tfidf_projects, \"toarray\"):\n",
    "    X = np.array(tfidf_projects.toarray())\n",
    "else:\n",
    "    X = np.array(tfidf_projects) # Assuming tfidf_projects is already a dense array\n",
    "\n",
    "# Convert your target to a suitable format\n",
    "y = np.stack(target['target'].values)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.conv1d = nn.Conv1d(1, 128, kernel_size=5, padding=2)\n",
    "        self.maxpool1d = nn.MaxPool1d(kernel_size=5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(128 * (1024 // 5), 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1d(x))\n",
    "        x = self.maxpool1d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Initialize the model\n",
    "model_cnn = CNN(X_train.shape[1], y_train.shape[1])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        inputs = X_train[i:i+batch_size]\n",
    "        labels = y_train[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct = (predicted == labels).float().sum()\n",
    "        epoch_acc += correct.item()\n",
    "        num_samples += labels.size(0)\n",
    "        print(outputs.shape)\n",
    "        \n",
    "'''\n",
    "    epoch_loss /= num_samples\n",
    "    epoch_acc /= num_samples\n",
    "\n",
    "    # Print the loss and accuracy for every epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have your data ready in X and y\n",
    "# Check if tfidf_projects is a sparse matrix and convert it to a NumPy array if so\n",
    "if hasattr(tfidf_projects, \"toarray\"):\n",
    "    X = np.array(tfidf_projects.toarray())\n",
    "else:\n",
    "    X = np.array(tfidf_projects) # Assuming tfidf_projects is already a dense array\n",
    "\n",
    "# Convert your target to a suitable format\n",
    "y = np.stack(target['target'].values)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the BERT-based model\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, output_size):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(bert_model.config.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = self.fc(pooled_output)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Initialize the model\n",
    "output_size = y_train.shape[1]\n",
    "model = BERTClassifier(bert_model, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        inputs = X_train[i:i+batch_size]\n",
    "        labels = y_train[i:i+batch_size]\n",
    "\n",
    "        # Tokenize and convert the input data to tensor\n",
    "        input_ids = torch.tensor([tokenizer.encode(str(inp), add_special_tokens=True, max_length=512, pad_to_max_length=True, truncation=True) for inp in inputs])\n",
    "        attention_mask = (input_ids != 0).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss /= num_samples\n",
    "\n",
    "    # Print the loss for every epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install \"tensorflow-probability[tf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade numpy pymc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(tfidf_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building a simple Bayesian Linear Regression Model\n",
    "with pm.Model() as model:\n",
    "    # Priors for unknown model parameters\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=10, shape=X_train.shape[1])\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "\n",
    "    # Expected value of outcome (Linear model)\n",
    "    mu = alpha + pm.math.dot(X_train, beta)\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Posterior distribution\n",
    "    trace = pm.sample(1000, return_inferencedata=False)\n",
    "\n",
    "# To visualize the posterior distribution\n",
    "pm.traceplot(trace)\n",
    "\n",
    "# To get the summary of the posterior distribution\n",
    "summary = pm.summary(trace)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_rnn = tf.keras.models.Sequential([\n",
    "#    tf.keras.layers.Embedding(input_dim=X_train.shape[1], output_dim=64, input_length=X_train.shape[1]),\n",
    "#    tf.keras.layers.SimpleRNN(128, return_sequences=True),\n",
    "#    tf.keras.layers.SimpleRNN(128),\n",
    "#    tf.keras.layers.Dense(y_train.shape[1], activation='sigmoid')\n",
    "#])#\n",
    "#\n",
    "#model_rnn.compile(optimizer='adam',\n",
    "#                  loss='binary_crossentropy',\n",
    "#                  metrics=['accuracy'])#\n",
    "#\n",
    "#model_rnn.fit(X_train.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.1)  # Note: RNN requires dense input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m venv pymc-venv\n",
    "source pymc-venv/bin/activate  # Use `.\\pymc-venv\\Scripts\\activate` on Windows\n",
    "pip install numpy pymc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
